[
  {
    "objectID": "x2go.html",
    "href": "x2go.html",
    "title": "X2Go",
    "section": "",
    "text": "X2Go provides fast and secure graphical access to an EML desktop with support for copy and paste between the local and remote computers.\n\n\nThere are clients for both Mac and Windows. If you have a Mac, make sure you have Xquartz installed.\n\n\n\nLaunch the application and create a new session. The following settings override the default values:\n\nSession\n\nSession name: Your Favorite Machine\nHost: machine-name.berkeley.edu\nLogin: YOUR EML LOGIN\nEnable “Try auto login (ssh-agent or default ssh key)” if you use ssh-agent to connect to the EML without your password. If you do not enable this you will be prompted to enter your EML password when connecting.\nSession type: XFCE\n\nInput/Output\n\nCustom: 1024x768 (or whatever you desire)\nSet display DPI: 100\n\nMedia\n\nDisable “Enable sound support”\nDisable “Client side printing support”",
    "crumbs": [
      "Home",
      "Remote Access",
      "X2Go"
    ]
  },
  {
    "objectID": "x2go.html#download",
    "href": "x2go.html#download",
    "title": "X2Go",
    "section": "",
    "text": "There are clients for both Mac and Windows. If you have a Mac, make sure you have Xquartz installed.",
    "crumbs": [
      "Home",
      "Remote Access",
      "X2Go"
    ]
  },
  {
    "objectID": "x2go.html#settings",
    "href": "x2go.html#settings",
    "title": "X2Go",
    "section": "",
    "text": "Launch the application and create a new session. The following settings override the default values:\n\nSession\n\nSession name: Your Favorite Machine\nHost: machine-name.berkeley.edu\nLogin: YOUR EML LOGIN\nEnable “Try auto login (ssh-agent or default ssh key)” if you use ssh-agent to connect to the EML without your password. If you do not enable this you will be prompted to enter your EML password when connecting.\nSession type: XFCE\n\nInput/Output\n\nCustom: 1024x768 (or whatever you desire)\nSet display DPI: 100\n\nMedia\n\nDisable “Enable sound support”\nDisable “Client side printing support”",
    "crumbs": [
      "Home",
      "Remote Access",
      "X2Go"
    ]
  },
  {
    "objectID": "vpn.html",
    "href": "vpn.html",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "Download the AnyConnect software from the bottom of its Software Central page.\nRun the AnyConnect client and on the Connection tab, in the field marked Connect to enter ucbvpn.berkeley.edu as the hostname.\nWhen prompted enter your CalNet credentials for the username and password fields.\nChoose a connection group. The first option is suitable for most cases:\n\n1-Campus_VPN: tunnel only campus traffic through the VPN\n2-Campus_VPN_Full_Tunnel: tunnel all of your internet traffic through it\n3-Library_VPN groups: just library traffic\n\nClick the Connect button.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Using the Campus VPN"
    ]
  },
  {
    "objectID": "vpn.html#using-the-campus-vpn",
    "href": "vpn.html#using-the-campus-vpn",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "Download the AnyConnect software from the bottom of its Software Central page.\nRun the AnyConnect client and on the Connection tab, in the field marked Connect to enter ucbvpn.berkeley.edu as the hostname.\nWhen prompted enter your CalNet credentials for the username and password fields.\nChoose a connection group. The first option is suitable for most cases:\n\n1-Campus_VPN: tunnel only campus traffic through the VPN\n2-Campus_VPN_Full_Tunnel: tunnel all of your internet traffic through it\n3-Library_VPN groups: just library traffic\n\nClick the Connect button.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Using the Campus VPN"
    ]
  },
  {
    "objectID": "ucthesis.html",
    "href": "ucthesis.html",
    "title": "ucthesis LaTeX style",
    "section": "",
    "text": "This is the README file for the UCTHESIS class for LaTeX. It corresponds to version 3.1 of the UCTHESIS class (14 July 2001).\nNOTE: v3.0 is the first LaTeX2e version of UCTHESIS. It is now a class that runs in native LaTeX2e mode. It is functionally identical to UCTHESIS.STY v2.7 released on 30 October 1994 by Ethan V. Munson. Other than changes for compatibility (mostly having to do with font selection), and option selection, very little modification has been done to the style. As a result, there are probably cleaner ways to implement a number of features. That will have to wait for the next release. (BBF 10/31/94)\n\n\n\n\n\nThere is a sample dissertation (by the fictitious, but very irritating, Perry H Disdainful) in the file uctest.tex. It also uses uctest.bib as its bibliography database (though the contents of the database are not important). Mostly this is useful as an example of how to produce the front matter. If you don’t understand LaTeX at all, this file might help you get started, but, since you’re going to be writing a 100+ page document, you should invest the $20 in a copy of the LaTeX manual (by Leslie Lamport the original author of LaTeX). This has recently been updated for LaTeX2e.\nThe LaTeX Companion, by Goossens, Mittelbach, and Samarin (who have been involved in developping and supporting the new version of LaTeX) is also quite good. It gives a lot of useful information if you are going to be writing or modifying classes, and gives a lot of additional information on commonly available style packages. It’s about $35.\n\n\n\nTo use the UCTHESIS class, make sure that the ucthesis.cls file is on your TEXINPUTS search path and use the following command at the start of your input file:\ndocumentclass{ucthesis}\n\n\n\n\nThe UCTHESIS class is a port of the UCTHESIS style version 2.7 (the final 2.09 release) to LaTeX2e. The UCTHESIS style is a modified version of the standard LaTeX REPORT style that is accepted for use with University of California PhD dissertations and Masters theses. The available commands are almost identical to those of the REPORT style, so your best starting point for documentation is the LaTeX manual written by Leslie Lamport.\nThe key features of the class are:\n\nThe primary modification to the REPORT style is the use of pseudo-double-spacing, since the UC system’s rules are still designed for typewriters. This is achieved by increasing the baselinestretch parameter to 1.37. The baselinestretch is returned to a single-spaced value of 1.00 for elements like tables, captions, and footnotes and for all displayed text (quote, quotation, and verse environments). Unfortunately, this is done with a macro called ssp which resets the font size to normalsize. In LaTeX 2.09 this seems to be unavoidable, but it makes it very hard to create tables in different font sizes.\nMargins are 1.5 inches on the left, 1.0 inches elsewhere.\n3) Uses 11 point by default; you can use the 10pt or 12pt options for those sizes.\nPage numbers are in the top right corner for all pages.\nComplete, correct front matter for UC dissertations can be generated. If you are not a UC student, you should make sure that the front matter is OK with your school.\n\n\n\nThere are five primary options:\nThe “draft” style uses single-spacing throughout the document.\nThe “final” style uses the correct pseudo-double-spacing. This option is the default and is redundant, but is included for symmetry.\nThe “10pt”, “11pt”, and “12pt” styles set the default font size to the obvious value. The “11pt” option is the default and thus is redundant, but is safe to use anyway.\nThe options are selected on the documentclass line, e.g.:\ndocumentclass[10pt,draft]{ucthesis}\n\n\n\nIf you want to use page headers or footers other than the default ones, you should try using “headerfooter.sty” or “fancyheadings.sty”. The myheadings pagestyle doesn’t work well and there is no workaround. The headerfooter and fancyheadings styles are widely distributed, well documented, and easy to use.\n\n\n\n\nThe other key service provided by this class is that it generates correct front matter (title page, approval page, abstract, etc.) with a failrly simple set of commands. This facility could be a little easier, but compared to an earlier state of affairs, it’s pretty slick. The format of the front matter is specified quite explicitly in the document “Guidelines for Submitting a Doctoral Dissertation or Master’s Thesis” distributed by the UC Berkeley Graduate Division. The current version of the class is based on the 2001 version of this document.\nA complete example of the use of the front matter commands can be found in the sample dissertation distributed with the class.\n\n\nTo use the front matter macros and environments, you must first declare a number of text strings:\ntitle           Dissertation title author          Your name as registered with UC (usually w/ full middle name) degreeyear      Year your dissertation will be granted degreesemester  Semester (or quarter) your dissertation will be granted degree          The title of your degree (e.g. Doctor of Philosophy) chair           Title and name of your committee chair (e.g. \"Professor Michael A. Harrison\") othermembers    The names of the other members of your committee separated by linebreaks (e.g. \"Professor Susan L. Graham\\Professor Jim Pitman) numberofmembers The number of members on your committee.  This defaults to 3 (and thus is optional) and can be any value between 3 and 6.  It affects the number of lines on the approval page and the space between them. prevdegrees     Your previous degrees:                 \"B.A. (University of California, San Diego) 1978\\\\                 B.A. (University of California, San Diego) 1986\\\\                 M.S. (University of California, Berkeley) 1989\" field           The official title of your field.  This is usually your department's name, but at Berkeley, most Engineering degrees have a more complex name.  Be sure to check the guidelines for any special twists on the name of your field. campus          The name of your UC campus.  This should be capitalized. (e.g. Berkeley) \n\n\n\nThe title, approval, and copyright pages have extremely rigid formats that allow them to be generated automatically once the above declarations have been made. To generate them, invoke the macros\n\\maketitle \\approvalpage \\copyrightpage\nYou should probably invoke them in that order, because that’s the order required by the guidelines.\n\n\n\nBecause you have to provide the text of the abstract, only the title can be generated automatically. So, there is an abstract environment. It generates the title and numbers the abstract in arabic numerals and makes sure that it starts on new page.\nThe UC system requires that your advisor sign the last page of your abstract. Many students just let their advisor just sign at a random location on the page, but you can use the abstractsignature command to generate a signature line with your advisor’s name printed below it. This command generates the signature line at the point it is invoked, so it should be placed at the end of the abstract.\n\n\n\nThe remaining front matter (dedication, table of contents, lists of figures and tables, acknowledgements) MUST be put inside the “frontmatter” environment, which ensures that page-numbering is handled properly. Within this frontmatter environment, you put the environments and commands for the rest of the front matter. There are environments for “dedication” and “acknowledgements” and the standard LaTeX commands for producing tableofcontents, listoffigures, and listoftables.\nThe standard LaTeX commands are well documented in the LaTeX manual. You will probably have to hand edit the .lof (list of figures) and .lot (list of tables) files to make verbose captions more suitable for this front matter. Once you do this, remember to use the nofiles macro to keep them from getting overwritten.\nThe acknowledgements and dedication environments make their contents start on a new page. The acknowledgements environment also put the word “Acknowledgements” in large, bold, centered text at the top of the page. For formatting the dedication page, you’re on your own. After all, the dedication is a kind of poetry and there’s no predicting the right way to format poetry.\n\n\n\n\nThe “smalltabular” and “smalltabular*” environments are equivalent to the “tabular” and “tabular*” environments, except that they use the small font. The “scriptsizetabular” and “scriptsizetabular*” use the scriptsize font.\n\n\n\nTo install the UCTHESIS class, you need to install four files:\nucthesis.cls uct10.clo uct11.clo uct12.clo\nin your LaTeX class file repository.",
    "crumbs": [
      "Home",
      "Software",
      "ucthesis LaTeX style"
    ]
  },
  {
    "objectID": "ucthesis.html#ucthesis-latex-class",
    "href": "ucthesis.html#ucthesis-latex-class",
    "title": "ucthesis LaTeX style",
    "section": "",
    "text": "This is the README file for the UCTHESIS class for LaTeX. It corresponds to version 3.1 of the UCTHESIS class (14 July 2001).\nNOTE: v3.0 is the first LaTeX2e version of UCTHESIS. It is now a class that runs in native LaTeX2e mode. It is functionally identical to UCTHESIS.STY v2.7 released on 30 October 1994 by Ethan V. Munson. Other than changes for compatibility (mostly having to do with font selection), and option selection, very little modification has been done to the style. As a result, there are probably cleaner ways to implement a number of features. That will have to wait for the next release. (BBF 10/31/94)",
    "crumbs": [
      "Home",
      "Software",
      "ucthesis LaTeX style"
    ]
  },
  {
    "objectID": "ucthesis.html#using-the-ucthesis-class",
    "href": "ucthesis.html#using-the-ucthesis-class",
    "title": "ucthesis LaTeX style",
    "section": "",
    "text": "There is a sample dissertation (by the fictitious, but very irritating, Perry H Disdainful) in the file uctest.tex. It also uses uctest.bib as its bibliography database (though the contents of the database are not important). Mostly this is useful as an example of how to produce the front matter. If you don’t understand LaTeX at all, this file might help you get started, but, since you’re going to be writing a 100+ page document, you should invest the $20 in a copy of the LaTeX manual (by Leslie Lamport the original author of LaTeX). This has recently been updated for LaTeX2e.\nThe LaTeX Companion, by Goossens, Mittelbach, and Samarin (who have been involved in developping and supporting the new version of LaTeX) is also quite good. It gives a lot of useful information if you are going to be writing or modifying classes, and gives a lot of additional information on commonly available style packages. It’s about $35.\n\n\n\nTo use the UCTHESIS class, make sure that the ucthesis.cls file is on your TEXINPUTS search path and use the following command at the start of your input file:\ndocumentclass{ucthesis}",
    "crumbs": [
      "Home",
      "Software",
      "ucthesis LaTeX style"
    ]
  },
  {
    "objectID": "ucthesis.html#what-the-ucthesis-class-does",
    "href": "ucthesis.html#what-the-ucthesis-class-does",
    "title": "ucthesis LaTeX style",
    "section": "",
    "text": "The UCTHESIS class is a port of the UCTHESIS style version 2.7 (the final 2.09 release) to LaTeX2e. The UCTHESIS style is a modified version of the standard LaTeX REPORT style that is accepted for use with University of California PhD dissertations and Masters theses. The available commands are almost identical to those of the REPORT style, so your best starting point for documentation is the LaTeX manual written by Leslie Lamport.\nThe key features of the class are:\n\nThe primary modification to the REPORT style is the use of pseudo-double-spacing, since the UC system’s rules are still designed for typewriters. This is achieved by increasing the baselinestretch parameter to 1.37. The baselinestretch is returned to a single-spaced value of 1.00 for elements like tables, captions, and footnotes and for all displayed text (quote, quotation, and verse environments). Unfortunately, this is done with a macro called ssp which resets the font size to normalsize. In LaTeX 2.09 this seems to be unavoidable, but it makes it very hard to create tables in different font sizes.\nMargins are 1.5 inches on the left, 1.0 inches elsewhere.\n3) Uses 11 point by default; you can use the 10pt or 12pt options for those sizes.\nPage numbers are in the top right corner for all pages.\nComplete, correct front matter for UC dissertations can be generated. If you are not a UC student, you should make sure that the front matter is OK with your school.\n\n\n\nThere are five primary options:\nThe “draft” style uses single-spacing throughout the document.\nThe “final” style uses the correct pseudo-double-spacing. This option is the default and is redundant, but is included for symmetry.\nThe “10pt”, “11pt”, and “12pt” styles set the default font size to the obvious value. The “11pt” option is the default and thus is redundant, but is safe to use anyway.\nThe options are selected on the documentclass line, e.g.:\ndocumentclass[10pt,draft]{ucthesis}\n\n\n\nIf you want to use page headers or footers other than the default ones, you should try using “headerfooter.sty” or “fancyheadings.sty”. The myheadings pagestyle doesn’t work well and there is no workaround. The headerfooter and fancyheadings styles are widely distributed, well documented, and easy to use.",
    "crumbs": [
      "Home",
      "Software",
      "ucthesis LaTeX style"
    ]
  },
  {
    "objectID": "ucthesis.html#front-matter",
    "href": "ucthesis.html#front-matter",
    "title": "ucthesis LaTeX style",
    "section": "",
    "text": "The other key service provided by this class is that it generates correct front matter (title page, approval page, abstract, etc.) with a failrly simple set of commands. This facility could be a little easier, but compared to an earlier state of affairs, it’s pretty slick. The format of the front matter is specified quite explicitly in the document “Guidelines for Submitting a Doctoral Dissertation or Master’s Thesis” distributed by the UC Berkeley Graduate Division. The current version of the class is based on the 2001 version of this document.\nA complete example of the use of the front matter commands can be found in the sample dissertation distributed with the class.\n\n\nTo use the front matter macros and environments, you must first declare a number of text strings:\ntitle           Dissertation title author          Your name as registered with UC (usually w/ full middle name) degreeyear      Year your dissertation will be granted degreesemester  Semester (or quarter) your dissertation will be granted degree          The title of your degree (e.g. Doctor of Philosophy) chair           Title and name of your committee chair (e.g. \"Professor Michael A. Harrison\") othermembers    The names of the other members of your committee separated by linebreaks (e.g. \"Professor Susan L. Graham\\Professor Jim Pitman) numberofmembers The number of members on your committee.  This defaults to 3 (and thus is optional) and can be any value between 3 and 6.  It affects the number of lines on the approval page and the space between them. prevdegrees     Your previous degrees:                 \"B.A. (University of California, San Diego) 1978\\\\                 B.A. (University of California, San Diego) 1986\\\\                 M.S. (University of California, Berkeley) 1989\" field           The official title of your field.  This is usually your department's name, but at Berkeley, most Engineering degrees have a more complex name.  Be sure to check the guidelines for any special twists on the name of your field. campus          The name of your UC campus.  This should be capitalized. (e.g. Berkeley) \n\n\n\nThe title, approval, and copyright pages have extremely rigid formats that allow them to be generated automatically once the above declarations have been made. To generate them, invoke the macros\n\\maketitle \\approvalpage \\copyrightpage\nYou should probably invoke them in that order, because that’s the order required by the guidelines.\n\n\n\nBecause you have to provide the text of the abstract, only the title can be generated automatically. So, there is an abstract environment. It generates the title and numbers the abstract in arabic numerals and makes sure that it starts on new page.\nThe UC system requires that your advisor sign the last page of your abstract. Many students just let their advisor just sign at a random location on the page, but you can use the abstractsignature command to generate a signature line with your advisor’s name printed below it. This command generates the signature line at the point it is invoked, so it should be placed at the end of the abstract.\n\n\n\nThe remaining front matter (dedication, table of contents, lists of figures and tables, acknowledgements) MUST be put inside the “frontmatter” environment, which ensures that page-numbering is handled properly. Within this frontmatter environment, you put the environments and commands for the rest of the front matter. There are environments for “dedication” and “acknowledgements” and the standard LaTeX commands for producing tableofcontents, listoffigures, and listoftables.\nThe standard LaTeX commands are well documented in the LaTeX manual. You will probably have to hand edit the .lof (list of figures) and .lot (list of tables) files to make verbose captions more suitable for this front matter. Once you do this, remember to use the nofiles macro to keep them from getting overwritten.\nThe acknowledgements and dedication environments make their contents start on a new page. The acknowledgements environment also put the word “Acknowledgements” in large, bold, centered text at the top of the page. For formatting the dedication page, you’re on your own. After all, the dedication is a kind of poetry and there’s no predicting the right way to format poetry.",
    "crumbs": [
      "Home",
      "Software",
      "ucthesis LaTeX style"
    ]
  },
  {
    "objectID": "ucthesis.html#other-commands-not-found-in-the-standard-report-style",
    "href": "ucthesis.html#other-commands-not-found-in-the-standard-report-style",
    "title": "ucthesis LaTeX style",
    "section": "",
    "text": "The “smalltabular” and “smalltabular*” environments are equivalent to the “tabular” and “tabular*” environments, except that they use the small font. The “scriptsizetabular” and “scriptsizetabular*” use the scriptsize font.",
    "crumbs": [
      "Home",
      "Software",
      "ucthesis LaTeX style"
    ]
  },
  {
    "objectID": "ucthesis.html#installing-the-ucthesis-class",
    "href": "ucthesis.html#installing-the-ucthesis-class",
    "title": "ucthesis LaTeX style",
    "section": "",
    "text": "To install the UCTHESIS class, you need to install four files:\nucthesis.cls uct10.clo uct11.clo uct12.clo\nin your LaTeX class file repository.",
    "crumbs": [
      "Home",
      "Software",
      "ucthesis LaTeX style"
    ]
  },
  {
    "objectID": "tensorflow.html",
    "href": "tensorflow.html",
    "title": "Tensorflow",
    "section": "",
    "text": "Recent versions of Tensorflow by default make use of AVX instructions, a feature of newer chips. If Tensorflow is run on these older machines, the instruction is not available and the error occurs. To avoid this, when submitting your job via Slurm, include `-c avx`. If you are directly accessing a compute server, you can run `grep avx /proc/cpuinfo | wc - l`. If the result is `0`, the AVX instructions are not available and you should use a newer machine, such as klein, fargo, quesnay, or sargan.",
    "crumbs": [
      "Home",
      "Software",
      "Tensorflow"
    ]
  },
  {
    "objectID": "tensorflow.html#why-does-tensorflow-fail-with-an-illegal-instruction",
    "href": "tensorflow.html#why-does-tensorflow-fail-with-an-illegal-instruction",
    "title": "Tensorflow",
    "section": "",
    "text": "Recent versions of Tensorflow by default make use of AVX instructions, a feature of newer chips. If Tensorflow is run on these older machines, the instruction is not available and the error occurs. To avoid this, when submitting your job via Slurm, include `-c avx`. If you are directly accessing a compute server, you can run `grep avx /proc/cpuinfo | wc - l`. If the result is `0`, the AVX instructions are not available and you should use a newer machine, such as klein, fargo, quesnay, or sargan.",
    "crumbs": [
      "Home",
      "Software",
      "Tensorflow"
    ]
  },
  {
    "objectID": "tape-backups.html",
    "href": "tape-backups.html",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "Weekly filesystem snapshots are performed on Sunday night at 10:00 pm. We keep about four weekly snapshots at a time. A weekly snapshot reflects the content of the files prior to the time of the creation of the previous monthly backup tape. Incremental changes to files can be recovered on a weekly basis from subsequent weekly backup tapes for up to five weeks.\nMonthly back-ups are performed on the first Sunday night of each month between the hours of 5:00pm and 12:00 midnight. Monthly backup tapes are retained for six months before being rotated on a new cycle. A monthly backup tape contains all user data.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Backup Schedule"
    ]
  },
  {
    "objectID": "tape-backups.html#backup-schedule",
    "href": "tape-backups.html#backup-schedule",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "Weekly filesystem snapshots are performed on Sunday night at 10:00 pm. We keep about four weekly snapshots at a time. A weekly snapshot reflects the content of the files prior to the time of the creation of the previous monthly backup tape. Incremental changes to files can be recovered on a weekly basis from subsequent weekly backup tapes for up to five weeks.\nMonthly back-ups are performed on the first Sunday night of each month between the hours of 5:00pm and 12:00 midnight. Monthly backup tapes are retained for six months before being rotated on a new cycle. A monthly backup tape contains all user data.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Backup Schedule"
    ]
  },
  {
    "objectID": "tape-backups.html#requesting-file-restoration",
    "href": "tape-backups.html#requesting-file-restoration",
    "title": "Econometrics Laboratory",
    "section": "Requesting File Restoration",
    "text": "Requesting File Restoration\nContact trouble@econ.berkeley.edu to request file restoration. You need to supply the following information:\n\nThe absolute pathnames of each file/directory you want restored, e.g. /accounts/projects/foobar, or just ~joe/pathname if you are user joe and the pathname is in your home directory.\nThe date and time they were deleted.\nThe date and time the files were last modified (very important).\n\nUsually the restorations can be done within 24 hours of the request. The files can usually be reconstructed to their state prior to the last backup which was done before they were destroyed. Since backups are done once every day, it is possible to lose whatever work was done during the previous 24 hours.\nThere is a $20 service fee (and if applicable, the cost of media) to recover files from any account that has been closed.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Backup Schedule"
    ]
  },
  {
    "objectID": "tape-backups.html#policy",
    "href": "tape-backups.html#policy",
    "title": "Econometrics Laboratory",
    "section": "Policy",
    "text": "Policy\nIn the event of a catastrophic disaster, for example, damage resulting from either an earthquake, fire, or bomb, access to the computing facilities and/or entry to Evans Hall may be prohibited on either a temporary or permanent basis. Users must be aware that the EML does not store information off-site. (outside of Evans Hall) If a user has a need for that level of protection, the user is responsible for maintaining their own backups.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Backup Schedule"
    ]
  },
  {
    "objectID": "ssh.html",
    "href": "ssh.html",
    "title": "SSH",
    "section": "",
    "text": "SSH provides a secure means to access a UNIX command-line shell on a remote computer. It also provides a way of transfering files and securing otherwise unsafe protocols.\nThe term ‘SSH’ may be used to name the secure connection protocol and the name of the primary program that implements the protocol.\n\n\n\n\n\nNewer versions of Windows 10 come with a built-in SSH client. It must be enabled.\nThe most popular SSH program for Windows is putty. The putty executable is a single file, so it can be stored wherever you find it convenient.\n\n\n\nmacOS comes with OpenSSH preinstalled. Open Terminal.app (in /Applications/Utilities/) and use SSH as you would on UNIX.\n\n\n\nLinux comes with OpenSSH preinstalled. If not, you will need to use your distribution’s software management program to install SSH.\n\n\n\nYou can visit the EML’s JupyterHub in any browser. Once you start your server you can launch New &gt; Terminal. This isn’t SSH, but it does let you access the EML in a remote terminal.\n\n\n\n\nThe most common way of logging into a remote site is with ‘ssh username@remotehost’. An alternative is ‘ssh -l username remotehost’. If your local username is the same as your remote username, you needn’t specify it on the command line, e.g. ‘ssh remotehost’.\nHere is an example login:\n$ ssh eml_user@iia.berkeley.edu\nThe authenticity of host 'iia.berkeley.edu' can't be established.\nRSA key fingerprint is xx:yy...\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added 'iia.berkeley.edu' (RSA) to the list of known hosts.\neml_user@iia.berkeley.edu's password:  \nYou have mail.\n...\nWhenever SSH connects to another computer, it receives a digital fingerprint of that computer. If you are connecting to a computer for the first time, it asks whether you want to continue, and then saves the fingerprint for the next time you want to connect. If you have connected to that computer before, it checks to make sure that the fingerprint is the same as it was the first time you connected to that machine. If the fingerprints are different, it will warn you that someone might have installed nefarious ssh software on the remote host. This is useful because bad people to break into computer seldom know the passphrase that the remote administrator used to generate the fingerprint with.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH"
    ]
  },
  {
    "objectID": "ssh.html#introduction",
    "href": "ssh.html#introduction",
    "title": "SSH",
    "section": "",
    "text": "SSH provides a secure means to access a UNIX command-line shell on a remote computer. It also provides a way of transfering files and securing otherwise unsafe protocols.\nThe term ‘SSH’ may be used to name the secure connection protocol and the name of the primary program that implements the protocol.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH"
    ]
  },
  {
    "objectID": "ssh.html#software",
    "href": "ssh.html#software",
    "title": "SSH",
    "section": "",
    "text": "Newer versions of Windows 10 come with a built-in SSH client. It must be enabled.\nThe most popular SSH program for Windows is putty. The putty executable is a single file, so it can be stored wherever you find it convenient.\n\n\n\nmacOS comes with OpenSSH preinstalled. Open Terminal.app (in /Applications/Utilities/) and use SSH as you would on UNIX.\n\n\n\nLinux comes with OpenSSH preinstalled. If not, you will need to use your distribution’s software management program to install SSH.\n\n\n\nYou can visit the EML’s JupyterHub in any browser. Once you start your server you can launch New &gt; Terminal. This isn’t SSH, but it does let you access the EML in a remote terminal.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH"
    ]
  },
  {
    "objectID": "ssh.html#basic-usage",
    "href": "ssh.html#basic-usage",
    "title": "SSH",
    "section": "",
    "text": "The most common way of logging into a remote site is with ‘ssh username@remotehost’. An alternative is ‘ssh -l username remotehost’. If your local username is the same as your remote username, you needn’t specify it on the command line, e.g. ‘ssh remotehost’.\nHere is an example login:\n$ ssh eml_user@iia.berkeley.edu\nThe authenticity of host 'iia.berkeley.edu' can't be established.\nRSA key fingerprint is xx:yy...\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added 'iia.berkeley.edu' (RSA) to the list of known hosts.\neml_user@iia.berkeley.edu's password:  \nYou have mail.\n...\nWhenever SSH connects to another computer, it receives a digital fingerprint of that computer. If you are connecting to a computer for the first time, it asks whether you want to continue, and then saves the fingerprint for the next time you want to connect. If you have connected to that computer before, it checks to make sure that the fingerprint is the same as it was the first time you connected to that machine. If the fingerprints are different, it will warn you that someone might have installed nefarious ssh software on the remote host. This is useful because bad people to break into computer seldom know the passphrase that the remote administrator used to generate the fingerprint with.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH"
    ]
  },
  {
    "objectID": "ssh-keys.html",
    "href": "ssh-keys.html",
    "title": "Manage SSH Keys",
    "section": "",
    "text": "It is possible to open an SSH connection without having to type your password everytime. Instead, you can use a passphrase in combination with SSH “key pairs”. On macOS or UNIX, you will be able to type in your passphrase once at login, and during that session, connect to different remote computers without typing in a password or passphrase each time. On Windows PCs, using the passphrase enables you to connect to different accounts or hosts in the same session seamlessly, without having to type in a password or passphrase every time.\nYou will need to create an SSH keypair to facilitate this process. One key, the private key, stays on the machine you will connect from. The other key, the public key, can be put in any account you connect to. Think of this process as leaving a real key (the public key) in a remote door. The door will only open if you have the associated private key as you approach. This is why you must keep the private key to yourself, otherwise people who have a copy of it can pass through all the doors in which you left your public key.\n\n\nNote: newer versions of Windows 10 may have native SSH clients. If you have the software already installed, see the UNIX and macOS instructions below. You can run the same commands in the Windows command prompt program.\n\n\n\n\nInstall PuTTY on your machine, and go to Start Menu &gt; PuTTY &gt; PuTTYgen.\nA new window will appear. At the bottom, for “Type of key”, choose RSA, ECDSA, or ED25519. Then click the the “Generate” button. You may need to move your mouse about in the small window area in order to generate randomness that the process requires.\nType in a unique passphrase in the Key and Confirm passphrase fields. The passphrase is used to protect your key and you will be asked for it when you connect via SSH using public key authentication.\nClick on the “Save Public Key” and “Save Private Key” buttons to save the keys.\n\n\n\n\nOnce you have generated the key pair, you will need to transfer the public key to the remote site. You can transfer the public key in any number of ways, such as by emailing it to the owner of the remote account or an administrator, or SCP or SFTP if you have access. The public key file is actually just a text file.\n\n\n\nSee the UNIX instructions for this step below as they are identical.\n\n\n\n\n\nYou can generate keys with the ‘ssh-keygen’ command:\n% ssh-keygen -t ed25519\nGenerating public/private ed25519 key pair.\nEnter file in which to save the key ($HOME/.ssh/id_ed25519):    \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again:  Your identification has been saved in $HOME/.ssh/id_ed25519.\nour public key has been saved in $HOME/.ssh/id_ed25519.pub.\n \n\n\n\nOnce you have generated the key pair, you will need to transfer the public key, e.g. id_ed25519.pub, to the remote site. You can transfer the public key in any number of ways, such as FTP, SFTP, or even by email as an attachment. The public key file is actually just a text file. Upload the file to anyplace in the top-level of your home directory.\nTo transfer the file to the remote machine using SCP, execute:\nscp ~/.ssh/id_ed25519.pub username@remotehost:mynewkey.pub\n\n\n\nAppend the public key to ~/.ssh/authorized_keys on the remote machine. SSH to that computer and run:\n$ cat ~/mynewkey.pub &gt;&gt; ~/.ssh/authorized_keys\n$ rm ~/mynewkey.pub",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Manage SSH Keys"
    ]
  },
  {
    "objectID": "ssh-keys.html#on-windows",
    "href": "ssh-keys.html#on-windows",
    "title": "Manage SSH Keys",
    "section": "",
    "text": "Note: newer versions of Windows 10 may have native SSH clients. If you have the software already installed, see the UNIX and macOS instructions below. You can run the same commands in the Windows command prompt program.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Manage SSH Keys"
    ]
  },
  {
    "objectID": "ssh-keys.html#creating-the-key-pair",
    "href": "ssh-keys.html#creating-the-key-pair",
    "title": "Manage SSH Keys",
    "section": "",
    "text": "Install PuTTY on your machine, and go to Start Menu &gt; PuTTY &gt; PuTTYgen.\nA new window will appear. At the bottom, for “Type of key”, choose RSA, ECDSA, or ED25519. Then click the the “Generate” button. You may need to move your mouse about in the small window area in order to generate randomness that the process requires.\nType in a unique passphrase in the Key and Confirm passphrase fields. The passphrase is used to protect your key and you will be asked for it when you connect via SSH using public key authentication.\nClick on the “Save Public Key” and “Save Private Key” buttons to save the keys.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Manage SSH Keys"
    ]
  },
  {
    "objectID": "ssh-keys.html#uploading-the-public-key",
    "href": "ssh-keys.html#uploading-the-public-key",
    "title": "Manage SSH Keys",
    "section": "",
    "text": "Once you have generated the key pair, you will need to transfer the public key to the remote site. You can transfer the public key in any number of ways, such as by emailing it to the owner of the remote account or an administrator, or SCP or SFTP if you have access. The public key file is actually just a text file.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Manage SSH Keys"
    ]
  },
  {
    "objectID": "ssh-keys.html#installing-the-public-key",
    "href": "ssh-keys.html#installing-the-public-key",
    "title": "Manage SSH Keys",
    "section": "",
    "text": "See the UNIX instructions for this step below as they are identical.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Manage SSH Keys"
    ]
  },
  {
    "objectID": "ssh-keys.html#on-unix-and-macos",
    "href": "ssh-keys.html#on-unix-and-macos",
    "title": "Manage SSH Keys",
    "section": "",
    "text": "You can generate keys with the ‘ssh-keygen’ command:\n% ssh-keygen -t ed25519\nGenerating public/private ed25519 key pair.\nEnter file in which to save the key ($HOME/.ssh/id_ed25519):    \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again:  Your identification has been saved in $HOME/.ssh/id_ed25519.\nour public key has been saved in $HOME/.ssh/id_ed25519.pub.\n \n\n\n\nOnce you have generated the key pair, you will need to transfer the public key, e.g. id_ed25519.pub, to the remote site. You can transfer the public key in any number of ways, such as FTP, SFTP, or even by email as an attachment. The public key file is actually just a text file. Upload the file to anyplace in the top-level of your home directory.\nTo transfer the file to the remote machine using SCP, execute:\nscp ~/.ssh/id_ed25519.pub username@remotehost:mynewkey.pub\n\n\n\nAppend the public key to ~/.ssh/authorized_keys on the remote machine. SSH to that computer and run:\n$ cat ~/mynewkey.pub &gt;&gt; ~/.ssh/authorized_keys\n$ rm ~/mynewkey.pub",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Manage SSH Keys"
    ]
  },
  {
    "objectID": "site.html",
    "href": "site.html",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "Accounts Disk Space, Printing, Duration\nServices available at EML\nSoftware\nHardware\nCopyright Information\nSecurity Policies\nEligibility Policy\nFacility Rules\nGeneral Rules\nHistory of EML\nAbout EML\nRemote Access to EML\nEML Data\nContact\nSetting up an Account\nAccount Rules"
  },
  {
    "objectID": "site.html#site-index",
    "href": "site.html#site-index",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "Accounts Disk Space, Printing, Duration\nServices available at EML\nSoftware\nHardware\nCopyright Information\nSecurity Policies\nEligibility Policy\nFacility Rules\nGeneral Rules\nHistory of EML\nAbout EML\nRemote Access to EML\nEML Data\nContact\nSetting up an Account\nAccount Rules"
  },
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "Services",
    "section": "",
    "text": "Compute\nFile storage\nBackups and data recovery\nDatabase\nStatistical and system applications and utilities\nPrinting\nServer room UPS and AC\n\n\n\n\n\nManagement of two computer labs (616 and 614)\nManagement of faculty workstations and printers\nImmediate response to troubleshooting requests for hardware and software applications\nEmail, phone, and in person technical support\n\n\n\n\n\nManagement of network infrastructure (105 subnet)\nFirewall\nSSH, SFTP, SCP\nGlobus\n\n\n\n\n\nComprehensive and proactive technical troubleshooting and end user consulting for the entire installed applications software base\nOpen and approachable personal application consulting (SCF/EML systems staff) and access to a professional statistical consultant (Chris Paciorek)\nCustomized online documentation\n\n\n\n\n\nSupport for widely used data analysis, statistical, database, and development software, e.g. Python, R, SQL, Matlab, Stata, Maple, Gauss, SAS, StatTransfer)\nSupport for many compilers and interpreters, C and Fortran, Perl, Python, PHP, and the Numerical Algorithms Group (NAG) library\nSupport for TeX/LaTeX\nStatistical dataset conversion\nConnectivity from personal computers, e.g. Samba, Exceed, SSH, SFTP, SCP, VNC, and RDP\n\n\n\n\n\nMaintenance of a large Library reserve collection of books and manuals for supported applications software\nHandling of sensitive data, e.g. clearances for the Bureau of Labor Statistics, Health and Retirement Survey, State of California Employment Development Department\nExtensive data archives, where datasets are cleaned and documented, and accompanied by technical references, sample programs, and sample output, e.g., CPS, CEX, Census\nData storage and backup of large datasets, both public access and restricted, for use on the production server and for webenabled downloads\n\n\n\n\n\nPersonal accounts for students, faculty and staff\nGraduate class accounts for Econ courses\nResearch project accounts that are shared by multiple users\nNo financial charges for CPU usage, file storage, or data recovery\n\n\n\n\n\nPersonal webpage hosting for faculty\nDissemination information regarding current findings on computationally intensive econometrics through conferences, symposia, short course programs, seminars and workshops funded by federal and private sector agencies."
  },
  {
    "objectID": "services.html#infrastructure",
    "href": "services.html#infrastructure",
    "title": "Services",
    "section": "",
    "text": "Compute\nFile storage\nBackups and data recovery\nDatabase\nStatistical and system applications and utilities\nPrinting\nServer room UPS and AC"
  },
  {
    "objectID": "services.html#desktop",
    "href": "services.html#desktop",
    "title": "Services",
    "section": "",
    "text": "Management of two computer labs (616 and 614)\nManagement of faculty workstations and printers\nImmediate response to troubleshooting requests for hardware and software applications\nEmail, phone, and in person technical support"
  },
  {
    "objectID": "services.html#network-and-security",
    "href": "services.html#network-and-security",
    "title": "Services",
    "section": "",
    "text": "Management of network infrastructure (105 subnet)\nFirewall\nSSH, SFTP, SCP\nGlobus"
  },
  {
    "objectID": "services.html#consulting-and-training",
    "href": "services.html#consulting-and-training",
    "title": "Services",
    "section": "",
    "text": "Comprehensive and proactive technical troubleshooting and end user consulting for the entire installed applications software base\nOpen and approachable personal application consulting (SCF/EML systems staff) and access to a professional statistical consultant (Chris Paciorek)\nCustomized online documentation"
  },
  {
    "objectID": "services.html#softwareapplication-support",
    "href": "services.html#softwareapplication-support",
    "title": "Services",
    "section": "",
    "text": "Support for widely used data analysis, statistical, database, and development software, e.g. Python, R, SQL, Matlab, Stata, Maple, Gauss, SAS, StatTransfer)\nSupport for many compilers and interpreters, C and Fortran, Perl, Python, PHP, and the Numerical Algorithms Group (NAG) library\nSupport for TeX/LaTeX\nStatistical dataset conversion\nConnectivity from personal computers, e.g. Samba, Exceed, SSH, SFTP, SCP, VNC, and RDP"
  },
  {
    "objectID": "services.html#data",
    "href": "services.html#data",
    "title": "Services",
    "section": "",
    "text": "Maintenance of a large Library reserve collection of books and manuals for supported applications software\nHandling of sensitive data, e.g. clearances for the Bureau of Labor Statistics, Health and Retirement Survey, State of California Employment Development Department\nExtensive data archives, where datasets are cleaned and documented, and accompanied by technical references, sample programs, and sample output, e.g., CPS, CEX, Census\nData storage and backup of large datasets, both public access and restricted, for use on the production server and for webenabled downloads"
  },
  {
    "objectID": "services.html#accounts",
    "href": "services.html#accounts",
    "title": "Services",
    "section": "",
    "text": "Personal accounts for students, faculty and staff\nGraduate class accounts for Econ courses\nResearch project accounts that are shared by multiple users\nNo financial charges for CPU usage, file storage, or data recovery"
  },
  {
    "objectID": "services.html#web",
    "href": "services.html#web",
    "title": "Services",
    "section": "",
    "text": "Personal webpage hosting for faculty\nDissemination information regarding current findings on computationally intensive econometrics through conferences, symposia, short course programs, seminars and workshops funded by federal and private sector agencies."
  },
  {
    "objectID": "server_rules.html",
    "href": "server_rules.html",
    "title": "Compute Server Rules",
    "section": "",
    "text": "Compute Server Rules\n\nFor jobs that will require more than 15 minutes, limit the use of resources to no more than 25% of each machine\nMonitor/check hour long jobs every 15 minutes and twice a day for jobs that take more than 4 hours.\n\nReport any problems regarding equipment or system failure to the EML (or SCF) staff by sending email to trouble@econ or by reporting the problem directly to room 643 Evans or 499 Evans. For more information or questions on the use of application packages, programming languages, libraries, or compilers, send mail to consult@econ. Questions or problems about accounts should be sent to manager@econ. In case of a machine-related emergency, there is a list of people to contact posted on the door of 450 Evans Hall (the machine room).",
    "crumbs": [
      "Home",
      "Accounts",
      "Policies and Rules",
      "Compute Server Rules"
    ]
  },
  {
    "objectID": "savio.html",
    "href": "savio.html",
    "title": "EML Condo Node at Savio",
    "section": "",
    "text": "EML Condo Node at Savio\nEML has purchased a condo node at Savio, the high-performance computational cluster managed by the Berkeley Research Computing (BRC) program. EML users may be able access to 2 compute nodes.\nIf you are interested in using this resource, please create an account at https://mybrc.brc.berkeley.edu/. Once your account is created and you’ve signed the cluster user access agreement, from the welcome page, click on “Join” next to 2. Create or join a project. Look for co_econ and click “Join” next to it. You will receive notificaiton when your request has been approved.\nInstructions on how to access the SAVIO cluster, hardware details, filesystems, job scheduler all are available at this user guide. Instructions on how to submit jobs to your condo are also available on this page.",
    "crumbs": [
      "Home",
      "Cluster",
      "EML Condo Node at Savio"
    ]
  },
  {
    "objectID": "rules-policies.html",
    "href": "rules-policies.html",
    "title": "Rules and Policies",
    "section": "",
    "text": "Rules and Policies\nDo not share account information with any other individual. Any user who is identified as having logged in to another user’s account will have his or her account closed immediately. If such access was freely granted, then both parties will have their accounts closed. Such activity may also result in further disciplinary action. Note that\n\nEach individual is responsible for ALL activity associated with his or her account.\nDO NOT log into your own account from another user’s account, and do not permit another user to log into your account.\nSend mail to “manager” immediately if you suspect that someone has gained access to your account.\n\nInitial login to your Econometrics Laboratory account certifies that you understand and agree to (a) publication of your email address as directory information, and (b) comply with university policies governing email, campus online activities policy, and appropriate use of university computer facilities.\nAbuse of any computer account by an individual within the EML system or abuse of any other computer system may lead to termination of the individual’s EML account and permanent suspension of ALL EML privileges.\nAbuse of an account includes, but is not limited to:\n\nUnauthorized attempts to access accounts, files, or system resources.\nMalicious mischief of any sort, including using a computer account that you are not authorized to use.\nObtaining a password for a computer account without the consent of the account owner.\nUsing the campus network to gain unauthorized access to any computer systems anywhere.\nKnowingly performing an act that will interfere with the normal operation of computers, terminals, peripherals, or networks.\nKnowingly running or installing on any computer system or network, or giving to another user, a program intended to damage or to place excessive load on a computer system or network. this includes but is not limited to programs known as computer viruses, Trojan horses, and worms.\nAttempting to circumvent data protection schemes or uncover security loopholes.\nViolating terms of applicable software licensing agreements or copyright laws.\nWasting system resources, such as playing games or broadcasting “chain” letters.\nMasking the identity of an account or machine.\nAny activity originating from an EML account (on any computer system) that results in an official complaint being logged against the user, such as broadcasting “for sale” or “want ad” messages to multiple departmental mailling lists (known as “spam”). Note that your account will be quickly and permanently revoked if you spam multiple departmental mailing lists that result in one or more complaints.\nUnsolicited electronic communication with an individual who is not known to the user; using electronic mail to harass others.\nUse of an EML account for commercial or personal benefit or financial gain.\nPosting on electronic bulletin boards materials that violate existing laws or the University’s codes of conduct.\nAttempting to monitor or tamper with another user’s electronic communications, or reading, copying, changing, or deleting another user’s files or software without the explicit agreement of the owner.\nFailure to cooperate with requests of the system staff regarding use of the system resources. System staff include all Statistical Computing Facility staff as well as all Econometrics Laboratory staff.\nRepeated failure to follow posted rules.\nActivities will not be considered misuse when authorized by appropriate University officials for security or performance testing.",
    "crumbs": [
      "Home",
      "Accounts",
      "Policies and Rules",
      "Rules and Policies"
    ]
  },
  {
    "objectID": "remote.html",
    "href": "remote.html",
    "title": "Remote Access to the EML Systems",
    "section": "",
    "text": "The EML consist of multi-user, macOS and Linux systems that may be accessed remotely using either your browser (via the EML JupyterHub) or a program which uses the secure shell (SSH) protocol. This encrypts your data as it is transmitted over the network.\n\n\nEML’s JupyterHub is deployed for users to remotely run Jupyter notebooks (using Python, R, Julia, MATLAB and other languages), terminal sessions, RStudio, and even graphical Remote Desktop sessions on EML machinesthrough your web browser. See our JupyterHub documentation for more information.\n\n\n\nThe list of hostnames users can access is listed on our dashboards. Only Linux workstations and compute servers allow you to view graphics/images, use the graphical user interface of certain programs and provide desktop connections.\n\n\nCommand-line Access\nPuTTY is a free SSH client for Windows. \n\nClick on the session category\nEnter the hostname\nClick Open\nType your username and password when prompted\n\nFile Transfer using Drag and Drop\nWinSCP is a free graphical SFTP client that allows you to copy/transfer files between your windows computer and your EML account. \n\nClick on the session category\nEnter the hostname\nEnter the username and password\nClick Login\n\nNote: If it is the first time you connect to a particular EML system, the SSH program will ask you if you want to accept the new host key. Click ‘Yes’.\nUsing Graphical User Interface of Unix Applications\nXming is X Windows Software from X.Org ported to Microsoft Windows. This requires the use of an SSH client such as PuTTY. \n\nInstall and open the Xming application.\nLaunch PuTTY, click on the plus sign to the left of “SSH” in the left hand pane, then click “X11” and check the box labelled “Enable X11 Forwarding”.\nUnder “Category” on the left, click on Session. Under Saved Sessions, select a name for the session and click on “Save”.\nLog-on to one of the Linux servers (not an emily) following instructions on logging in using PuTTY\nType in the commands of the GUI program such as xstata, nautilus (file explorer), etc on PuTTY’s command-line window.\n\nRemote (Graphical) Desktop Environment Access\nWindows Remote Desktop allows remote desktop connections to the EML Linux systems. X2Go is a remote desktop solution that provides fast and secure graphical access to an EML desktop with support for copy and paste between local and remote computers.\n\n\n\n\nCommand line access and using graphical user interface applications\nFile Transfer\nRemote Desktop Access\n\n\n\n\n\nCommand line access and using graphical user interface applications\nFile Transfer\nRemote (Graphical) Desktop Environment Access"
  },
  {
    "objectID": "remote.html#jupyter-notebooks-and-other-remote-applications-via-a-browser",
    "href": "remote.html#jupyter-notebooks-and-other-remote-applications-via-a-browser",
    "title": "Remote Access to the EML Systems",
    "section": "",
    "text": "EML’s JupyterHub is deployed for users to remotely run Jupyter notebooks (using Python, R, Julia, MATLAB and other languages), terminal sessions, RStudio, and even graphical Remote Desktop sessions on EML machinesthrough your web browser. See our JupyterHub documentation for more information."
  },
  {
    "objectID": "remote.html#access-via-ssh-or-via-a-remote-desktop-application",
    "href": "remote.html#access-via-ssh-or-via-a-remote-desktop-application",
    "title": "Remote Access to the EML Systems",
    "section": "",
    "text": "The list of hostnames users can access is listed on our dashboards. Only Linux workstations and compute servers allow you to view graphics/images, use the graphical user interface of certain programs and provide desktop connections.\n\n\nCommand-line Access\nPuTTY is a free SSH client for Windows. \n\nClick on the session category\nEnter the hostname\nClick Open\nType your username and password when prompted\n\nFile Transfer using Drag and Drop\nWinSCP is a free graphical SFTP client that allows you to copy/transfer files between your windows computer and your EML account. \n\nClick on the session category\nEnter the hostname\nEnter the username and password\nClick Login\n\nNote: If it is the first time you connect to a particular EML system, the SSH program will ask you if you want to accept the new host key. Click ‘Yes’.\nUsing Graphical User Interface of Unix Applications\nXming is X Windows Software from X.Org ported to Microsoft Windows. This requires the use of an SSH client such as PuTTY. \n\nInstall and open the Xming application.\nLaunch PuTTY, click on the plus sign to the left of “SSH” in the left hand pane, then click “X11” and check the box labelled “Enable X11 Forwarding”.\nUnder “Category” on the left, click on Session. Under Saved Sessions, select a name for the session and click on “Save”.\nLog-on to one of the Linux servers (not an emily) following instructions on logging in using PuTTY\nType in the commands of the GUI program such as xstata, nautilus (file explorer), etc on PuTTY’s command-line window.\n\nRemote (Graphical) Desktop Environment Access\nWindows Remote Desktop allows remote desktop connections to the EML Linux systems. X2Go is a remote desktop solution that provides fast and secure graphical access to an EML desktop with support for copy and paste between local and remote computers.\n\n\n\n\nCommand line access and using graphical user interface applications\nFile Transfer\nRemote Desktop Access\n\n\n\n\n\nCommand line access and using graphical user interface applications\nFile Transfer\nRemote (Graphical) Desktop Environment Access"
  },
  {
    "objectID": "rclone.html",
    "href": "rclone.html",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "rclone is a command-line tool that can connect to Dropbox, Box, Google Drive, sftp servers, and a many other file services.",
    "crumbs": [
      "Home",
      "Remote Access",
      "File Transfer",
      "Using rclone"
    ]
  },
  {
    "objectID": "rclone.html#using-rclone",
    "href": "rclone.html#using-rclone",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "rclone is a command-line tool that can connect to Dropbox, Box, Google Drive, sftp servers, and a many other file services.",
    "crumbs": [
      "Home",
      "Remote Access",
      "File Transfer",
      "Using rclone"
    ]
  },
  {
    "objectID": "rclone.html#connecting-to-dropbox",
    "href": "rclone.html#connecting-to-dropbox",
    "title": "Econometrics Laboratory",
    "section": "Connecting to Dropbox",
    "text": "Connecting to Dropbox\n\nInitial Configuration\nYou only need to configure rclone for Dropbox once. These instructions assume you’ve logged in to an EML computer. In a terminal window:\n\neml:~$ rclone config\nn) New remote\ns) Set configuration password\nq) Quit config\nn/s/q&gt; n\nname&gt; dropbox\nType of storage to configure.\nChoose a number from below, or type in your own value\n...\n 7 / Dropbox\n   \\ \"dropbox\"\n...\nStorage&gt; 7\nDropbox App Client Id - leave blank normally.\nclient_id&gt;\nDropbox App Client Secret - leave blank normally.\nclient_secret&gt;\nRemote config\nUse auto config?\n * Say Y if not sure\n * Say N if you are working on a remote or headless machine\ny) Yes\nn) No\ny/n&gt; n\nFor this to work, you will need rclone available on a machine that has a web browser available.\nExecute the following on your machine:\n    rclone authorize \"dropbox\"\n\nAt this point you would run `rclone authorize dropbox` on a machine with rclone installed and which can display a web browser. For example this could be a second terminal window that you’ve opened on the EML or it could also be your own computer if you have rclone. It will open a web browser where you log into your dropbox account and permit rclone to access files. rclone will then print a long string. Copy that string and pasted it into the first terminal.\n\nresult&gt; {\"access_token\":\"abc1234...\",\"token_type\":\"bearer\",\"expiry\":\"0001-01-01T00:00:00Z\"}\n--------------------\n[dropbox]\ntype = dropbox\nclient_id =\nclient_secret =\ntoken = {\"access_token\":\"abc1234...\",\"token_type\":\"bearer\",\"expiry\":\"0001-01-01T00:00:00Z\"}\n--------------------\ny) Yes this is OK\ne) Edit this remote\nd) Delete this remote\ny/e/d&gt; y\nCurrent remotes:\nName                 Type\n====                 ====\ndropbox              dropbox\ne) Edit existing remote\nn) New remote\nd) Delete remote\nr) Rename remote\nc) Copy remote\ns) Set configuration password\nq) Quit config\ne/n/d/r/c/s/q&gt; q\n\n\n\nUsing rclone\nTest your configuration by listing the files in your Dropbox:\neml:~$ rclone ls dropbox:\n... lists your dropbox files...\nSync a file/directory to/from dropbox:\neml:~$ rclone sync dropbox:path-to-file-or-folder ~/place/i/want/to/sync/to/\neml:~$ rclone sync some/dir/on/eml dropbox:\nSince rclone sync can drastically change the contents of the destination location, you may want to append the –dry-run option to rclone at first, just to see what it would do before it does it. Then repeat without it to actually make changes.\nThere are some limitations mentioned on https://rclone.org/dropbox/:\n\nNote that Dropbox is case insensitive so you can’t have a file called “Hello.doc” and one called “hello.doc”. There are some file names such as thumbs.db which Dropbox can’t store. There is a full list of them in the “Ignored Files” section of this document. Rclone will issue an error message File name disallowed - not uploading if it attempts to upload one of those file names, but the sync won’t fail. If you have more than 10,000 files in a directory then rclone purge dropbox:dir will return the error Failed to purge: There are too many files involved in this operation. As a work-around do an rclone delete dropbox:dir followed by an rclone rmdir dropbox:dir.",
    "crumbs": [
      "Home",
      "Remote Access",
      "File Transfer",
      "Using rclone"
    ]
  },
  {
    "objectID": "python-packages.html",
    "href": "python-packages.html",
    "title": "Python Packages",
    "section": "",
    "text": "We provide Python including a variety of packages (including numpy, scipy, pandas, scikit-learn, and other computational packages) through the Anaconda distribution.\nOn our Linux servers Python 3.12 is the default as of June 2024. We also have Python 3.11 available.\n\n\nTo see what Python packages are available, invoke\nconda list\nTo install packages locally in your home directory use the --user flag to pip:\npip install --user package_to_install\nIt is possible to install packages using conda, but we don’t recommend it as conda can cause confusing interference between dependencies.\n\n\nIf you would like to override system-installed libraries, for example if you want to use a newer or older version, try virtualenv, “a tool to create isolated Python environments”.\nvirtualenv --system-site-packages ~/path/for/your/env\nsource ~/path/for/your/env/bin/activate\nAt this point you can pip install your library or do something more involved:\ngit clone https://github.com/somerepo/somelibrary.git\ncd somelibrary\npython setup.py install\n# optionally, to delete source files\ncd .. && rm -rf somelibrary\nWhen you want to escape out of this environment, run deactivate. To re-enter, run the source line as above.\nAlternatively you can use Conda to create environments:\nconda create --name myenv\nsource activate myenv\nTo escape out of this environment, run source deactivate.\n\n\n\n\nYou can use Linux environment modules to switch between different Python versions. This can be done on a one-time basis in a given terminal session or cluster submission script, or can be done in your .bashrc (after the stanza involving ~skel/std.bashrc) to set a default different than the system default.\nTo switch from Python 3.x to Python 3.y:\nmodule switch python/3.x python/3.y\nTo see what Python is being used (if nothing is listed here then the default machine Python with very few packages will be used):\nmodule list\nIf no Python is listed you can use\nmodule load python\nin this case to load the default Python.",
    "crumbs": [
      "Home",
      "Software",
      "Python Packages"
    ]
  },
  {
    "objectID": "python-packages.html#packages",
    "href": "python-packages.html#packages",
    "title": "Python Packages",
    "section": "",
    "text": "To see what Python packages are available, invoke\nconda list\nTo install packages locally in your home directory use the --user flag to pip:\npip install --user package_to_install\nIt is possible to install packages using conda, but we don’t recommend it as conda can cause confusing interference between dependencies.\n\n\nIf you would like to override system-installed libraries, for example if you want to use a newer or older version, try virtualenv, “a tool to create isolated Python environments”.\nvirtualenv --system-site-packages ~/path/for/your/env\nsource ~/path/for/your/env/bin/activate\nAt this point you can pip install your library or do something more involved:\ngit clone https://github.com/somerepo/somelibrary.git\ncd somelibrary\npython setup.py install\n# optionally, to delete source files\ncd .. && rm -rf somelibrary\nWhen you want to escape out of this environment, run deactivate. To re-enter, run the source line as above.\nAlternatively you can use Conda to create environments:\nconda create --name myenv\nsource activate myenv\nTo escape out of this environment, run source deactivate.",
    "crumbs": [
      "Home",
      "Software",
      "Python Packages"
    ]
  },
  {
    "objectID": "python-packages.html#switch-versions",
    "href": "python-packages.html#switch-versions",
    "title": "Python Packages",
    "section": "",
    "text": "You can use Linux environment modules to switch between different Python versions. This can be done on a one-time basis in a given terminal session or cluster submission script, or can be done in your .bashrc (after the stanza involving ~skel/std.bashrc) to set a default different than the system default.\nTo switch from Python 3.x to Python 3.y:\nmodule switch python/3.x python/3.y\nTo see what Python is being used (if nothing is listed here then the default machine Python with very few packages will be used):\nmodule list\nIf no Python is listed you can use\nmodule load python\nin this case to load the default Python.",
    "crumbs": [
      "Home",
      "Software",
      "Python Packages"
    ]
  },
  {
    "objectID": "passwords.html",
    "href": "passwords.html",
    "title": "Managing Passwords",
    "section": "",
    "text": "Managing Passwords\nWhenever you login, you must type both your login name and your correspondin password. Your password serves as a security check to protect your UNIX account from unauthorized users. Only people who know your password can login to your account. Therefore, it is probably a good idea to change your password on a regular basis.\nTo change your password, use the “passwd” command. The system will prompt you for your old password as well as your new one. Your old password is the one you signed on with and your new password is one of your choice. Passwords must observe the following restrictions:\n\nust be at least 6 characters. (If you use special [eg: &, ^, *, ?] or non-printing [eg: Control-T, TAB] characters, the length may be as short as four characters.)\nCannot contain all digits.\nCannot be a login name, or a login name spelled backwards.\nCannot contain any “piece” of the full-name as specified in the GECOS field, or the very “piece” spelled backwards.\nCannot exactly match any word in the dictionary if the proposed password is 6 or 7 characters; if the proposed password is exactly 8 characters, those 8 characters can not match any contiguous 8 characters of any word in the dictionary.\nCan not be a dictionary word (as in rule 5) with a leading and/or trailing digit and/or punctuation mark. For example, do not use the following:\n\ndragon1\n3dragon\n4dragon2\n!dragon\n3dragon!\n*dragon0\n\nCannot contain all lower-case letters.\n\nWhen you respond to the system’s prompts for old and new passwords, what you type will not be displayed on the screen.\nExample for a user whose login name is “joe”:\n$ passwd            \nChanging password for joe\nOld password:\nNew password:\nRetype new password:\n$ \nIf you type your old password correctly, set a legitimate new password, and retype your new password without any mistakes, UNIX will return its percent sign prompt “%”, indicating that your new password is currently in effect and the system is ready to accept subsequent UNIX commands. If you make a mistake, UNIX will return an error message and you must begin again. For more information on the passwd command, consult the UNIX manual entry passwd(1).\nOnce you set a new password, you must type this password whenever you login.\nIf you forget your password, contact the system staff to acquire a new password which will make it possible for you to login to the system.\nStudents using class accounts must ask their instructor or TA to reset their password. The system staff will not ordinarily reset class account passwords.",
    "crumbs": [
      "Home",
      "Accounts",
      "Managing Passwords"
    ]
  },
  {
    "objectID": "mount-home.html",
    "href": "mount-home.html",
    "title": "Network Volumes Access",
    "section": "",
    "text": "Network Volumes Access\nThe EML allows users to “mount” their home directories onto their personal computers so that they appear as a volume or “hard drive” on their desktop. Due to security restrictions, this is only available within the EML networks. It is possible, however, to use an SSH tunnel to secure the connection from any network address.\nConfiguring PuTTY with port forwarding\n\nStart PuTTY and create a new session or load your existing session for logging in.\nExpand the Connection-&gt;SSH menu option in the Category tree-list and select Tunnels.\nAdd a new forwarded port:\nFor the Source port, fill in the IP address of your loopback adapter, plus the port 44445 (NOT 445!). The entry field might seem to small for it, but it will work. If you have configured your loopback adapter exactly as in the previous section, then fill in\n10.255.255.1:44445.\nFor the Destination, fill in eml.berkeley.edu:445.\nClick on Add.\n\nMap the network drive\n\nStart Windows Explorer and right-click on Computer and select “Map Network Drive”\nIn the next screen, choose an available drive letter.\nType in as the Folder name: \\\\10.255.255.1_username&gt;\nCheck of Reconnect on Logon and Connect Using Different credentials\nIn the next screen, select “Use Another Account”\nFor the User name, fill in the eml_username\nFor the Password, fill in your EML samba password and press OK.\nClick on Finish to complete the network drive mapping.\n\nFor Macs\n\nDisable Windows file sharing in the Sharing section of System Preferences.\nFollow the SSH tunnel instructions, making sure to use the ports for SMB traffic.\nConnect to smb://localhost/USERNAME (via the Finder’s Go &gt; Connect to Server). For you web area, use slash www instead of slash USERNAME.\nWhen prompted, enter your EML username and your EML “PC password” (which may or may not be the same as your UNIX password).\n\nIf you have not yet set a PC password, contact manager@econ.berkeley.edu.",
    "crumbs": [
      "Home",
      "Remote Access",
      "File Transfer",
      "Network Volumes Access"
    ]
  },
  {
    "objectID": "memory.html",
    "href": "memory.html",
    "title": "Memory Management",
    "section": "",
    "text": "The EML is set up to allow multiple jobs (from one or more users) to run at the same time on each of the nodes in the EML cluster and on the standalone Linux servers. In addition we don’t require that users specify how much memory their job will need, in part because users often don’t know this (or don’t know in advance of running the job). This sharing of machines without limiting memory usage by jobs allows more jobs to run, but it can mean that if multiple jobs that use a lot of memory end up on the same machine, a job can fail because it runs out of memory. This can occur even for jobs that don’t use a lot of memory, because of the memory use by other jobs on the same machine.\n\n\n\nUsers whose jobs die because memory is not available have a few options. First they can wait until the large-memory jobs on a machine end or they can start their job again on a different machine (see here for a list of standalone servers with their memory and here for the memory available on the cluster nodes. (Note that to avoid a particular problematic node in the cluster, you can exclude it from the nodes that your job is allowed to run on using the -x flag. For example “-x eml-sm20” to avoid the eml-sm20 node.) Second, particularly for larger memory jobs, you can request access to an entire node when submitting a cluster job by adding the flag “–exclusive” to your sbatch or srun invocation. This will prevent any other jobs from running on that node and ensure your job has access to all the memory on the node.",
    "crumbs": [
      "Home",
      "Cluster",
      "Memory Management"
    ]
  },
  {
    "objectID": "memory.html#why-might-my-job-run-out-of-memory",
    "href": "memory.html#why-might-my-job-run-out-of-memory",
    "title": "Memory Management",
    "section": "",
    "text": "The EML is set up to allow multiple jobs (from one or more users) to run at the same time on each of the nodes in the EML cluster and on the standalone Linux servers. In addition we don’t require that users specify how much memory their job will need, in part because users often don’t know this (or don’t know in advance of running the job). This sharing of machines without limiting memory usage by jobs allows more jobs to run, but it can mean that if multiple jobs that use a lot of memory end up on the same machine, a job can fail because it runs out of memory. This can occur even for jobs that don’t use a lot of memory, because of the memory use by other jobs on the same machine.",
    "crumbs": [
      "Home",
      "Cluster",
      "Memory Management"
    ]
  },
  {
    "objectID": "memory.html#how-can-i-get-my-large-memory-job-to-run",
    "href": "memory.html#how-can-i-get-my-large-memory-job-to-run",
    "title": "Memory Management",
    "section": "",
    "text": "Users whose jobs die because memory is not available have a few options. First they can wait until the large-memory jobs on a machine end or they can start their job again on a different machine (see here for a list of standalone servers with their memory and here for the memory available on the cluster nodes. (Note that to avoid a particular problematic node in the cluster, you can exclude it from the nodes that your job is allowed to run on using the -x flag. For example “-x eml-sm20” to avoid the eml-sm20 node.) Second, particularly for larger memory jobs, you can request access to an entire node when submitting a cluster job by adding the flag “–exclusive” to your sbatch or srun invocation. This will prevent any other jobs from running on that node and ensure your job has access to all the memory on the node.",
    "crumbs": [
      "Home",
      "Cluster",
      "Memory Management"
    ]
  },
  {
    "objectID": "jupyterhub.html",
    "href": "jupyterhub.html",
    "title": "JupyterHub",
    "section": "",
    "text": "EML’s JupyterHub is deployed for users to remotely run Jupyter Lab (with Python, R, MATLAB, and iTorch), terminal sessions, RStudio, VS Code, and even graphical desktop sessions on EML machines.\n\n\nBy default, your notebook will be spawned onto the first available standalone Linux server. For more processing power, choose the partition that will use the high-performance computing cluster: “low” for the low priority partition and the “high” for the high priority partition\nYou can also pass SBATCH options to your notebook and specify prologue commands that will run prior to your notebook startup.\n\n\n\nTo stop your server (and free up resources for other users), please visit the “Hub Control Panel” and choose “Stop My Server”. Note that selecting “Logout” does not free up resources for other users as it keeps your server running.\n\n\n\nSome research accounts are shared among multiple people to ease the management burden of large datasets and/or code development. SSH access to such accounts is managed through SSH keys, however our JupyterHub has a different method. If you have been authorized to use a shared account, you can specify a username of `your_username@shared_username`, and then your own password, e.g. `jane_doe@big_research`. You can request access to shared accounts through the faculty who manages the account or through manager@econ.berkeley.edu.\nUsers of shared accounts are encourage to create independent named servers within JupyterHub, as documented below.\n\n\n\nIt is possible to start up multiple servers on the cluster, analogously to how you might start up more than one job on the cluster. This is useful if you want to provide your jupyter server with different hardware resources or cluster options, or if you are sharing a research account and want to let each user run a different jupyter server.\nAfter you login, do not click Start on the Server Options page. Instead, visit the control panel at https://jupyter.econ.berkeley.edu/hub/home. You can get there by clicking the Home button at the top-left. Specify a name in the “Name your server” field, then click “Add New Server”. If you are using a shared account, consider naming the server after your own EML username or after your name. This helps the other account users to tell the servers apart. If you are working from your own account, consider naming your additional servers after your project or the cluster characteristics of your job. After naming and adding the server, you will then be prompted to specify spawning options.\nIf you have multiple named servers running, just navigate to the hub control panel by clicking the Home button at the top left, clicking File &gt; Hub Control Panel from within Lab, or by visiting https://jupyter.econ.berkeley.edu/hub/home directly. There is no hub control panel button from within RStudio. You can access, modify, or stop the servers there. Note that your default server will be available at https://jupyter.econ.berkeley.edu/user/username while your named servers will be available at https://jupyter.econ.berkeley.edu/user/username/servername/.\n\n\n\nWithin JupyterLab, click the application from the launcher. If you don’t see the launcher, click File &gt; New Launcher.",
    "crumbs": [
      "Home",
      "Remote Access",
      "JupyterHub"
    ]
  },
  {
    "objectID": "jupyterhub.html#starting-your-server",
    "href": "jupyterhub.html#starting-your-server",
    "title": "JupyterHub",
    "section": "",
    "text": "By default, your notebook will be spawned onto the first available standalone Linux server. For more processing power, choose the partition that will use the high-performance computing cluster: “low” for the low priority partition and the “high” for the high priority partition\nYou can also pass SBATCH options to your notebook and specify prologue commands that will run prior to your notebook startup.",
    "crumbs": [
      "Home",
      "Remote Access",
      "JupyterHub"
    ]
  },
  {
    "objectID": "jupyterhub.html#stopping-your-server",
    "href": "jupyterhub.html#stopping-your-server",
    "title": "JupyterHub",
    "section": "",
    "text": "To stop your server (and free up resources for other users), please visit the “Hub Control Panel” and choose “Stop My Server”. Note that selecting “Logout” does not free up resources for other users as it keeps your server running.",
    "crumbs": [
      "Home",
      "Remote Access",
      "JupyterHub"
    ]
  },
  {
    "objectID": "jupyterhub.html#shared-accounts",
    "href": "jupyterhub.html#shared-accounts",
    "title": "JupyterHub",
    "section": "",
    "text": "Some research accounts are shared among multiple people to ease the management burden of large datasets and/or code development. SSH access to such accounts is managed through SSH keys, however our JupyterHub has a different method. If you have been authorized to use a shared account, you can specify a username of `your_username@shared_username`, and then your own password, e.g. `jane_doe@big_research`. You can request access to shared accounts through the faculty who manages the account or through manager@econ.berkeley.edu.\nUsers of shared accounts are encourage to create independent named servers within JupyterHub, as documented below.",
    "crumbs": [
      "Home",
      "Remote Access",
      "JupyterHub"
    ]
  },
  {
    "objectID": "jupyterhub.html#named-servers",
    "href": "jupyterhub.html#named-servers",
    "title": "JupyterHub",
    "section": "",
    "text": "It is possible to start up multiple servers on the cluster, analogously to how you might start up more than one job on the cluster. This is useful if you want to provide your jupyter server with different hardware resources or cluster options, or if you are sharing a research account and want to let each user run a different jupyter server.\nAfter you login, do not click Start on the Server Options page. Instead, visit the control panel at https://jupyter.econ.berkeley.edu/hub/home. You can get there by clicking the Home button at the top-left. Specify a name in the “Name your server” field, then click “Add New Server”. If you are using a shared account, consider naming the server after your own EML username or after your name. This helps the other account users to tell the servers apart. If you are working from your own account, consider naming your additional servers after your project or the cluster characteristics of your job. After naming and adding the server, you will then be prompted to specify spawning options.\nIf you have multiple named servers running, just navigate to the hub control panel by clicking the Home button at the top left, clicking File &gt; Hub Control Panel from within Lab, or by visiting https://jupyter.econ.berkeley.edu/hub/home directly. There is no hub control panel button from within RStudio. You can access, modify, or stop the servers there. Note that your default server will be available at https://jupyter.econ.berkeley.edu/user/username while your named servers will be available at https://jupyter.econ.berkeley.edu/user/username/servername/.",
    "crumbs": [
      "Home",
      "Remote Access",
      "JupyterHub"
    ]
  },
  {
    "objectID": "jupyterhub.html#using-rstudio-vs-code-linux-desktop",
    "href": "jupyterhub.html#using-rstudio-vs-code-linux-desktop",
    "title": "JupyterHub",
    "section": "",
    "text": "Within JupyterLab, click the application from the launcher. If you don’t see the launcher, click File &gt; New Launcher.",
    "crumbs": [
      "Home",
      "Remote Access",
      "JupyterHub"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "Welcome to the Econometrics Laboratory (EML) at the University of California at Berkeley. The Lab is a state-of-the-art and highly service-oriented computing facility that provides extensive server services, comprehensive user support, and is committed to provide the best possible computational hardware and wide selection of statistical, mathematical and econometric software for its users.\nThe EML is a computing facility dedicated to instruction at the graduate level and research by graduate students and faculty in the Department of Economics. This work concentrates on new developments in computationally intensive econometrics.\nEML is a unit of the Institute of Business and Economic Research, located in space provided by the Department of Economics at the University of California, Berkeley."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Econometrics Laboratory",
    "section": "Getting Started",
    "text": "Getting Started\n\nGetting an EML account\nRemote Access\nCompute Cluster"
  },
  {
    "objectID": "index.html#announcements",
    "href": "index.html#announcements",
    "title": "Econometrics Laboratory",
    "section": "Announcements",
    "text": "Announcements\n\nEML has a condo node at Savio\nStata 16 is available to all EML systems\nMatlab Distributed Server is available"
  },
  {
    "objectID": "index.html#related-resources",
    "href": "index.html#related-resources",
    "title": "Econometrics Laboratory",
    "section": "Related Resources",
    "text": "Related Resources\n\nData Sources\nComputing Resources\nEconometrics Seminar"
  },
  {
    "objectID": "history.html",
    "href": "history.html",
    "title": "A Brief History of the EML",
    "section": "",
    "text": "A Brief History of the EML\nThe Econometrics Laboratory became operational in December 1991 and was formally opened on January 24, 1992. It is was originally a Unix facility dedicated to graduate student and faculty teaching and research in the Department of Economics, University of California at Berkeley. The EML emphasizes new developments in computationally intensive econometrics. During the Spring 1992 semester it was used for instruction in three graduate courses in economics with a total enrollment of over 100 students. In its first year of operation, the EML supported an average user base of approximately 75 graduate students and faculty members in addition to the graduate courses. By the end of the academic year 1994-95, the EML supported a user base of roughly 400 graduate students and faculty members, and had provided instructional support to eight graduate courses.\nIn its first phase of equipment acquisition, completed in the Spring of 1992, the EML was comprised of a Sun SPARCstation 2 fileserver with six gigabytes of disk storage, serving a SPARCstation 2 and four x-terminals in the faculty cluster, and ten SPARCstation IPXs in the student cluster. EML facilities also included an Exabyte tape drive, three DAT tape drives, two CD ROM drives, two laserprinters, and a port selector that served seven 14.4K modems.\nIn its second phase of equipment acquisition, completed in the Spring of 1995, the EML installed a Sun SPARCcenter 2000 fileserver with twenty-seven gigabytes of disk storage. Its faculty cluster was expanded to two SPARC 2, two SPARC 10, and two SPARC 20 compute servers, while its graduate student cluster was expanded to fifteen SPARCstation IPXs. The original SPARC 2 fileserver became the ELSA web server. Peripheral devices includes two additional CD ROMs, an additional laserprinter, a DAT autoloader, and an upgrade to the port selector to support PPP.\nAdditional disk packs continued to be added to the fileserver; the EML handle droughly 200GB in 1995 of disk storage; by 2000 we had two fully packed D1000 trays and roughly 400MB of disks; in 2001 we acquired an A3500 cabinet with 1 terabyte of storage.\nIn 1996 the EML acquired an UltraSPARC 3000 enterprise server. It is a dedicated compute server for programs requiring vector processing capabilities. The core of IPX workstations was upgraded and an additional network laserprinter was added. In 1997, Sun Microsystems generously donated 14 Ultra 1 workstations to replace our aging core of IPX workstations. The Lab subsequently upgraded its ethernet infrastructure to 100 mb/s. In 1998, the Lab installed a PRI line and upgraded its modem bank to 23 57.6K modems and added another network printer. The ELSA web server was upgraded to a SPARC 10 and new disk packs were installed that more than doubles its storage capacity.\nIn 2000, with a grant from Sun Microsystems, the Lab’s Ultra 1 workstations were upgraded to Ultra 5s and 10s. The web/ftp server was upgraded to an Ultra 1, and a new database server was installed. An additional 200GB of disk storage was acquired along with a new DLT tape autoloader.\nIn 2001, the EML embarked on an ambitious program. We upgraded the entire Economics Department from a shared 10 mb/s infrastructure to fully switched, 100 mb/s fast ethernet (previously, only the EML’s Suns had been upgraded to fast ethernet); expanded the “econ” domain to two subnets, and acquired a new Sun Fire 3800e fileserver. The EML also acquired an 8 kilovolt UPS for its servers.\nIn 2002, the EML received an equipment grant from the National Science Foundation, to fund acquisition of an LTO tape library and a 660 GB T3B fiber channel, RAID5-enabled disk tray for the new server. The EML now held more than 1 terabyte of disks, with the largest allocations going toward faculty research projects and graduate student dissertation research. Through a grant from Sun Microsystems, the EML also upgraded 16 Ultra 5s to Sun Blade 150s in 2002. Over the past few years, EML users have engaged in ever larger empirical research projects, and through grants from Sun, NSF, and other sources, the EML has kept pace with their computational needs.\nFrom 2005 to the present, the EML continues to add powerful compute servers, upgrade file servers to increase disk storage, and improve backup hardware to accommodate the increasing demand for large data store on fast hardware. In 2009, the EML received matching funding from the department to replace the Unix workstations in the general public lab with Apple iMacs.\nThe Laboratory continues to pursue its mission of providing outstanding computational support in econometrics and statistics to its faculty and graduate students. Creation of the EML was motivated by Professor Daniel McFadden’s vision; its implementation was accomplished through the generous financial support of the National Science Foundation, the E. Morris Cox Endowment, the College of Letters and Science, the Office of the Vice Chancellor for Research, and individual faculty associates.",
    "crumbs": [
      "Home",
      "About",
      "A Brief History of the EML"
    ]
  },
  {
    "objectID": "grafana.html",
    "href": "grafana.html",
    "title": "Grafana Dashboards",
    "section": "",
    "text": "Grafana Dashboards\nThe EML has a series of dashboards which provide an overview of the machines and their available resources. You must login with your EML account.\n\nGeneral overview\nMemory utilization\nCPU load averages\nSLURM activity\nAll general dashboards",
    "crumbs": [
      "Home",
      "Cluster",
      "Grafana Dashboards"
    ]
  },
  {
    "objectID": "file-permissions.html",
    "href": "file-permissions.html",
    "title": "File Permissions",
    "section": "",
    "text": "A file may have three types of permission: read (‘r’), write (‘w’), and execute (‘x’). Each permission may be ‘on’ or ‘off’ for each of three categories of users: the file’s owner; other people in the same group as the owner; and all others. To find out a file’s mode, or permission settings, use the command “ls -l filename”. The output will be of the form:\n-rwxr-x--x 1 owner      2300 Jul 14 14:38 filename\nThe string of 10 characters at the left shows the mode. The initial ‘-’ indicates that the file is a plain file; a ‘d’ would indicate a directory. Characters 2-4 are, respectively, ‘r’, ‘w’, or ‘x’ if the corresponding permission is turned on for the owner or ‘-’ if the permission is turned off. Characters 5-7 similarly show the permissions for the group; characters 8-10 for all others.\nTo change the mode of a file, use the chmod command. The general form is:\nchmod X@Y file1 file2 ...\nwhere X is any combination of the letters ‘u’ (for owner), ‘g’ (for group), ‘o’ (for others), ‘a’ (for all; that is, for ‘ugo’); @ is either ‘+’ to add permissions, ‘-’ to remove permissions, or ‘=’ to assign permissions absolutely; and Y is any combination of ‘r’, ‘w’, ‘x’. Examples:\nchmod u=rx file         Give the owner rx permissions, but not w\nchmod go-rwx file       Deny rwx permission for group and others\nchmod g+w file          Give write permission to the group\nchmod a+x file1 file2   Give execute permission to everybody\nchmod g+rx,o+x file     OK to combine like this with a comma\n\n\n\nThe same permission scheme applies to directories. For a directory, read permission gives the ability to list files in it via the ls command (and thus to discover what file names are); write permission gives the ability to create and delete files in it; execute permission gives the ability to access a file or subdirectory of known name (even without read permission). To find out the mode of a directory:\nls -dl dir ...  Show permissions for the named directory(ies)\nls -al dir ...  Long list of all files in named directory(ies) (including those with names starting in '.')\nIf no directories are specified, the listing is for all files in the current directory. The output will look something like:\ndrwx------12 perito      592 Jul 11 13:46 .\ndrwxr-xr-x24 stat       1424 Jul 10 13:07 ..\nThe initial ‘d’ in the 10-character mode string indicates that the file is a directory. The file name ‘.’ always refers to the current directory; the file name ‘..’ always refers to the parent of the current directory. Thus, this output shows the permissions for the current directory and its parent.\nFor more information, including octal specification of permissions, see “man chmod”, “man ls”, “man umask”.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "File Permissions"
    ]
  },
  {
    "objectID": "file-permissions.html#introduction",
    "href": "file-permissions.html#introduction",
    "title": "File Permissions",
    "section": "",
    "text": "A file may have three types of permission: read (‘r’), write (‘w’), and execute (‘x’). Each permission may be ‘on’ or ‘off’ for each of three categories of users: the file’s owner; other people in the same group as the owner; and all others. To find out a file’s mode, or permission settings, use the command “ls -l filename”. The output will be of the form:\n-rwxr-x--x 1 owner      2300 Jul 14 14:38 filename\nThe string of 10 characters at the left shows the mode. The initial ‘-’ indicates that the file is a plain file; a ‘d’ would indicate a directory. Characters 2-4 are, respectively, ‘r’, ‘w’, or ‘x’ if the corresponding permission is turned on for the owner or ‘-’ if the permission is turned off. Characters 5-7 similarly show the permissions for the group; characters 8-10 for all others.\nTo change the mode of a file, use the chmod command. The general form is:\nchmod X@Y file1 file2 ...\nwhere X is any combination of the letters ‘u’ (for owner), ‘g’ (for group), ‘o’ (for others), ‘a’ (for all; that is, for ‘ugo’); @ is either ‘+’ to add permissions, ‘-’ to remove permissions, or ‘=’ to assign permissions absolutely; and Y is any combination of ‘r’, ‘w’, ‘x’. Examples:\nchmod u=rx file         Give the owner rx permissions, but not w\nchmod go-rwx file       Deny rwx permission for group and others\nchmod g+w file          Give write permission to the group\nchmod a+x file1 file2   Give execute permission to everybody\nchmod g+rx,o+x file     OK to combine like this with a comma",
    "crumbs": [
      "Home",
      "Data and Storage",
      "File Permissions"
    ]
  },
  {
    "objectID": "file-permissions.html#directories",
    "href": "file-permissions.html#directories",
    "title": "File Permissions",
    "section": "",
    "text": "The same permission scheme applies to directories. For a directory, read permission gives the ability to list files in it via the ls command (and thus to discover what file names are); write permission gives the ability to create and delete files in it; execute permission gives the ability to access a file or subdirectory of known name (even without read permission). To find out the mode of a directory:\nls -dl dir ...  Show permissions for the named directory(ies)\nls -al dir ...  Long list of all files in named directory(ies) (including those with names starting in '.')\nIf no directories are specified, the listing is for all files in the current directory. The output will look something like:\ndrwx------12 perito      592 Jul 11 13:46 .\ndrwxr-xr-x24 stat       1424 Jul 10 13:07 ..\nThe initial ‘d’ in the 10-character mode string indicates that the file is a directory. The file name ‘.’ always refers to the current directory; the file name ‘..’ always refers to the parent of the current directory. Thus, this output shows the permissions for the current directory and its parent.\nFor more information, including octal specification of permissions, see “man chmod”, “man ls”, “man umask”.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "File Permissions"
    ]
  },
  {
    "objectID": "emldata.html",
    "href": "emldata.html",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "GENERAL REFERENCES\nCalifornia Digital Library\nAmerican Economic Review (UCB only; via Ingenta Select)\nJournal of Economic Literature (UCB only’ via Ingenta Select)\nJournal of Economic Perspectives (UCB only; via Ingenta Select)\nBerkeley Electronic Press, including journals in theoretical economics, macroeconomics, and economic analysis and policy.\neScholarship Working Paper Repository (You can join the Repository and contribute your working paper series!)\nEBSCO Online\nElsevier E-Journals (UCB only; can also be accessed via the CDL)\nSpringer E-Journals (UCB only; can also be accessed via the CDL)\nWiley E-Journals (UCB only; can also be accessed via the CDL)\nEncyclopedia Britannica (UCB only)\nEncyclopedia Americana (UCB only)\nFirstSearch (UCB only; can also be accessed via the CDL)\nJSTOR (UCB only)\nUC DATA Archives\nProquest Direct (UCB only; use link on Long Library’s homepage\nScience Direct (UCB only; can also be accessed via the CDL)\nNESSTAR\nEconDoc (German libraries)\nRAND California\nCENSUS\nCensus Bureau Home Page\nCalifornia Census Research Data Center\nGovernment and Social Science Data Library\nCIESIN/SEDAC Census Archive\nICPSR\nICPSR Home Page\nPSID (web)\nAHEAD and HRS\nLABOR STATISTICS\nNLSY97 Bureau of Labor Statistics Home Page\nMost Requested Series:\nNATIONAL BUREAU OF ECONOMIC RESEARCH\nSurvey of Income and Program Participation (SIPP), including sample SAS, Stata, and SPSS programs NBER Home Page\nPenn-World Tables\nMacro History Database\nOfficial Business Cycle Dates\nManufacturing Industry Productivity\nOTHER FEDERAL GOVERNMENT SOURCES NSF’s Industrial Research and Development Information System (IRIS)\nU.S. Federal Government Statistics\n- Bureau of Economic Analysis\n- Bureau of Labor Statistics\n- Bureau of Justice Statistics\n- Bureau of Transportation Statistics\n- Bureau of the Census\n- Energy Information and Administration\n- Economic Research Service\n- Environmental Protection Agency\n- IRS Statistics of Income Division\n… and much, much more!\nFedWorld Information Network (NTIS)\nFederal Reserve Bank Data from FRED\nFederal Reserve Board’s Survey of Consumer Finances\nFederal Reserve Board’s Survey of Consumer Finances from Ohio State University\nOTHER MISCELLANEOUS SOURCES\nNielsen Scanner Data (UCB only)\nABI/Inform (UCB only; via Proquest)\nCIESIN\nDigital Dissertations (UCB only)\nEconomic Growth Resources\nIMF’s International Financial Statistics\nISI Emerging Markets\nWharton Research Data Service (WRDS; UCB only - WRDS use is restricted to UCB faculty and graduate students. Reguires a password issued by WRDS. Click on the link, choose “account request,” and if you qualify, a password will be sent by email.)\nZillow’s Assessor and Real Estate Database (ZTRAX) (UCB only)",
    "crumbs": [
      "Home",
      "Data and Storage",
      "EML Data Links"
    ]
  },
  {
    "objectID": "emldata.html#eml-data-links",
    "href": "emldata.html#eml-data-links",
    "title": "Econometrics Laboratory",
    "section": "",
    "text": "GENERAL REFERENCES\nCalifornia Digital Library\nAmerican Economic Review (UCB only; via Ingenta Select)\nJournal of Economic Literature (UCB only’ via Ingenta Select)\nJournal of Economic Perspectives (UCB only; via Ingenta Select)\nBerkeley Electronic Press, including journals in theoretical economics, macroeconomics, and economic analysis and policy.\neScholarship Working Paper Repository (You can join the Repository and contribute your working paper series!)\nEBSCO Online\nElsevier E-Journals (UCB only; can also be accessed via the CDL)\nSpringer E-Journals (UCB only; can also be accessed via the CDL)\nWiley E-Journals (UCB only; can also be accessed via the CDL)\nEncyclopedia Britannica (UCB only)\nEncyclopedia Americana (UCB only)\nFirstSearch (UCB only; can also be accessed via the CDL)\nJSTOR (UCB only)\nUC DATA Archives\nProquest Direct (UCB only; use link on Long Library’s homepage\nScience Direct (UCB only; can also be accessed via the CDL)\nNESSTAR\nEconDoc (German libraries)\nRAND California\nCENSUS\nCensus Bureau Home Page\nCalifornia Census Research Data Center\nGovernment and Social Science Data Library\nCIESIN/SEDAC Census Archive\nICPSR\nICPSR Home Page\nPSID (web)\nAHEAD and HRS\nLABOR STATISTICS\nNLSY97 Bureau of Labor Statistics Home Page\nMost Requested Series:\nNATIONAL BUREAU OF ECONOMIC RESEARCH\nSurvey of Income and Program Participation (SIPP), including sample SAS, Stata, and SPSS programs NBER Home Page\nPenn-World Tables\nMacro History Database\nOfficial Business Cycle Dates\nManufacturing Industry Productivity\nOTHER FEDERAL GOVERNMENT SOURCES NSF’s Industrial Research and Development Information System (IRIS)\nU.S. Federal Government Statistics\n- Bureau of Economic Analysis\n- Bureau of Labor Statistics\n- Bureau of Justice Statistics\n- Bureau of Transportation Statistics\n- Bureau of the Census\n- Energy Information and Administration\n- Economic Research Service\n- Environmental Protection Agency\n- IRS Statistics of Income Division\n… and much, much more!\nFedWorld Information Network (NTIS)\nFederal Reserve Bank Data from FRED\nFederal Reserve Board’s Survey of Consumer Finances\nFederal Reserve Board’s Survey of Consumer Finances from Ohio State University\nOTHER MISCELLANEOUS SOURCES\nNielsen Scanner Data (UCB only)\nABI/Inform (UCB only; via Proquest)\nCIESIN\nDigital Dissertations (UCB only)\nEconomic Growth Resources\nIMF’s International Financial Statistics\nISI Emerging Markets\nWharton Research Data Service (WRDS; UCB only - WRDS use is restricted to UCB faculty and graduate students. Reguires a password issued by WRDS. Click on the link, choose “account request,” and if you qualify, a password will be sent by email.)\nZillow’s Assessor and Real Estate Database (ZTRAX) (UCB only)",
    "crumbs": [
      "Home",
      "Data and Storage",
      "EML Data Links"
    ]
  },
  {
    "objectID": "disk-space.html",
    "href": "disk-space.html",
    "title": "Manage Disk Space",
    "section": "",
    "text": "Each user is assigned a disk space quota, or allotment, when their account is created to insure that there will be sufficient disk space for all our users’ needs. If you need additional space, please submit your request to manager@econ.berkeley.edu.\nThe commands below can show you how disk space you are consuming. For additional information, consult the respective man pages.\n\n\n\n\nbigfiles\n\n\nRecursively searches a directory for big files.\n\n\n\n\ndu -h\n\n\nRecursive summary of disk use. Gives disk use for each directory and all its subdirectories.\n\n\n\n\nls -l\n\n\nLists size of all files in the current directory.\n\n\n\n\nfind ~ -ls\n\n\nMost information: lists size of all files in all directories and subdirectories.\n\n\n\n\nquota\n\n\nReports your disk quota and current disk use.\n\n\n\n\n\n\n\nThere are several places where users can temporarily store data. These areas are often larger than home directories, but they are not backed up and may be removed without notice.\n\n\nFiles put in the /tmp directory are only accessible on the machine on which they were created and are automatically wiped everytime the computer is rebooted. Files may also be deleted with little or no warning if resources become scarce. However, if you need a large amount of disk space for a short amount of time, /tmp provides a solution which does not need any staff intervention. Remember that there is no guarantee that files stored in /tmp are safe. Do not use /tmp for data that that is difficult or expensive to re-create.\nNo special permissions are required to use /tmp. To reference your files using /tmp, use ‘/tmp’ as the prefix to the name of the file, for example ‘/tmp/myfile’. If you are storing more than a handful of files, reduce the clutter by using a subdirectory of /tmp named with your account name, for example ‘/tmp/username/myfile’.\nThe limit to the amount of storage a user can take up is the physical limitation of the partition. However, if /tmp is full, editors, compilers, and many other programs will not work or behave erratically. To find out how much space is available in /tmp on your system, type ‘df -k /tmp’. Do not use /tmp if less than 30% of the space is available. Remove files when they are no longer needed.\n\n\n\nThe /var/tmp directory functions similarly to /tmp, however, files are not automatically removed after the machine is rebooted. This directory does get erased, however, whenever the workstation needs to be reinstalled or reconfigured. Otherwise, the same policies that apply to /tmp apply to /var/tmp.\nThe /Users/Shared directory functions identically to /var/tmp, except it is only found on our Macintosh computers.\n\n\n\nThe /var/tmp/scratch directory exists on some workstations that have secondary disks. This directory functions similarly to /var/tmp, however, it does not get erased when the computer is reinstalled or reconfigured.\n\n\n\nDirectories under /scratch exist on the file server and can be accessed from every machine. Unlike users’ home directories, they are not backed up, but can usually accommodate larger data files. If space becomes limited we may automatically compress files or (if time permitting) ask users to either remove or archive files that are no longer needed in order to make room for other users. Files that are not actively being used should be compressed if possible.\nSend email to manager@econ.berkeley.edu to request space under /scratch.\n\n\n\n\nInfrequently accessed files may be compressed to save disk space.\ngunzip file.gz                         Uncompresses file.gz to file\ngzip file                              Compresses file to file.gz\ntar xzf file.tar.gz                    Uncompresses file.tar.gz to the contents of file.tar\ntar czf file.tar.gz file1 [file2...]   Compresses one or more files into file.tar.gz\nunzip file.zip                         Uncompresses file.zip\nzip file.zip file1 [file2...]          Compresses one or more files to file.zip\nuncompress x y ...                     Uncompresses x.Z, y.Z, ... to x, y, ...\ncompress x y file1 [file2...]          Compresses x, y, ... to x.Z, y.Z, ...\nzcat x.Z y.Z ...                       Prints the compressed file(s) to the terminal\\\nSee the UNIX manual pages for the above programs by using the ‘man’, for example ‘man gzip’.\n\n\n\nTo remove files and directories type:\nrm file         Removes 'file' provided you have write permission on it. \nrm -f file      Removes 'file' if you have write permission in the directory containing it. \nrmdir dir       Removes the empty directory 'dir'. \nrm -rf dir      Recursively remove dir including every file and subdirectory. Use with caution.\nSome applications leave behind files that may be removed without adversely affecting the program.\n\nWeb browser cache files can be removed. You can clear your browser disk cache, as well as instruct the browser to set aside less disk space to use for its cache, in the program’s Preference window, usually under ‘Advanced’.\nPostScript, .aux, and .log files produced by LaTeX can be recreated as necessary from the corresponding .tex file.\nCompiled object files, often with the suffix .o, produced by C, C++, or Fortran compilers, can usually be deleted. If need be, they can be recreated from the original programs that produced them.\nCompilers tend to create lots of big binary files such as ‘.o’ and ‘.out’ files. ‘.out’ files in particular can be quite large. If you have such files which have been unused for several days and which you don’t intend to use for several more days, they should be removed. (They can easily be recreated if you need them; see ‘help learn_fortran’ for more discussion.) The size of ‘.out’ files which you do need can be reduced somewhat by stripping them. Type:\nstrip a.out     Strips an already existing 'a.out'. \nf77 -s ...      Creates a pre-stripped '.out' file when using f77. \ncc -s ...       Similarly for cc.\nWhen programs crash, they sometimes report ‘Core dumped’ indicating that a large file called ‘core’ has been created in the program’s current working directory. A user may disable core dumps by adding “ulimit -c 0” to ~/.bashrc.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Manage Disk Space"
    ]
  },
  {
    "objectID": "disk-space.html#determining-usage",
    "href": "disk-space.html#determining-usage",
    "title": "Manage Disk Space",
    "section": "",
    "text": "Each user is assigned a disk space quota, or allotment, when their account is created to insure that there will be sufficient disk space for all our users’ needs. If you need additional space, please submit your request to manager@econ.berkeley.edu.\nThe commands below can show you how disk space you are consuming. For additional information, consult the respective man pages.\n\n\n\n\nbigfiles\n\n\nRecursively searches a directory for big files.\n\n\n\n\ndu -h\n\n\nRecursive summary of disk use. Gives disk use for each directory and all its subdirectories.\n\n\n\n\nls -l\n\n\nLists size of all files in the current directory.\n\n\n\n\nfind ~ -ls\n\n\nMost information: lists size of all files in all directories and subdirectories.\n\n\n\n\nquota\n\n\nReports your disk quota and current disk use.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Manage Disk Space"
    ]
  },
  {
    "objectID": "disk-space.html#temporary-disk-space",
    "href": "disk-space.html#temporary-disk-space",
    "title": "Manage Disk Space",
    "section": "",
    "text": "There are several places where users can temporarily store data. These areas are often larger than home directories, but they are not backed up and may be removed without notice.\n\n\nFiles put in the /tmp directory are only accessible on the machine on which they were created and are automatically wiped everytime the computer is rebooted. Files may also be deleted with little or no warning if resources become scarce. However, if you need a large amount of disk space for a short amount of time, /tmp provides a solution which does not need any staff intervention. Remember that there is no guarantee that files stored in /tmp are safe. Do not use /tmp for data that that is difficult or expensive to re-create.\nNo special permissions are required to use /tmp. To reference your files using /tmp, use ‘/tmp’ as the prefix to the name of the file, for example ‘/tmp/myfile’. If you are storing more than a handful of files, reduce the clutter by using a subdirectory of /tmp named with your account name, for example ‘/tmp/username/myfile’.\nThe limit to the amount of storage a user can take up is the physical limitation of the partition. However, if /tmp is full, editors, compilers, and many other programs will not work or behave erratically. To find out how much space is available in /tmp on your system, type ‘df -k /tmp’. Do not use /tmp if less than 30% of the space is available. Remove files when they are no longer needed.\n\n\n\nThe /var/tmp directory functions similarly to /tmp, however, files are not automatically removed after the machine is rebooted. This directory does get erased, however, whenever the workstation needs to be reinstalled or reconfigured. Otherwise, the same policies that apply to /tmp apply to /var/tmp.\nThe /Users/Shared directory functions identically to /var/tmp, except it is only found on our Macintosh computers.\n\n\n\nThe /var/tmp/scratch directory exists on some workstations that have secondary disks. This directory functions similarly to /var/tmp, however, it does not get erased when the computer is reinstalled or reconfigured.\n\n\n\nDirectories under /scratch exist on the file server and can be accessed from every machine. Unlike users’ home directories, they are not backed up, but can usually accommodate larger data files. If space becomes limited we may automatically compress files or (if time permitting) ask users to either remove or archive files that are no longer needed in order to make room for other users. Files that are not actively being used should be compressed if possible.\nSend email to manager@econ.berkeley.edu to request space under /scratch.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Manage Disk Space"
    ]
  },
  {
    "objectID": "disk-space.html#compression",
    "href": "disk-space.html#compression",
    "title": "Manage Disk Space",
    "section": "",
    "text": "Infrequently accessed files may be compressed to save disk space.\ngunzip file.gz                         Uncompresses file.gz to file\ngzip file                              Compresses file to file.gz\ntar xzf file.tar.gz                    Uncompresses file.tar.gz to the contents of file.tar\ntar czf file.tar.gz file1 [file2...]   Compresses one or more files into file.tar.gz\nunzip file.zip                         Uncompresses file.zip\nzip file.zip file1 [file2...]          Compresses one or more files to file.zip\nuncompress x y ...                     Uncompresses x.Z, y.Z, ... to x, y, ...\ncompress x y file1 [file2...]          Compresses x, y, ... to x.Z, y.Z, ...\nzcat x.Z y.Z ...                       Prints the compressed file(s) to the terminal\\\nSee the UNIX manual pages for the above programs by using the ‘man’, for example ‘man gzip’.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Manage Disk Space"
    ]
  },
  {
    "objectID": "disk-space.html#deleting-files",
    "href": "disk-space.html#deleting-files",
    "title": "Manage Disk Space",
    "section": "",
    "text": "To remove files and directories type:\nrm file         Removes 'file' provided you have write permission on it. \nrm -f file      Removes 'file' if you have write permission in the directory containing it. \nrmdir dir       Removes the empty directory 'dir'. \nrm -rf dir      Recursively remove dir including every file and subdirectory. Use with caution.\nSome applications leave behind files that may be removed without adversely affecting the program.\n\nWeb browser cache files can be removed. You can clear your browser disk cache, as well as instruct the browser to set aside less disk space to use for its cache, in the program’s Preference window, usually under ‘Advanced’.\nPostScript, .aux, and .log files produced by LaTeX can be recreated as necessary from the corresponding .tex file.\nCompiled object files, often with the suffix .o, produced by C, C++, or Fortran compilers, can usually be deleted. If need be, they can be recreated from the original programs that produced them.\nCompilers tend to create lots of big binary files such as ‘.o’ and ‘.out’ files. ‘.out’ files in particular can be quite large. If you have such files which have been unused for several days and which you don’t intend to use for several more days, they should be removed. (They can easily be recreated if you need them; see ‘help learn_fortran’ for more discussion.) The size of ‘.out’ files which you do need can be reduced somewhat by stripping them. Type:\nstrip a.out     Strips an already existing 'a.out'. \nf77 -s ...      Creates a pre-stripped '.out' file when using f77. \ncc -s ...       Similarly for cc.\nWhen programs crash, they sometimes report ‘Core dumped’ indicating that a large file called ‘core’ has been created in the program’s current working directory. A user may disable core dumps by adding “ulimit -c 0” to ~/.bashrc.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Manage Disk Space"
    ]
  },
  {
    "objectID": "copyright.html",
    "href": "copyright.html",
    "title": "Copyright Compliance Agreement",
    "section": "",
    "text": "Copyright Compliance Agreement\nAll Econometrics Laboratory (EML) users must comply with copyright law. The contents of all accounts (including all files that are owned or created by the user regardless of location) administred by the EML are subject to copyright law.\nThe copyright law (Title 17, United States Code) governs the circumstances under which computer files may be copied. All “original works of authorship” that are produced or distributed are covered by copyright law. An individual cannot store or distribute (make available), in part or in whole, any item that is protected by copyright law without the written permission of the copyright owner. Certain exceptions are permitted under the Fair Use Doctrine (Section 107 of the copyright law).\nWhen you acquire an EML user account or submit contributions to the ELSA software archive, you are agreeing to operate the EML account and to utilize the archive in compliance with all copyright laws, and in addition, you are agreeing to assume full financial responsibility for any infringement that may result from your failure to do so.",
    "crumbs": [
      "Home",
      "Accounts",
      "Policies and Rules",
      "Copyright Compliance Agreement"
    ]
  },
  {
    "objectID": "compute-servers-policy.html",
    "href": "compute-servers-policy.html",
    "title": "Compute Servers Policy",
    "section": "",
    "text": "Compute Servers Policy\nAccess to the compute server nerlove is restricted to individuals who have obtained instructions regarding the use and limitations of running jobs on the compute servers. Please contact the EML staff to register as a compute server user or to schedule access to additional resources on the EML compute servers. Only individuals who have registered as a compute server are allowed to use the compute servers. When registering, users will need to identify the computational resources required for their work and their ability to monitor the status of those jobs. User names will be added to a mailing list to be used for announcements concerning scheduling of special projects and downtimes for maintenance and repairs.\nPlease observe the following policies:\n\nAccess to the compute servers is restricted to individuals who are familiar with running batch jobs in a UNIX/Linux environment. If you are not familiar with running jobs in this way, you can contact consult@econ.berkeley.edu.\nJobs must be nice’d to a value of 19. Any job that is running on a compute server with a lower priority (without prior authorization) may be terminated.\nThe maximum number of jobs can be running on a server at any one time is equal to the number of processors. The number of CPUs on a machine can be seen on our Grafana dashboards. If you see (using top) that all CPUs are busy, do not run/start a job on that server until resources become available.\nA user should not run so many simultaneous jobs on a compute server such that other users are prevented from starting jobs due to lack of resources. This policy is intended to ensure that CPU cycles and memory are used fairly and effectively. Accommodations will be made based on availability and the current needs of the user community. Please send mail to “manager” if you need temporary or long term access to additional computing resources.\nUse the command sitehosts cserver for the list of computers whose use is restricted and covered by these rules.",
    "crumbs": [
      "Home",
      "Cluster",
      "Compute Servers Policy"
    ]
  },
  {
    "objectID": "ccluster.html",
    "href": "ccluster.html",
    "title": "EML Computing Cluster",
    "section": "",
    "text": "EML Computing Cluster\nThe Econometrics Laboratory (EML) has a high-performance computing cluster that consists of low priority partition and a high priority partition. This system allow users to work with massive data sets and easily manage long-running jobs. All software running on EML Linux machines is available on the cluster. Users can also compile programs on any EML Linux machine and then run that program on the cluster. It is managed by the SLURM queuing software. SLURM provides a standard batch queuing system through which users submit jobs to the cluster. Jobs are typically submitted to SLURM using a user-defined shell script that executes one’s application code. Interactive use is also an option. Users may also query the cluster to see job status.\nThe high priority partition has has eight nodes, divided into two sets of four nodes each. The first set has four nodes each with two 8-core CPUs. Each core has two hyperthreads, for a total of 128 processing units. Each node has 768 GB dedicated RAM. The second set has four nodes each with two 14-core CPUs. Each core has two hyperthreads, for a total of 224 processing units. Each node has 132 GB dedicated RAM. The lower priority partition has has eight nodes, each with two 16-core CPUs available for compute jobs (i.e., 32 cores per node), for a total of 256 cores. Each node has 248 GB dedicated RAM.\nWe provide documentation on how to use the EML compute cluster."
  },
  {
    "objectID": "availability.html",
    "href": "availability.html",
    "title": "Availability",
    "section": "",
    "text": "The EML is normally available 24/7. Our systems are remotely accessible during all hours.\nWe periodically perform maintenance activities which requires taking some systems offline. We also need to respond to campus Facilities events – such as power or cooling activities. In those cases we may need to take all systems down.\n\n\n\nEvery attempt will be made to schedule downtimes during off hours.\nScheduled system downtime is posted on this website and in the ssh login message. We will attempt to post the message at least 24 hours in advance. The announcement will state the date(s) and time(s) of the downtime and every attempt will be made not to exceed the posted downtime hours. Whenever possible, 10 minutes warning will be given prior to shutting the system down.\n\n\n\nAll systems will be taken down under the following circumstances:\n\nEmergency hardware or software conditions may occur, including emergency filesystem repair, which may result in unscheduled system downtime. As much advance warning as possible will be given; but at times the system must be taken down rapidly to avoid further damage to hardware or other system resources.\nIf it is transparent to all users (which in practice means that there are no users on the system and no user background jobs running) the system may be taken down (for no more than 30 minutes) without advance message of the day warning.\nThe machines usually can reboot themselves from a crash, but occasionally the system will be unavailable until a qualified person can be reached.",
    "crumbs": [
      "Home",
      "About",
      "Availability"
    ]
  },
  {
    "objectID": "availability.html#normal-hours",
    "href": "availability.html#normal-hours",
    "title": "Availability",
    "section": "",
    "text": "The EML is normally available 24/7. Our systems are remotely accessible during all hours.\nWe periodically perform maintenance activities which requires taking some systems offline. We also need to respond to campus Facilities events – such as power or cooling activities. In those cases we may need to take all systems down.",
    "crumbs": [
      "Home",
      "About",
      "Availability"
    ]
  },
  {
    "objectID": "availability.html#scheduled-downtimes",
    "href": "availability.html#scheduled-downtimes",
    "title": "Availability",
    "section": "",
    "text": "Every attempt will be made to schedule downtimes during off hours.\nScheduled system downtime is posted on this website and in the ssh login message. We will attempt to post the message at least 24 hours in advance. The announcement will state the date(s) and time(s) of the downtime and every attempt will be made not to exceed the posted downtime hours. Whenever possible, 10 minutes warning will be given prior to shutting the system down.",
    "crumbs": [
      "Home",
      "About",
      "Availability"
    ]
  },
  {
    "objectID": "availability.html#unscheduled-downtimes",
    "href": "availability.html#unscheduled-downtimes",
    "title": "Availability",
    "section": "",
    "text": "All systems will be taken down under the following circumstances:\n\nEmergency hardware or software conditions may occur, including emergency filesystem repair, which may result in unscheduled system downtime. As much advance warning as possible will be given; but at times the system must be taken down rapidly to avoid further damage to hardware or other system resources.\nIf it is transparent to all users (which in practice means that there are no users on the system and no user background jobs running) the system may be taken down (for no more than 30 minutes) without advance message of the day warning.\nThe machines usually can reboot themselves from a crash, but occasionally the system will be unavailable until a qualified person can be reached.",
    "crumbs": [
      "Home",
      "About",
      "Availability"
    ]
  },
  {
    "objectID": "account-types.html",
    "href": "account-types.html",
    "title": "Account Types",
    "section": "",
    "text": "Account Types\nComputer accounts are issued to individuals in the following categories:\n\nClass accounts: Economics courses which require computer access may obtain class accounts. Class accounts are assigned to individual students by the course instructor or TA. Course instructors should contact the EML Manager in room 643 Evans. Please allow 2 weeks for class accounts to be added to the system.\nDepartmental accounts: Currently registered students (undergraduates or graduates) and faculty in the Economics Departments, and employees of the Economics Department.\nCampus student accounts: Currently registered students (undergraduates or graduates) from other UC departments with a demonstrated need for specific EML services (such as statistical packages). This type of account cannot be used for work that is funded by either grants and/or outside funds. This type of account requires faculty approval and must be renewed each semester.\nCampus staff accounts: Currently active UC staff employees from other UC departments with a demonstrated need for specific EML services (such as statistical packages). This type of account cannot be used for work that is funded by either grants and/or outside funds and must be renewed annually.\nResearch accounts: Persons working within the UC system on specific research projects which are funded by grants and/or outside funds.\nOfficial guests (visiting faculty) and visitors (associate research fellows) in the Department, at the invitation (and with the approval) of faculty.\nAlumni accounts: Past students of the Economics Department. The alumni category also includes past employees of the Economics Department. This type of account is issued to individuals who have left the Department in good standing and is only valid for one year after separation from the Department. It may not be renewed. If one of the above relationships with the Department resumes, then a new account may be issued, but the alumni account is terminated after one year. The alumni account only provides for up to 5MB under the home directory. It will be necessary to obtain a contrator account if additional resources are required.\nContractor accounts: An individual may obtain an account on a recharge basis. The person will be billed monthly for the use of system resources (login time, cpu time, disk usage, and printing). Any person who does not fall into one of the above categories may apply for a contractor account. This type of account is valid indefinitely, as long as the account is in good standing.",
    "crumbs": [
      "Home",
      "Accounts",
      "Account Types"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "The Econometrics Laboratory",
    "section": "",
    "text": "The Econometrics Laboratory\nThe Econometrics Laboratory (EML) is a computing facility dedicated to instruction at the graduate level and research by graduate students and faculty in the Department of Economics. This work concentrates on new developments in computationally intensive econometrics.\nEML is a unit of the Institute of Business and Economic Research, located in space provided by the Department of Economics at the University of California, Berkeley.\nThe Laboratory’s Director is David Card. He is the Class of 1950 Professor of Economics and the Director for the Center for Labor Economics at the University of California, Berkeley. He is also the Director of the Labor Studies Program at the National Bureau of Economic Research."
  },
  {
    "objectID": "accounts.html",
    "href": "accounts.html",
    "title": "Accounts",
    "section": "",
    "text": "Fill in the EML application form\n\nThose with Calnet ID\nThose without Calnet ID\nResearch Project Account\n\nRead the EML rules, the UC Berkeley computer use policies, and all accompanying guidelines that accompany the application form.\nObtain a faculty signature (if you are a graduate student), or a principal investigator’s signature for research project accounts, and the EML manager’s signature (643 Evans Hall).\nSign the project account application form stating that you have read the rules, you understand them, and you will comply with them.\nTake the project account application form to 643 Evans to establish your login name and your password.\nYou will receive an e-mail confirming your account has been set up.\n\n\n\nThe allocation of disk space on all accounts is controlled by disk quotas. Below are the default allocations for home directories:\n\nGraduate students: 5 GB\nFaculty: 5 GB\nStaff: 1 GB\nVisiting Faculty: 1 GB\nGuest Accounts: 1 GB\n\nMonitor your disk quota to ensure proper functioning of your account.\nIf more disk space is required, users can request additional space by providing written justification to the EML manager. It is expected that requests for increased disk allocation come after basic account maintenance: deletion of files in trash, removal of obsolete data, archiving or compressing of no longer used files, and so forth.\nAll users have access to additional temporary disk space on the EML system.\nUsers are recommended to store critical files and confidential files safely in personal accounts, and use the unix file permissions to make these files secure and private (see man chmod). Delete any old files that are no longer needed or that can be easily re-created. Compress large files. The command bigfiles will show you your biggest files when invoked in your current working directory.\n\n\n\nAccounts must be renewed according to the following schedule:\n\nClass accounts expire at the end of each semester and cannot be renewed.\nGraduate accounts for Economics students are valid as long as the individual is currently enrolled (registered)\nAlumni accounts are issued upon request to individuals who have left the Department in good standing and are valid for up to two months after separation from the Department if reasonable cause can be demonstrated. Alumni accounts cannot be renewed.\nAll other student accounts expire on January 1 and July 1 of each year and must be renewed.\nGuest accounts must be renewed each year by July 1 and require approval of the sponsoring faculty member.\nFaculty and visitor (associate research fellows) accounts expire upon termination of their appointments.\nContractor accounts are valid indefinitely, as long as the account is in good standing.\nAll other accounts expire on July 1 of each year and must be renewed.\n\nRequests for extension of an account must be received within 5 days of the account expiration date. Contact manager@econ.berkeley.edu.",
    "crumbs": [
      "Home",
      "Accounts",
      "Accounts"
    ]
  },
  {
    "objectID": "accounts.html#get-an-account",
    "href": "accounts.html#get-an-account",
    "title": "Accounts",
    "section": "",
    "text": "Fill in the EML application form\n\nThose with Calnet ID\nThose without Calnet ID\nResearch Project Account\n\nRead the EML rules, the UC Berkeley computer use policies, and all accompanying guidelines that accompany the application form.\nObtain a faculty signature (if you are a graduate student), or a principal investigator’s signature for research project accounts, and the EML manager’s signature (643 Evans Hall).\nSign the project account application form stating that you have read the rules, you understand them, and you will comply with them.\nTake the project account application form to 643 Evans to establish your login name and your password.\nYou will receive an e-mail confirming your account has been set up.",
    "crumbs": [
      "Home",
      "Accounts",
      "Accounts"
    ]
  },
  {
    "objectID": "accounts.html#initial-disk-space",
    "href": "accounts.html#initial-disk-space",
    "title": "Accounts",
    "section": "",
    "text": "The allocation of disk space on all accounts is controlled by disk quotas. Below are the default allocations for home directories:\n\nGraduate students: 5 GB\nFaculty: 5 GB\nStaff: 1 GB\nVisiting Faculty: 1 GB\nGuest Accounts: 1 GB\n\nMonitor your disk quota to ensure proper functioning of your account.\nIf more disk space is required, users can request additional space by providing written justification to the EML manager. It is expected that requests for increased disk allocation come after basic account maintenance: deletion of files in trash, removal of obsolete data, archiving or compressing of no longer used files, and so forth.\nAll users have access to additional temporary disk space on the EML system.\nUsers are recommended to store critical files and confidential files safely in personal accounts, and use the unix file permissions to make these files secure and private (see man chmod). Delete any old files that are no longer needed or that can be easily re-created. Compress large files. The command bigfiles will show you your biggest files when invoked in your current working directory.",
    "crumbs": [
      "Home",
      "Accounts",
      "Accounts"
    ]
  },
  {
    "objectID": "accounts.html#account-duration",
    "href": "accounts.html#account-duration",
    "title": "Accounts",
    "section": "",
    "text": "Accounts must be renewed according to the following schedule:\n\nClass accounts expire at the end of each semester and cannot be renewed.\nGraduate accounts for Economics students are valid as long as the individual is currently enrolled (registered)\nAlumni accounts are issued upon request to individuals who have left the Department in good standing and are valid for up to two months after separation from the Department if reasonable cause can be demonstrated. Alumni accounts cannot be renewed.\nAll other student accounts expire on January 1 and July 1 of each year and must be renewed.\nGuest accounts must be renewed each year by July 1 and require approval of the sponsoring faculty member.\nFaculty and visitor (associate research fellows) accounts expire upon termination of their appointments.\nContractor accounts are valid indefinitely, as long as the account is in good standing.\nAll other accounts expire on July 1 of each year and must be renewed.\n\nRequests for extension of an account must be received within 5 days of the account expiration date. Contact manager@econ.berkeley.edu.",
    "crumbs": [
      "Home",
      "Accounts",
      "Accounts"
    ]
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "Background Processes",
    "section": "",
    "text": "Unix has the ability to run your program in the background. This means that instead of waiting for the program to finish execution, the UNIX shell prompts you again and you can run other commands at the same time that the background process is running. To run the program myprog in background, type:\nmyprog &\nThe shell will respond with a number, its process identification number (or PID) and then return to the prompt.\nIt is also possible to leave a big job running in the background even after you logout. To keep the program myprog running in background, type:\nnohup myprog &\nFor example, to run your R job in the background from tcsh with a nice level of 19:\nnohup nice +19 R --slave &lt; infile.R &\nOr from bash:\nnohup nice -19 R --slave &lt; in.R &gt; R.out 2&gt;&1 &\nOr MATLAB from tcsh, while running it with a nice level of 19:\nnohup nice +19 matlab &lt; infile.m &gt; outfile &\n\n\n\nYou may alternatively choose to use GNU screen to run your jobs so that you can leave them running when you logout. Just invoke screen from your shell, type a space or carriage return to dismiss the startup message, then start your job. When you want to detach, type Control-a followed by Control-d. You can then exit from your terminal session. When you want to access your job again, connect to the same machine your job is running on and type screen -r.",
    "crumbs": [
      "Home",
      "Cluster",
      "Background Processes"
    ]
  },
  {
    "objectID": "background.html#bash",
    "href": "background.html#bash",
    "title": "Background Processes",
    "section": "",
    "text": "Unix has the ability to run your program in the background. This means that instead of waiting for the program to finish execution, the UNIX shell prompts you again and you can run other commands at the same time that the background process is running. To run the program myprog in background, type:\nmyprog &\nThe shell will respond with a number, its process identification number (or PID) and then return to the prompt.\nIt is also possible to leave a big job running in the background even after you logout. To keep the program myprog running in background, type:\nnohup myprog &\nFor example, to run your R job in the background from tcsh with a nice level of 19:\nnohup nice +19 R --slave &lt; infile.R &\nOr from bash:\nnohup nice -19 R --slave &lt; in.R &gt; R.out 2&gt;&1 &\nOr MATLAB from tcsh, while running it with a nice level of 19:\nnohup nice +19 matlab &lt; infile.m &gt; outfile &",
    "crumbs": [
      "Home",
      "Cluster",
      "Background Processes"
    ]
  },
  {
    "objectID": "background.html#screen",
    "href": "background.html#screen",
    "title": "Background Processes",
    "section": "",
    "text": "You may alternatively choose to use GNU screen to run your jobs so that you can leave them running when you logout. Just invoke screen from your shell, type a space or carriage return to dismiss the startup message, then start your job. When you want to detach, type Control-a followed by Control-d. You can then exit from your terminal session. When you want to access your job again, connect to the same machine your job is running on and type screen -r.",
    "crumbs": [
      "Home",
      "Cluster",
      "Background Processes"
    ]
  },
  {
    "objectID": "cluster.html",
    "href": "cluster.html",
    "title": "Using the SLURM cluster",
    "section": "",
    "text": "The EML operates a high-performance Linux-based computing cluster that uses the Slurm queueing software to manage jobs. The cluster has three partitions, which are distinct sets of nodes, with different generations of CPUs.\nThe high priority (default) partition has eight nodes, divided into two sets of four nodes.\n\neml-sm2 nodes: These nodes each have two 14-core CPUs, each core with two hyperthreads (i.e., 56 logical cores per node) available for compute jobs. Each node has 132 GB dedicated RAM\neml-sm3 nodes: These nodes each have two 8-core CPUS, each core with two hyperthreads (i.e., 32 logical cores per node) available for compute jobs. Each node has 768 GB dedicated RAM.\n\nIn the remainder of this document, we’ll refer to the processing units (the logical cores) as ‘cores’.\nThe low priority partition has eight nodes, each with 32 physical cnores per node, for a total of 256 cores. Each node has 264 GB dedicated RAM. These nodes have slower cores than the high priority partition and are intended for use when the high priority partition is busy or users have jobs that are not time-critical, thereby freeing up the high partition for other jobs.\nThe gpu partition has a single node (with 48 logical cores and 264 GB CPU RAM) that hosts an Nvidia A40 GPU.\nThe partitions are managed by the Slurm queueing software. Slurm provides a standard batch queueing system through which users submit jobs to the cluster. Jobs are submitted to Slurm using a user-defined shell script that executes one’s application code. Interactive use is also an option. Users may also query the cluster to see job status. As currently set up, the cluster is designed for processing single-core and multi-core/threaded jobs, as well as distributed memory jobs that use MPI. All software running on EML Linux machines is available on the cluster. Users can also compile programs on any EML Linux machine and then run that program on the cluster.\nBelow is more detailed information about how to use the cluster.\n\n\nThe cluster is open to a restricted set of Department of Economics faculty, grad students, project account collaborators, and visitors using their EML logon.\nCurrently users may submit jobs on the following standalone Linux servers (aka ‘submit hosts’):\nblundell, frisch, hicks, jorgensen, laffont, logit, marlowe,\nmarshall, nerlove, radner, theil\nUsers can also start JupyterHub sessions to get browser-based access to the cluster nodes.\nThe cluster has three job queues (called partitions by Slurm) called ‘high’ (the default), ‘low’, and ‘gpu’. Interactive jobs can also be run in any queue.\nOne important note about using the cluster is that your code will not be able to use any more cores than you have requested via Slurm when submitting your job (this is enforced by a Linux tool called ‘cgroups’).\nAlso note that as indicated above, the cores in the high and gpu partitions use hyperthreading. If you’d like to run multi-core jobs without hyperthreading, please contact us for work-arounds.\nAt the moment the default time limit on each job is five days run-time, but users can still request a longer limit (up to max of 28 days) with the -t flag. The scheduling software can better balance usage across multiple users when it has information about how long each job is expected to take, so if possible please indicate a time limit for your job even if it is less than five days. Feel free to be generous in this time limit to avoid having your job killed if it runs longer than expected. Also feel free to set a time limit as a round number, such as 1 hour, 4 hours, 1 day, 3 days, 10 days, and 28 days rather than trying to be more exact.\nThis table outlines the job restrictions in each partition.\n\n\n\n\n\n\n\n\n\n\nPartition\nMax. cores/user\nTime Limit\nMax. mem/job (GB)\nMax. cores/job\n\n\n\n\nhigh (default)\n352\n28 days2\n132 GB (eml-sm2 nodes) or 768 GB (eml-sm3 nodes, requested with “-C mem768g” [formerly “-C bigmem”] 4)\n56 (eml-sm2 nodes) or 32 (eml-sm3 nodes)3\n\n\nlow1\n256\n28 days2\n264 GB\n323\n\n\ngpu5\n48\n28 days\n256 GB\n48\n\n\n\n[1] See How to Submit Jobs to the Low Partition.\n[2] See Submitting Long Jobs for jobs you expect to take more than three days.\n[3] If you use software set up to use multiple nodes, you can run individual jobs on more than 56 (or 32 on the low partition) cores. See Submitting Multi-node Jobs or Submitting MPI Jobs or Submitting MATLAB Parallel Server Jobs.\n[4] See Submitting Large Memory Jobs for jobs needing more than 25 GB memory.\n[5] See Submitting GPU Jobs for jobs using the GPU.\n\n\n\n\n\nOur sister facility, the Statistical Computing Facility, has a quick start guide to submitting and monitoring jobs that is useful for EML users as well (but note that the machine names shown in the guide are the SCF machines, not EML machines; in particular make sure you ssh to an EML Linux server to submit jobs).\n\n\n\nPrepare a shell script containing the instructions you would like the system to execute. When submitted using the instructions in this section, your code should only use a single core at a time. Jobs that start additional processes will still only have access to one core. In the later sections of this document, we describe how to submit jobs that use a variety of types of parallelization to make use of multiple cores.\nFor example a simple script to run the Matlab code in the file ‘simulate.m’ would contain these lines:\n#!/bin/bash\nmatlab -nodisplay -nodesktop &lt; simulate.m &gt; simulate.out\nNote that the first line, indicating which UNIX shell to use, is required. You can specify tcsh or another shell if you prefer.\nOnce logged onto a submit host, use the sbatch command with the name of the shell script (assumed to be job.sh here) to enter a job into the queue:\ntheil:~$ sbatch job.sh\nSubmitted batch job 380\nHere the job is assigned job ID 380. Results that would normally be printed to the screen from your program will be written to a file called simulate.out per the invocation of MATLAB in the job script.\nFor Stata, if you submit a job without requesting multiple cores, it makes sense to use Stata/SE so that Stata only attempts to use a single core.\nSlurm provides a number of additional flags (input options) to control what happens; you can see the man page for sbatch for help with these. Here are some examples, placed in the job script file, where we name the job, ask for email updates and name the output and error files:\n#!/bin/bash\n#SBATCH --job-name=myAnalysisName\n#SBATCH -o myAnalysisName.out #File to which job script's standard output will be written\n#SBATCH -e myAnalysisName.err #File to which job script's standard error will be written\nmatlab -nodisplay -nodesktop -singleCompThread &lt; simulate.m &gt; simulate.out\nFor any of the sbatch flags you may choose to include them in the job script as just above, or to use the flags on the command line when you submit the job, just after you type ‘sbatch’ and before the name of the submission script, for example:\ntheil:~$ sbatch --job-name=foo --mail-user=blah@berkeley.edu job.sh\nNote that Slurm is configured such that single-core jobs will have access to a single physical core (including both hyperthreads on the machines in the high and gpu partitions), so there won’t be any contention between the two threads on a physical core. However, if you have many single-core jobs to run on the high or gpu partitions, you might improve your throughput by modifying your workflow so that you can one run job per hyperthread rather than one job per physical core. You could do this by taking advantage of parallelization strategies in R, Python, or MATLAB to distribute tasks across workers in a single job, or you could use GNU parallel or srun within sbatch.\n\n\n\nFirst, find the job-id of the job, by typing ‘squeue’ at the command line of a submit host (see the section on ‘How to Monitor Jobs’ below).\nThen use scancel to delete the job (with id 380 in this case):\ntheil:~$ scancel 380\n\n\n\nTo submit a job to the slower nodes in the low priority partition (e.g., when the default high priority partition is busy), you must include either the ‘–partition=low’ or ‘-p low’ flag. Without this flag, jobs will be run by default in the high partition. For example:\ntheil:~$ sbatch -p low job.sh\nSubmitted batch job 380\nYou can also submit interactive jobs (see next section) to the low partition, by simply adding the flag for the low partition, e.g., ‘-p low’, to the srun command.\n\n\n\nYou can work interactively on a node from the Linux shell command line by starting an interactive job (in any of the partitions). Please do not forget to close your interactive sessions when you finish your work so the cores are available to other users.\nThe syntax for requesting an interactive (bash) shell session is:\nsrun --pty /bin/bash\nThis will start a shell on one of the nodes. You can then act as you would on any EML Linux compute server. For example, you might use top to assess the status of one of your non-interactive (i.e., batch) cluster jobs. Or you might test some code before running it as a batch job. You can also transfer files to the local disk of the cluster node.\nIf you want to run a program that involves a graphical interface (requiring an X11 window), you need to add –x11=first to your srun command. So you could directly run MATLAB, e.g., on a cluster node as follows:\nsrun --pty --x11=first matlab\nor you could add the -x11=first flag when requesting an interactive shell session and then subsequently start a program that has a graphical interface.\nPlease note that you will only have access to one core in your interactive job unless you specifically request more cores. To run an interactive session in which you would like to use multiple cores, do the following (here we request 4 cores for our use):\nsrun --pty --cpus-per-task 4 /bin/bash\nNote that “-c” is a shorthand for “–cpus-per-task”. More details on jobs that use more than one core can be found below in the section on Submitting Parallel Jobs.\nTo transfer files to the local disk of a specific node, you need to request that your interactive session be started on the node of interest (in this case eml-sm10):\nsrun --pty -w eml-sm10 /bin/bash\nNote that if that specific node does not have sufficient free cores to run your job, you will need to wait until cores become available on that node before your interactive session will start. The squeue command (see below in the section on How to Monitor Jobs) will tell you on which node a given job is running.\n\n\n\nAs mentioned earlier, the default time limit on each job is five days run-time, but users can still request a longer limit (up to max of 28 days) with the -t flag, as illustrated here to request a 10-day job:\ntheil:~$ sbatch -t 10-00:00:00 job.sh\nThe scheduling software can better balance usage across multiple users when it has information about how long each job is expected to take, so if possible please indicate a time limit for your job even if it is less than three days. Feel free to be generous in this time limit to avoid having your job killed if it runs longer than expected. (For this reason, we suggest that if you expect your job to take more than three days that you may want to increase the limit relative to the five-day default.) Also feel free to set a time limit as a round number, such as 1 hour, 4 hours, 1 day, 3 days, 10 days, and 28 days rather than trying to be more exact.\nHere is an example of requesting three hours for a job:\ntheil:~$ sbatch -t 3:00:00 job.sh\n\n\n\nThe default high priority partition has some nodes with 132 GB memory and some with 768 GB of memory. If you’re submitting a job that needs a lot of memory, you should add the ‘-C mem768g’ flag (formerly ‘bigmem’) to ensure your job runs on a node with 768 GB of memory. In particular, any jobs that use more than 100 GB memory should use this flag, and we recommend that jobs using more than 25 GB memory use this flag (because having multiple such jobs, potentially from different users, could cause the nodes with 132 GB of memory to run out of memory).\ntheil:~$ sbatch -C mem768g job.sh\nYou don’t need to, and usually shouldn’t, use the ‘–mem’ flag for sbatch. In general, you’ll have access to all the memory on a node. This is true for all users, so occasionally a job will fail as mentioned above and discussed further here.\nIf you expect to need all the memory on a node or need to make sure your job does not die because of memory use by other user jobs on the node your job is running on, you can request that your job have exclusive access to a node by adding the ‘–exclusive’ flag.\n\n\n\nTo submit a job to the GPU node, you must include either the ‘–partition=gpu’ or ‘-p gpu’ flag, as well as the “–gres=gpu:1” flag. For example:\ntheil:~$ sbatch -p gpu --gres=gpu:1 job.sh\nSubmitted batch job 380\nTo use CUDA or cuDNN, you’ll need to load the ‘cuda’ or ‘cudnn’ modules. To use Tensorflow with the GPU, you’ll need to load the ‘tensorflow’ module (without loading the cuda or cudnn modules, as CUDA and cuDNN will be available to Tensorflow via a different mechanism).\n\n\n\nThe Slurm command squeue provides info on job status:\ntheil:~$ squeue\n   JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n     381      high   job.sh paciorek  R      25:28      1 eml-sm20\n     380      low    job.sh paciorek  R      25:37      1 eml-sm11\nThe following will tailor the output to include information on the number of cores (the CPUs column below) being used:\ntheil:~$ squeue -o \"%.7i %.9P %.8j %.8u %.2t %.9M %.5C %.8r %.6D %R\"\n   JOBID PARTITION     NAME     USER ST      TIME  CPUS   REASON  NODES NODELIST(REASON)\n     381      high   job.sh paciorek  R     28:00     4     None      1 eml-sm20\n     380      low    job.sh paciorek  R     28:09     4     None      1 eml-sm11 \nThe ST field indicates whether a job is running (R), failed (F), or pending (PD). The latter occurs when there are not yet enough resources on the system for your job to run.\nIf you would like to logon to the node on which your job is running in order to assess CPU or memory use, you can run an interactive job within the context of your existing job. First determine the job ID of your running job using squeue (here job 380) and insert that in the following command:\nsrun --pty --jobid=380 /bin/bash\nYou can then run ‘top’ and other such tools.\nTo see a history of your jobs (within a time range), including reasons they might have failed:\nsacct  --starttime=2021-04-01 --endtime=2021-04-30 \\\n  --format JobID,JobName,Partition,Account,AllocCPUS,State%30,ExitCode,Submit,Start,End,NodeList,MaxRSS\n\n\n\nIf you’d like to see how busy each node is (e.g., to choose what partition to submit a job to), you can run the following:\ntheil:~$ sinfo -N -o \"%8P %15N %.5a %6t %C\"\nPARTITIO NODELIST        AVAIL STATE  CPUS(A/I/O/T)\nlow*     eml-sm00           up idle   0/32/0/32\nlow*     eml-sm01           up idle   0/32/0/32\nlow*     eml-sm02           up idle   0/32/0/32\nlow*     eml-sm03           up idle   0/32/0/32\nlow*     eml-sm10           up mix    29/3/0/32\nlow*     eml-sm11           up mix    27/5/0/32\nlow*     eml-sm12           up mix    9/23/0/32\nlow*     eml-sm13           up idle   0/32/0/32\nhigh     eml-sm20           up idle   0/56/0/56\nhigh     eml-sm21           up mix    8/48/0/56\nhigh     eml-sm22           up idle   0/56/0/56\nhigh     eml-sm23           up idle   0/56/0/56 \nhigh     eml-sm30           up mix    28/4/0/32\nhigh     eml-sm31           up mix    28/4/0/32\nhigh     eml-sm32           up idle   0/32/0/32\nhigh     eml-sm33           up idle   0/32/0/32\nHere the A column indicates the number of cores used (i.e., active), I indicates the number of inactive cores, and T the total number of cores on the node.\n\n\n\nThe cluster is managed using the Slurm scheduling software. We configure Slurm to try to balance the needs of the various cluster users.\nOften there may be enough available CPU cores (aka ‘resources’) on the partition, and your job will start immediately after you submit it.\nHowever, there are various reasons a job may take a while to start. Here are some details of how the scheduler works.\n\nIf there aren’t enough resources in a given partition to run a job when it is submitted, it goes into the queue. The queue is sorted based how much CPU time you’ve used over the past few weeks, using the ‘fair share’ policy described below. Your jobs will be moved to a position in the queue below the jobs of users who have used less CPU time in recent weeks. This happens dynamically, so another user can submit a job well after you have submitted your job, and that other user’s job can be placed higher in the queue at that time and start sooner than your job. If this were not the case, imagine the situation of a user sending 100s of big jobs to the system. They get into the queue and everyone submitting after that has to wait for a long time while those jobs are run, if other jobs can’t get moved above those jobs in the queue.\nWhen a job at the top of the queue needs multiple CPU cores (or in some cases an entire node), then jobs submitted to that same partition that are lower in the queue will not start even if there are enough CPU cores available for those lower priority jobs. That’s because the scheduler is trying to accumulate resources for the higher priority job(s) and guarantee that the higher priority jobs’ start times wouldn’t be pushed back by running the lower priority jobs.\nIn some cases, if the scheduler has enough information about how long jobs will run, it will run lower-priority jobs on available resources when it can do so without affecting when a higher priority job would start. This is called backfill. It can work well on some systems but on the SCF and EML it doesn’t work all that well because we don’t require that users specify their jobs’ time limits carefully. We made that tradeoff to make the cluster more user-friendly at the expense of optimizing throughput.\n\nThe ‘fair share’ policy governs the order of jobs that are waiting in the queue for resources to become available. In particular, if two users each have a job sitting in a queue, the job that will start first will be that of the user who has made less use of the cluster recently (measured in terms of CPU time). The measurement of CPU time downweights usage over time, with a half-life of one month, so a job that ran a month ago will count half as much as a job that ran yesterday. Apart from this prioritization based on recent use, all users are treated equally.\n\n\n\nWe’ve prepared a set of shortcut commands that wrap around Slurm commands such srun, squeue, sinfo, and sacct with some commonly-used options:\n\nslogin: starts an interactive shell on a cluster node\nsnodes: prints the current usage of nodes on the cluster\nsjobs: lists running jobs on the cluster\nshist: provides information about completed (including failed) jobs\nsassoc: gives information about user access to cluster partitions\n\nFor each of these commands, you can add the -h flag to see how to use them. For example:\ntheil:~$ slogin -h\nUsages:\n'slogin' to start an interactive job\n'slogin jobid' to start a shell on the node a job is running on\n'slogin additional_arguments_to_srun' to start an interactive job with additional arguments to srun\n\n\n\n\nOne can use Slurm to submit a variety of types of parallel code. Here is a set of potentially useful templates that we expect will account for most user needs. If you have a situation that does not fall into these categories or have questions about parallel programming or submitting jobs to use more than one core, please email consult@econ.berkeley.edu.\nFor additional details, please see the SCF tutorial on the basics of parallel programming in R, Python, MATLAB and C/C++, with some additional details on doing so in the context of a Slurm job. If you’re making use of the threaded BLAS, it’s worth doing some testing to make sure that threading is giving an non-negligible speedup; see the notes above for more information.\n\n\nHere’s an example job script to use multiple threads (4 in this case) in R (or with your own openMP-based program):\n#!/bin/bash\n#SBATCH --cpus-per-task 4\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nR CMD BATCH --no-save simulate.R simulate.Rout\nThis will allow your R code to use the system’s threaded BLAS and LAPACK routines. [Note that in R you can instead use the omp_set_num_threads() function in the RhpcBLASctl package, again making use of the SLURM_CPUS_PER_TASK environment variable.]\nThe same syntax in your job script will work if you’ve compiled a C/C++/Fortran program that makes use of openMP for threading. Just replace the R CMD BATCH line with the line calling your program.\nHere’s an example job script to use multiple threads (4 in this case) in MATLAB:\n#!/bin/bash\n#SBATCH --cpus-per-task 4\nmatlab -nodesktop -nodisplay &lt; simulate.m &gt; simulate.out\nIMPORTANT: At the start of your MATLAB code file you should include this line:\nmaxNumCompThreads(str2num(getenv('SLURM_CPUS_PER_TASK')));\nHere’s an example job script to use multiple threads (4 in this case) in SAS:\n#!/bin/bash\n#SBATCH --cpus-per-task 4\nsas -threads -cpucount $SLURM_CPUS_PER_TASK\nA number of SAS procs are set to take advantage of threading, including SORT, SUMMARY, TABULATE, GLM, LOESS, and REG. SAS enables threading by default, with the default number of threads set to four. Starting SAS as above ensures that the number of threads is set to the number of cores you requested. You can check that threading is enabled from within SAS by running the following and looking for the cpucount and threads options in the printout.\nProc Options group=performance; run;\nYou can use up to eight cores with Stata/MP (limited by the EML license for Stata). IMPORTANT: Do not request more than 8 cores for a Stata job. If you request eight cores (–cpus-per-task=8) or fewer, you are all set.\nIt’s possible to explicitly set the number of processors in Stata to be the number you requested in your job submission, but that is unnecessary because Slurm will limit your job to the number of cores requested. That said, one way to do this is to hard-code the following line at the start of your Stata code (in this case assuming you requested four cores):\nset processors 4\nYou can do this in an automated fashion by first invoking Stata in your job script as:\nstata-mp -b do myStataCode.do ${SLURM_CPUS_PER_TASK}\nand then at the start of your Stata code including these two lines:\nargs ncores\nset processors `ncores'\n\n\n\nThe following example job script files pertain to jobs that need to use multiple cores on a single node that do not fall under the threading/openMP context. This is relevant for parfor in MATLAB; for IPython parallel (ipyparallel), Dask, Ray, Pool.map and pp.Server in Python; and for parallel code in R that starts multiple R process (e.g., future’s future_lapply, foreach, mclapply, parLapply).\nHere’s an example script that uses multiple cores (4 in this case):\n#!/bin/bash\n#SBATCH --cpus-per-task 4\nR CMD BATCH --no-save simulate.R simulate.Rout\nIMPORTANT: Your R, Python, or any other code won’t be able to use more cores than the number of total cores requested (4 in this case). You can use the SLURM_CPUS_PER_TASK environment variable to programmatically control this, though your software will automatically detect the number of available cores in many cases.\nThe same syntax for your job script pertains to MATLAB. When using parpool in MATLAB, you can do the following:\nparpool(str2num(getenv('SLURM_CPUS_PER_TASK')));\nIn the high (default) partition, the default maximum number of workers is 28 on the eml-sm2 nodes and 16 on the eml-sm3 nodes, while in the low partition it is also 16. To increase this (up to the maximum number of cores on a machine), run the following code before invoking parpool:\ncl = parcluster();\ncl.NumWorkers = str2num(getenv('SLURM_CPUS_PER_TASK'));\ncl.parpool(str2num(getenv('SLURM_CPUS_PER_TASK')));\nTo use more than 32 workers (i.e., 32 cores or more) (or more than 56 in the eml-sm2 nodes on the high (default) partition) in MATLAB in a parpool context (or to use cores spread across multiple nodes, which can help start your job faster when the cluster is busy), you need to use MATLAB Parallel Server, discussed below.\nTo use multiple threads per worker in MATLAB, here is an example script for four workers and two threads per worker:\n#!/bin/bash\n#SBATCH --nodes 1\n#SBATCH --ntasks 4\n#SBATCH --cpus-per-task 2\nmatlab -nodesktop -nodisplay &lt; simulate.m &gt; simulate.out\nAnd here is how to start your parpool in your MATLAB code:\ncl = parcluster();\ncl.NumThreads = str2num(getenv('SLURM_CPUS_PER_TASK'));\ncl.parpool(str2num(getenv('SLURM_NTASKS')));\nAlso note that as indicated above, the cores in the high and gpu partitions use hyperthreading, which could slow multi-core computations in some cases. If you’d like to run multi-core jobs without hyperthreading, please contact us for work-arounds.\n\n\n\nYou can run jobs that use cores across multiple nodes, but only if the software you are using is configured to execute across machines. Some examples include use of MATLAB Parallel server (discussed below); MPI-based jobs (discussed below); Python code that uses ipyparallel, Dask or Ray with workers running on multiple nodes; or R code using the future package or other multi-node-capable tools. This modality allows you to use more cores than exist on a single node or to gather free cores that are scattered across the nodes when the cluster is heavily used. To run across multiple nodes, you can simply request the total number of cores you want using the –ntasks flag. In cases where the number of cores is greater than the number available on a machine, your job will have access to multiple nodes. Depending on cluster usage, even if you request fewer cores than a machine has, your job may still access cores on multiple nodes.\n\n\n\nYou can use MPI to run jobs across multiple nodes. This modality allows you to use more cores than exist on a single node or to gather free cores that are scattered across the nodes when the cluster is heavily used.\nHere’s an example script that uses multiple processors via MPI (64 in this case):\n#!/bin/bash\n#SBATCH --ntasks 64\nmpirun -np $SLURM_NTASKS myMPIexecutable\nNote that “-n” is a shorthand for “–ntasks”.\n“myMPIexecutable” could be C/C++/Fortran code you’ve written that uses MPI, or R or Python code that makes use of MPI. More details are available here.\nTo run an MPI job with each process threaded, your job script would look like the following (here with 14 processes and two threads per process):\n#!/bin/bash\n#SBATCH --ntasks 14 --cpus-per-task 2\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nmpirun -np $SLURM_NTASKS -x OMP_NUM_THREADS myMPIexecutable\n\n\n\nMATLAB Parallel Server (formerly MATLAB DCS) allows you to run a parallel MATLAB job across multiple nodes.\nThere are two primary advantages to using MATLAB Parallel Server rather than parallelizing your MATLAB code across the cores on a single node: (1) there is no limit on the number of workers (apart from the limit on the number of cores available on the cluster), and (2) Your job may not have to wait until the number of cores requested are all available on a single node, but rather than “scavenge” available cores across multiple nodes. (But note that all cores must be within one partition.\nBy default each worker will use one core, but it’s possible to use more than one core per worker as discussed below.\nThere are two ways to use MATLAB Parallel Server.\n\n\nAs a one-time setup step (you only need to do this the first time you are using the approach), go to “Environment-&gt;Parallel-&gt;Create and Manage Cluster Profiles” in the MATLAB Desktop toolbar; this will open the Cluster Profile Manager. Then click on ‘Import’ and navigate to /usr/local/linux/MATLAB/current/toolbox/parallel/dcs.mlsettings (dcsProfile.settings in MATLAB R2022a) and click ‘Open’. Then exit out of the Cluster Profile Manager.\nTo submit a MATLAB Parallel Server job, you’ll need to specify the number of MATLAB workers (by using the -n or –ntasks flag). Unlike in the past you should NOT use the ‘-C dcs’ flag. Here’s an example job script that would use 40 cores for 40 workers (making sure to use the ‘-n’ flag when requesting the number of cores):\n#!/bin/bash\n#SBATCH -n 40\nmatlab -nodesktop -nodisplay &lt; code.m &gt; code.mout\nThen in your MATLAB code, simply invoke parpool as:\npool = parpool('dcs', str2num(getenv('SLURM_NTASKS')));\nIf you’d like to use multiple threads per worker, please set –cpus-per-task equal to the number of threads per worker you desire and then use this approach in your MATLAB code:\ncl = parcluster('dcs');\ncl.NumThreads = str2num(getenv('SLURM_CPUS_PER_TASK'));\npool = cl.parpool('dcs', str2num(getenv('SLURM_NTASKS'));  % Start a pool of multi-core workers on the EML cluster\n% execute code\ndelete(pool);   % Make sure to delete the job so the cluster resources of the Slurm job are released\nYou should also be able to use the “batch” command to execute a script or function across multiple workers as described under Option 2 below. Other uses of MATLAB parallel server functionality may also be possible.\n\n\n\nTo submit a MATLAB Parallel Server job, you’ll need to specify the number of MATLAB workers (by using the -n or –ntasks flag) and indicate that a Parallel Server job will be run (by using ‘-C dcs’). This won’t work with srun, only with sbatch. Here’s an example job script that would use 40 cores for 40 workers (making sure to use the ‘-n’ flag when requesting the number of cores):\n#!/bin/bash\n#SBATCH -n 40 -C dcs \nmatlab -nodesktop -nodisplay &lt; code.m &gt; code.mout\nThen in your MATLAB code, simply invoke parpool as:\npool = parpool(str2num(getenv('SLURM_NTASKS')));\nNote that the workers will run as the user “matlabdcs”, so if you interactively log into a node with some of the workers on it, you will see MATLAB processes running as this user if you use ‘top’ or ‘ps’.\nIf you’d like to use multiple threads per worker, please set –cpus-per-task equal to the number of threads per worker you desire and then use this appraoch in your MATLAB code:\ncl = parcluster('dcs');\ncl.NumThreads = str2num(getenv('SLURM_CPUS_PER_TASK'));\npool = cl.parpool('dcs', 20);  % Start a 20-worker pool of multi-core workers on the EML cluster\n% execute code\ndelete(pool);   % Make sure to delete the job so the cluster resources of the Slurm job are released\n\n\n\nThis option allows you to be running code within MATLAB running on a stand-alone Linux machine (not part of the EML cluster) and offload parallel execution of a portion of your code to the cluster without explicitly starting a cluster job via Slurm. Note that you simply login to an EML Linux machine and start MATLAB; you do NOT use sbatch or srun to start a cluster job under this approach.\nUnder Option 2, you can either start a pool of workers using “parpool” or you can use the “batch” command to execute code across multiple workers.\nTo start up a pool of workers (with the only limit on the number of workers being the number of cores in a given partition and the usage of cores by other users’ jobs), you’ll need to use the ‘dcs’ cluster profile.\nAs a one-time setup step (you only need to do this the first time you are using the approach), go to “Environment-&gt;Parallel-&gt;Create and Manage Cluster Profiles” in the MATLAB Desktop toolbar; this will open the Cluster Profile Manager. Then click on ‘Import’ and navigate to /usr/local/linux/MATLAB/current/toolbox/parallel/dcs.mlsettings (dcsProfile.settings in R2022a and earlier versions) and click ‘Open’. Then exit out of the Cluster Profile Manager.\nNow, whenever you want to start up a pool of workers, simply do the following (here for 40 workers):\npool = parpool('dcs', 40);  % Start a 40-worker pool on the EML cluster\n% execute code\ndelete(pool);               % Make sure to delete the job so the cluster resources of the Slurm job are released\nThis starts a Slurm job (and prints out the job ID to the screen in case you want to monitor the Slurm job). Once the pool is ready, simply execute your parallel code (such as with a parfor loop). When you are done remember to delete the pool so the cluster job ends and the resources are available to others.\nFor threaded workers, you can simply do this:\ncl = parcluster('dcs');\ncl.NumThreads = 2;      % however many threads per worker you'd like to use\npool = cl.parpool(20);  % Start a 20-worker pool of multi-core workers on the EML cluster\n% execute code\ndelete(pool);           % Make sure to delete the job so the cluster resources of the Slurm job are released\nIf you’d like to modify the flags that are used when the underlying Slurm job is submitted (e.g., to use the ‘low’ partition and set a particular time limit as shown here), you would do it like this:\ncl = parcluster('dcs');\ncl.AdditionalProperties.AdditionalSubmitArgs='-p low -t 30:00'\n% Start a 40-worker pool on EML cluster low partition, 30 min. time limit\npool = cl.parpool(40);\n% execute code\ndelete(pool);   % Make sure to delete the job so the cluster resources of the Slurm job are released\nAlternatively you can use the “batch” command to execute a script or function across multiple workers. Here is one example usage but there are a variety of others discussed in MATLAB’s online documentation for the “batch” command. Suppose you have a file ‘code.m’ that executes a parfor. To run that code on 39 workers (an additional worker will be used to manage the work, for a total of 40 workers), you would do this:\nc = parcluster('dcs');           % Sets things up to make use of MATLAB Parallel Server\nj = c.batch('code', 'Pool', 39); % Uses 40 workers total, starting a Slurm job on the EML cluster\nwait(j)                          % Wait for the job to finish\ndiary(j)                         % Display logging output\nr = fetchOutputs(j);             % Get results into a cell array\nr{1}                             % Display results\nj.delete()                       % Make sure to delete the job so the cluster resources of the Slurm job are released\n\n\n\n\n\n\n\nJob array submissions are a nice way to submit multiple jobs in which you vary a parameter across the different jobs.\nHere’s what your job script would look like, in this case to run a total of 5 jobs with parameter values of 0, 1, 2, 5, 7:\n#!/bin/bash\n#SBATCH -a 0-2,5,7\nmyExecutable\nYour program should then make use of the SLURM_ARRAY_TASK_ID environment variable, which for a given job will contain one of the values from the set given with the -a flag (in this case from {0,1,2,5,7}). You could, for example, read SLURM_ARRAY_TASK_ID into your R, Python, MATLAB, or C code.\nHere’s a concrete example where it’s sufficient to use SLURM_ARRAY_TASK_ID to distinguish different input files if you need to run the same command (the bioinformatics program tophat in this case) on multiple input files (in this case, trans0.fq, trans1.fq, …):\n#!/bin/bash\n#SBATCH -a 0-2,5,7\ntophat BowtieIndex trans${SLURM_ARRAY_TASK_ID}.fq\n\n\n\nHere’s how you would set up your job script if you want to run multiple instances (18 in this case) of the same code as part of a single job.\n#!/bin/bash\n#SBATCH --ntasks 18 \nsrun myExecutable\nTo have each instance behave differently, you can make use of the SLURM_PROCID environment variable, which will be distinct (and have values 0, 1, 2, …) between the different instances.\nTo have each process be threaded, see the syntax under the MPI section above.\n\n\n\nThe above approaches are more elegant, but you can also use UNIX shell tools to submit multiple Slurm jobs. Here are some approaches and example syntax. We’ve tested these a bit but email consult@econ.berkeley.edu if you have problems or find a better way to do this. (Of course you can also manually create lots of individual job submission scripts, each of which calls a different script.)\nFirst, remember that each individual job should be submitted through sbatch.\nHere is some example bash shell code (which could be placed in a shell script file) that loops over two variables (one numeric and the other a string):\nfor ((it = 1; it &lt;= 10; it++)); do\n  for mode in short long; do\n    sbatch job.sh $it $mode\n  done\ndone\nYou now have a couple options in terms of how job.sh is specified. This illustrates things for MATLAB jobs, but it shouldn’t be too hard to modify for other types of jobs.\n\n\n# contents of job.sh\necho \"it = $1; mode = '$2'; myMatlabCode\" &gt; tmp-$1-$2.m\nmatlab -nodesktop -nodisplay -singleCompThread &lt; tmp-$1-$2.m &gt; tmp-$1-$2.out 2&gt; tmp-$1-$2.err\nIn this case myMatlabCode.m would use the variables ‘it’ and ‘mode’ but not define them.\n\n\n\n# contents of job.sh\nexport it=$1; export mode=$2;\nmatlab -nodesktop -nodisplay -singleCompThread &lt; myMatlabCode.m &gt; tmp-$1-$2.out 2&gt; tmp-$1-$2.err\nIn this case you need to insert the following MATLAB code at the start of myMatlabCode.m so that MATLAB correctly reads the values of ‘it’ and ‘mode’ from the UNIX environment variables:\nit = str2num(getenv('it'));\nmode = getenv('mode');\nFor Stata jobs, there’s an easier mechanism for passing arguments into a batch job. Invoke Stata as follows in job.sh:\nstata -b do myStataCode.do $1 $2\nand then in the first line of your Stata code file, myStataCode.do above, assign the input values to variables (in this case I’ve named them id and mode to match the shell variables, but they can be named differently):\nargs id mode\nThen the remainder of your code can make use of these variables.",
    "crumbs": [
      "Home",
      "Cluster",
      "Using the SLURM cluster"
    ]
  },
  {
    "objectID": "cluster.html#access-and-job-restrictionstime-limits",
    "href": "cluster.html#access-and-job-restrictionstime-limits",
    "title": "Using the SLURM cluster",
    "section": "",
    "text": "The cluster is open to a restricted set of Department of Economics faculty, grad students, project account collaborators, and visitors using their EML logon.\nCurrently users may submit jobs on the following standalone Linux servers (aka ‘submit hosts’):\nblundell, frisch, hicks, jorgensen, laffont, logit, marlowe,\nmarshall, nerlove, radner, theil\nUsers can also start JupyterHub sessions to get browser-based access to the cluster nodes.\nThe cluster has three job queues (called partitions by Slurm) called ‘high’ (the default), ‘low’, and ‘gpu’. Interactive jobs can also be run in any queue.\nOne important note about using the cluster is that your code will not be able to use any more cores than you have requested via Slurm when submitting your job (this is enforced by a Linux tool called ‘cgroups’).\nAlso note that as indicated above, the cores in the high and gpu partitions use hyperthreading. If you’d like to run multi-core jobs without hyperthreading, please contact us for work-arounds.\nAt the moment the default time limit on each job is five days run-time, but users can still request a longer limit (up to max of 28 days) with the -t flag. The scheduling software can better balance usage across multiple users when it has information about how long each job is expected to take, so if possible please indicate a time limit for your job even if it is less than five days. Feel free to be generous in this time limit to avoid having your job killed if it runs longer than expected. Also feel free to set a time limit as a round number, such as 1 hour, 4 hours, 1 day, 3 days, 10 days, and 28 days rather than trying to be more exact.\nThis table outlines the job restrictions in each partition.\n\n\n\n\n\n\n\n\n\n\nPartition\nMax. cores/user\nTime Limit\nMax. mem/job (GB)\nMax. cores/job\n\n\n\n\nhigh (default)\n352\n28 days2\n132 GB (eml-sm2 nodes) or 768 GB (eml-sm3 nodes, requested with “-C mem768g” [formerly “-C bigmem”] 4)\n56 (eml-sm2 nodes) or 32 (eml-sm3 nodes)3\n\n\nlow1\n256\n28 days2\n264 GB\n323\n\n\ngpu5\n48\n28 days\n256 GB\n48\n\n\n\n[1] See How to Submit Jobs to the Low Partition.\n[2] See Submitting Long Jobs for jobs you expect to take more than three days.\n[3] If you use software set up to use multiple nodes, you can run individual jobs on more than 56 (or 32 on the low partition) cores. See Submitting Multi-node Jobs or Submitting MPI Jobs or Submitting MATLAB Parallel Server Jobs.\n[4] See Submitting Large Memory Jobs for jobs needing more than 25 GB memory.\n[5] See Submitting GPU Jobs for jobs using the GPU.",
    "crumbs": [
      "Home",
      "Cluster",
      "Using the SLURM cluster"
    ]
  },
  {
    "objectID": "cluster.html#basic-slurm-usage",
    "href": "cluster.html#basic-slurm-usage",
    "title": "Using the SLURM cluster",
    "section": "",
    "text": "Our sister facility, the Statistical Computing Facility, has a quick start guide to submitting and monitoring jobs that is useful for EML users as well (but note that the machine names shown in the guide are the SCF machines, not EML machines; in particular make sure you ssh to an EML Linux server to submit jobs).\n\n\n\nPrepare a shell script containing the instructions you would like the system to execute. When submitted using the instructions in this section, your code should only use a single core at a time. Jobs that start additional processes will still only have access to one core. In the later sections of this document, we describe how to submit jobs that use a variety of types of parallelization to make use of multiple cores.\nFor example a simple script to run the Matlab code in the file ‘simulate.m’ would contain these lines:\n#!/bin/bash\nmatlab -nodisplay -nodesktop &lt; simulate.m &gt; simulate.out\nNote that the first line, indicating which UNIX shell to use, is required. You can specify tcsh or another shell if you prefer.\nOnce logged onto a submit host, use the sbatch command with the name of the shell script (assumed to be job.sh here) to enter a job into the queue:\ntheil:~$ sbatch job.sh\nSubmitted batch job 380\nHere the job is assigned job ID 380. Results that would normally be printed to the screen from your program will be written to a file called simulate.out per the invocation of MATLAB in the job script.\nFor Stata, if you submit a job without requesting multiple cores, it makes sense to use Stata/SE so that Stata only attempts to use a single core.\nSlurm provides a number of additional flags (input options) to control what happens; you can see the man page for sbatch for help with these. Here are some examples, placed in the job script file, where we name the job, ask for email updates and name the output and error files:\n#!/bin/bash\n#SBATCH --job-name=myAnalysisName\n#SBATCH -o myAnalysisName.out #File to which job script's standard output will be written\n#SBATCH -e myAnalysisName.err #File to which job script's standard error will be written\nmatlab -nodisplay -nodesktop -singleCompThread &lt; simulate.m &gt; simulate.out\nFor any of the sbatch flags you may choose to include them in the job script as just above, or to use the flags on the command line when you submit the job, just after you type ‘sbatch’ and before the name of the submission script, for example:\ntheil:~$ sbatch --job-name=foo --mail-user=blah@berkeley.edu job.sh\nNote that Slurm is configured such that single-core jobs will have access to a single physical core (including both hyperthreads on the machines in the high and gpu partitions), so there won’t be any contention between the two threads on a physical core. However, if you have many single-core jobs to run on the high or gpu partitions, you might improve your throughput by modifying your workflow so that you can one run job per hyperthread rather than one job per physical core. You could do this by taking advantage of parallelization strategies in R, Python, or MATLAB to distribute tasks across workers in a single job, or you could use GNU parallel or srun within sbatch.\n\n\n\nFirst, find the job-id of the job, by typing ‘squeue’ at the command line of a submit host (see the section on ‘How to Monitor Jobs’ below).\nThen use scancel to delete the job (with id 380 in this case):\ntheil:~$ scancel 380\n\n\n\nTo submit a job to the slower nodes in the low priority partition (e.g., when the default high priority partition is busy), you must include either the ‘–partition=low’ or ‘-p low’ flag. Without this flag, jobs will be run by default in the high partition. For example:\ntheil:~$ sbatch -p low job.sh\nSubmitted batch job 380\nYou can also submit interactive jobs (see next section) to the low partition, by simply adding the flag for the low partition, e.g., ‘-p low’, to the srun command.\n\n\n\nYou can work interactively on a node from the Linux shell command line by starting an interactive job (in any of the partitions). Please do not forget to close your interactive sessions when you finish your work so the cores are available to other users.\nThe syntax for requesting an interactive (bash) shell session is:\nsrun --pty /bin/bash\nThis will start a shell on one of the nodes. You can then act as you would on any EML Linux compute server. For example, you might use top to assess the status of one of your non-interactive (i.e., batch) cluster jobs. Or you might test some code before running it as a batch job. You can also transfer files to the local disk of the cluster node.\nIf you want to run a program that involves a graphical interface (requiring an X11 window), you need to add –x11=first to your srun command. So you could directly run MATLAB, e.g., on a cluster node as follows:\nsrun --pty --x11=first matlab\nor you could add the -x11=first flag when requesting an interactive shell session and then subsequently start a program that has a graphical interface.\nPlease note that you will only have access to one core in your interactive job unless you specifically request more cores. To run an interactive session in which you would like to use multiple cores, do the following (here we request 4 cores for our use):\nsrun --pty --cpus-per-task 4 /bin/bash\nNote that “-c” is a shorthand for “–cpus-per-task”. More details on jobs that use more than one core can be found below in the section on Submitting Parallel Jobs.\nTo transfer files to the local disk of a specific node, you need to request that your interactive session be started on the node of interest (in this case eml-sm10):\nsrun --pty -w eml-sm10 /bin/bash\nNote that if that specific node does not have sufficient free cores to run your job, you will need to wait until cores become available on that node before your interactive session will start. The squeue command (see below in the section on How to Monitor Jobs) will tell you on which node a given job is running.\n\n\n\nAs mentioned earlier, the default time limit on each job is five days run-time, but users can still request a longer limit (up to max of 28 days) with the -t flag, as illustrated here to request a 10-day job:\ntheil:~$ sbatch -t 10-00:00:00 job.sh\nThe scheduling software can better balance usage across multiple users when it has information about how long each job is expected to take, so if possible please indicate a time limit for your job even if it is less than three days. Feel free to be generous in this time limit to avoid having your job killed if it runs longer than expected. (For this reason, we suggest that if you expect your job to take more than three days that you may want to increase the limit relative to the five-day default.) Also feel free to set a time limit as a round number, such as 1 hour, 4 hours, 1 day, 3 days, 10 days, and 28 days rather than trying to be more exact.\nHere is an example of requesting three hours for a job:\ntheil:~$ sbatch -t 3:00:00 job.sh\n\n\n\nThe default high priority partition has some nodes with 132 GB memory and some with 768 GB of memory. If you’re submitting a job that needs a lot of memory, you should add the ‘-C mem768g’ flag (formerly ‘bigmem’) to ensure your job runs on a node with 768 GB of memory. In particular, any jobs that use more than 100 GB memory should use this flag, and we recommend that jobs using more than 25 GB memory use this flag (because having multiple such jobs, potentially from different users, could cause the nodes with 132 GB of memory to run out of memory).\ntheil:~$ sbatch -C mem768g job.sh\nYou don’t need to, and usually shouldn’t, use the ‘–mem’ flag for sbatch. In general, you’ll have access to all the memory on a node. This is true for all users, so occasionally a job will fail as mentioned above and discussed further here.\nIf you expect to need all the memory on a node or need to make sure your job does not die because of memory use by other user jobs on the node your job is running on, you can request that your job have exclusive access to a node by adding the ‘–exclusive’ flag.\n\n\n\nTo submit a job to the GPU node, you must include either the ‘–partition=gpu’ or ‘-p gpu’ flag, as well as the “–gres=gpu:1” flag. For example:\ntheil:~$ sbatch -p gpu --gres=gpu:1 job.sh\nSubmitted batch job 380\nTo use CUDA or cuDNN, you’ll need to load the ‘cuda’ or ‘cudnn’ modules. To use Tensorflow with the GPU, you’ll need to load the ‘tensorflow’ module (without loading the cuda or cudnn modules, as CUDA and cuDNN will be available to Tensorflow via a different mechanism).\n\n\n\nThe Slurm command squeue provides info on job status:\ntheil:~$ squeue\n   JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n     381      high   job.sh paciorek  R      25:28      1 eml-sm20\n     380      low    job.sh paciorek  R      25:37      1 eml-sm11\nThe following will tailor the output to include information on the number of cores (the CPUs column below) being used:\ntheil:~$ squeue -o \"%.7i %.9P %.8j %.8u %.2t %.9M %.5C %.8r %.6D %R\"\n   JOBID PARTITION     NAME     USER ST      TIME  CPUS   REASON  NODES NODELIST(REASON)\n     381      high   job.sh paciorek  R     28:00     4     None      1 eml-sm20\n     380      low    job.sh paciorek  R     28:09     4     None      1 eml-sm11 \nThe ST field indicates whether a job is running (R), failed (F), or pending (PD). The latter occurs when there are not yet enough resources on the system for your job to run.\nIf you would like to logon to the node on which your job is running in order to assess CPU or memory use, you can run an interactive job within the context of your existing job. First determine the job ID of your running job using squeue (here job 380) and insert that in the following command:\nsrun --pty --jobid=380 /bin/bash\nYou can then run ‘top’ and other such tools.\nTo see a history of your jobs (within a time range), including reasons they might have failed:\nsacct  --starttime=2021-04-01 --endtime=2021-04-30 \\\n  --format JobID,JobName,Partition,Account,AllocCPUS,State%30,ExitCode,Submit,Start,End,NodeList,MaxRSS\n\n\n\nIf you’d like to see how busy each node is (e.g., to choose what partition to submit a job to), you can run the following:\ntheil:~$ sinfo -N -o \"%8P %15N %.5a %6t %C\"\nPARTITIO NODELIST        AVAIL STATE  CPUS(A/I/O/T)\nlow*     eml-sm00           up idle   0/32/0/32\nlow*     eml-sm01           up idle   0/32/0/32\nlow*     eml-sm02           up idle   0/32/0/32\nlow*     eml-sm03           up idle   0/32/0/32\nlow*     eml-sm10           up mix    29/3/0/32\nlow*     eml-sm11           up mix    27/5/0/32\nlow*     eml-sm12           up mix    9/23/0/32\nlow*     eml-sm13           up idle   0/32/0/32\nhigh     eml-sm20           up idle   0/56/0/56\nhigh     eml-sm21           up mix    8/48/0/56\nhigh     eml-sm22           up idle   0/56/0/56\nhigh     eml-sm23           up idle   0/56/0/56 \nhigh     eml-sm30           up mix    28/4/0/32\nhigh     eml-sm31           up mix    28/4/0/32\nhigh     eml-sm32           up idle   0/32/0/32\nhigh     eml-sm33           up idle   0/32/0/32\nHere the A column indicates the number of cores used (i.e., active), I indicates the number of inactive cores, and T the total number of cores on the node.\n\n\n\nThe cluster is managed using the Slurm scheduling software. We configure Slurm to try to balance the needs of the various cluster users.\nOften there may be enough available CPU cores (aka ‘resources’) on the partition, and your job will start immediately after you submit it.\nHowever, there are various reasons a job may take a while to start. Here are some details of how the scheduler works.\n\nIf there aren’t enough resources in a given partition to run a job when it is submitted, it goes into the queue. The queue is sorted based how much CPU time you’ve used over the past few weeks, using the ‘fair share’ policy described below. Your jobs will be moved to a position in the queue below the jobs of users who have used less CPU time in recent weeks. This happens dynamically, so another user can submit a job well after you have submitted your job, and that other user’s job can be placed higher in the queue at that time and start sooner than your job. If this were not the case, imagine the situation of a user sending 100s of big jobs to the system. They get into the queue and everyone submitting after that has to wait for a long time while those jobs are run, if other jobs can’t get moved above those jobs in the queue.\nWhen a job at the top of the queue needs multiple CPU cores (or in some cases an entire node), then jobs submitted to that same partition that are lower in the queue will not start even if there are enough CPU cores available for those lower priority jobs. That’s because the scheduler is trying to accumulate resources for the higher priority job(s) and guarantee that the higher priority jobs’ start times wouldn’t be pushed back by running the lower priority jobs.\nIn some cases, if the scheduler has enough information about how long jobs will run, it will run lower-priority jobs on available resources when it can do so without affecting when a higher priority job would start. This is called backfill. It can work well on some systems but on the SCF and EML it doesn’t work all that well because we don’t require that users specify their jobs’ time limits carefully. We made that tradeoff to make the cluster more user-friendly at the expense of optimizing throughput.\n\nThe ‘fair share’ policy governs the order of jobs that are waiting in the queue for resources to become available. In particular, if two users each have a job sitting in a queue, the job that will start first will be that of the user who has made less use of the cluster recently (measured in terms of CPU time). The measurement of CPU time downweights usage over time, with a half-life of one month, so a job that ran a month ago will count half as much as a job that ran yesterday. Apart from this prioritization based on recent use, all users are treated equally.\n\n\n\nWe’ve prepared a set of shortcut commands that wrap around Slurm commands such srun, squeue, sinfo, and sacct with some commonly-used options:\n\nslogin: starts an interactive shell on a cluster node\nsnodes: prints the current usage of nodes on the cluster\nsjobs: lists running jobs on the cluster\nshist: provides information about completed (including failed) jobs\nsassoc: gives information about user access to cluster partitions\n\nFor each of these commands, you can add the -h flag to see how to use them. For example:\ntheil:~$ slogin -h\nUsages:\n'slogin' to start an interactive job\n'slogin jobid' to start a shell on the node a job is running on\n'slogin additional_arguments_to_srun' to start an interactive job with additional arguments to srun",
    "crumbs": [
      "Home",
      "Cluster",
      "Using the SLURM cluster"
    ]
  },
  {
    "objectID": "cluster.html#submitting-parallel-jobs",
    "href": "cluster.html#submitting-parallel-jobs",
    "title": "Using the SLURM cluster",
    "section": "",
    "text": "One can use Slurm to submit a variety of types of parallel code. Here is a set of potentially useful templates that we expect will account for most user needs. If you have a situation that does not fall into these categories or have questions about parallel programming or submitting jobs to use more than one core, please email consult@econ.berkeley.edu.\nFor additional details, please see the SCF tutorial on the basics of parallel programming in R, Python, MATLAB and C/C++, with some additional details on doing so in the context of a Slurm job. If you’re making use of the threaded BLAS, it’s worth doing some testing to make sure that threading is giving an non-negligible speedup; see the notes above for more information.\n\n\nHere’s an example job script to use multiple threads (4 in this case) in R (or with your own openMP-based program):\n#!/bin/bash\n#SBATCH --cpus-per-task 4\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nR CMD BATCH --no-save simulate.R simulate.Rout\nThis will allow your R code to use the system’s threaded BLAS and LAPACK routines. [Note that in R you can instead use the omp_set_num_threads() function in the RhpcBLASctl package, again making use of the SLURM_CPUS_PER_TASK environment variable.]\nThe same syntax in your job script will work if you’ve compiled a C/C++/Fortran program that makes use of openMP for threading. Just replace the R CMD BATCH line with the line calling your program.\nHere’s an example job script to use multiple threads (4 in this case) in MATLAB:\n#!/bin/bash\n#SBATCH --cpus-per-task 4\nmatlab -nodesktop -nodisplay &lt; simulate.m &gt; simulate.out\nIMPORTANT: At the start of your MATLAB code file you should include this line:\nmaxNumCompThreads(str2num(getenv('SLURM_CPUS_PER_TASK')));\nHere’s an example job script to use multiple threads (4 in this case) in SAS:\n#!/bin/bash\n#SBATCH --cpus-per-task 4\nsas -threads -cpucount $SLURM_CPUS_PER_TASK\nA number of SAS procs are set to take advantage of threading, including SORT, SUMMARY, TABULATE, GLM, LOESS, and REG. SAS enables threading by default, with the default number of threads set to four. Starting SAS as above ensures that the number of threads is set to the number of cores you requested. You can check that threading is enabled from within SAS by running the following and looking for the cpucount and threads options in the printout.\nProc Options group=performance; run;\nYou can use up to eight cores with Stata/MP (limited by the EML license for Stata). IMPORTANT: Do not request more than 8 cores for a Stata job. If you request eight cores (–cpus-per-task=8) or fewer, you are all set.\nIt’s possible to explicitly set the number of processors in Stata to be the number you requested in your job submission, but that is unnecessary because Slurm will limit your job to the number of cores requested. That said, one way to do this is to hard-code the following line at the start of your Stata code (in this case assuming you requested four cores):\nset processors 4\nYou can do this in an automated fashion by first invoking Stata in your job script as:\nstata-mp -b do myStataCode.do ${SLURM_CPUS_PER_TASK}\nand then at the start of your Stata code including these two lines:\nargs ncores\nset processors `ncores'\n\n\n\nThe following example job script files pertain to jobs that need to use multiple cores on a single node that do not fall under the threading/openMP context. This is relevant for parfor in MATLAB; for IPython parallel (ipyparallel), Dask, Ray, Pool.map and pp.Server in Python; and for parallel code in R that starts multiple R process (e.g., future’s future_lapply, foreach, mclapply, parLapply).\nHere’s an example script that uses multiple cores (4 in this case):\n#!/bin/bash\n#SBATCH --cpus-per-task 4\nR CMD BATCH --no-save simulate.R simulate.Rout\nIMPORTANT: Your R, Python, or any other code won’t be able to use more cores than the number of total cores requested (4 in this case). You can use the SLURM_CPUS_PER_TASK environment variable to programmatically control this, though your software will automatically detect the number of available cores in many cases.\nThe same syntax for your job script pertains to MATLAB. When using parpool in MATLAB, you can do the following:\nparpool(str2num(getenv('SLURM_CPUS_PER_TASK')));\nIn the high (default) partition, the default maximum number of workers is 28 on the eml-sm2 nodes and 16 on the eml-sm3 nodes, while in the low partition it is also 16. To increase this (up to the maximum number of cores on a machine), run the following code before invoking parpool:\ncl = parcluster();\ncl.NumWorkers = str2num(getenv('SLURM_CPUS_PER_TASK'));\ncl.parpool(str2num(getenv('SLURM_CPUS_PER_TASK')));\nTo use more than 32 workers (i.e., 32 cores or more) (or more than 56 in the eml-sm2 nodes on the high (default) partition) in MATLAB in a parpool context (or to use cores spread across multiple nodes, which can help start your job faster when the cluster is busy), you need to use MATLAB Parallel Server, discussed below.\nTo use multiple threads per worker in MATLAB, here is an example script for four workers and two threads per worker:\n#!/bin/bash\n#SBATCH --nodes 1\n#SBATCH --ntasks 4\n#SBATCH --cpus-per-task 2\nmatlab -nodesktop -nodisplay &lt; simulate.m &gt; simulate.out\nAnd here is how to start your parpool in your MATLAB code:\ncl = parcluster();\ncl.NumThreads = str2num(getenv('SLURM_CPUS_PER_TASK'));\ncl.parpool(str2num(getenv('SLURM_NTASKS')));\nAlso note that as indicated above, the cores in the high and gpu partitions use hyperthreading, which could slow multi-core computations in some cases. If you’d like to run multi-core jobs without hyperthreading, please contact us for work-arounds.\n\n\n\nYou can run jobs that use cores across multiple nodes, but only if the software you are using is configured to execute across machines. Some examples include use of MATLAB Parallel server (discussed below); MPI-based jobs (discussed below); Python code that uses ipyparallel, Dask or Ray with workers running on multiple nodes; or R code using the future package or other multi-node-capable tools. This modality allows you to use more cores than exist on a single node or to gather free cores that are scattered across the nodes when the cluster is heavily used. To run across multiple nodes, you can simply request the total number of cores you want using the –ntasks flag. In cases where the number of cores is greater than the number available on a machine, your job will have access to multiple nodes. Depending on cluster usage, even if you request fewer cores than a machine has, your job may still access cores on multiple nodes.\n\n\n\nYou can use MPI to run jobs across multiple nodes. This modality allows you to use more cores than exist on a single node or to gather free cores that are scattered across the nodes when the cluster is heavily used.\nHere’s an example script that uses multiple processors via MPI (64 in this case):\n#!/bin/bash\n#SBATCH --ntasks 64\nmpirun -np $SLURM_NTASKS myMPIexecutable\nNote that “-n” is a shorthand for “–ntasks”.\n“myMPIexecutable” could be C/C++/Fortran code you’ve written that uses MPI, or R or Python code that makes use of MPI. More details are available here.\nTo run an MPI job with each process threaded, your job script would look like the following (here with 14 processes and two threads per process):\n#!/bin/bash\n#SBATCH --ntasks 14 --cpus-per-task 2\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nmpirun -np $SLURM_NTASKS -x OMP_NUM_THREADS myMPIexecutable\n\n\n\nMATLAB Parallel Server (formerly MATLAB DCS) allows you to run a parallel MATLAB job across multiple nodes.\nThere are two primary advantages to using MATLAB Parallel Server rather than parallelizing your MATLAB code across the cores on a single node: (1) there is no limit on the number of workers (apart from the limit on the number of cores available on the cluster), and (2) Your job may not have to wait until the number of cores requested are all available on a single node, but rather than “scavenge” available cores across multiple nodes. (But note that all cores must be within one partition.\nBy default each worker will use one core, but it’s possible to use more than one core per worker as discussed below.\nThere are two ways to use MATLAB Parallel Server.\n\n\nAs a one-time setup step (you only need to do this the first time you are using the approach), go to “Environment-&gt;Parallel-&gt;Create and Manage Cluster Profiles” in the MATLAB Desktop toolbar; this will open the Cluster Profile Manager. Then click on ‘Import’ and navigate to /usr/local/linux/MATLAB/current/toolbox/parallel/dcs.mlsettings (dcsProfile.settings in MATLAB R2022a) and click ‘Open’. Then exit out of the Cluster Profile Manager.\nTo submit a MATLAB Parallel Server job, you’ll need to specify the number of MATLAB workers (by using the -n or –ntasks flag). Unlike in the past you should NOT use the ‘-C dcs’ flag. Here’s an example job script that would use 40 cores for 40 workers (making sure to use the ‘-n’ flag when requesting the number of cores):\n#!/bin/bash\n#SBATCH -n 40\nmatlab -nodesktop -nodisplay &lt; code.m &gt; code.mout\nThen in your MATLAB code, simply invoke parpool as:\npool = parpool('dcs', str2num(getenv('SLURM_NTASKS')));\nIf you’d like to use multiple threads per worker, please set –cpus-per-task equal to the number of threads per worker you desire and then use this approach in your MATLAB code:\ncl = parcluster('dcs');\ncl.NumThreads = str2num(getenv('SLURM_CPUS_PER_TASK'));\npool = cl.parpool('dcs', str2num(getenv('SLURM_NTASKS'));  % Start a pool of multi-core workers on the EML cluster\n% execute code\ndelete(pool);   % Make sure to delete the job so the cluster resources of the Slurm job are released\nYou should also be able to use the “batch” command to execute a script or function across multiple workers as described under Option 2 below. Other uses of MATLAB parallel server functionality may also be possible.\n\n\n\nTo submit a MATLAB Parallel Server job, you’ll need to specify the number of MATLAB workers (by using the -n or –ntasks flag) and indicate that a Parallel Server job will be run (by using ‘-C dcs’). This won’t work with srun, only with sbatch. Here’s an example job script that would use 40 cores for 40 workers (making sure to use the ‘-n’ flag when requesting the number of cores):\n#!/bin/bash\n#SBATCH -n 40 -C dcs \nmatlab -nodesktop -nodisplay &lt; code.m &gt; code.mout\nThen in your MATLAB code, simply invoke parpool as:\npool = parpool(str2num(getenv('SLURM_NTASKS')));\nNote that the workers will run as the user “matlabdcs”, so if you interactively log into a node with some of the workers on it, you will see MATLAB processes running as this user if you use ‘top’ or ‘ps’.\nIf you’d like to use multiple threads per worker, please set –cpus-per-task equal to the number of threads per worker you desire and then use this appraoch in your MATLAB code:\ncl = parcluster('dcs');\ncl.NumThreads = str2num(getenv('SLURM_CPUS_PER_TASK'));\npool = cl.parpool('dcs', 20);  % Start a 20-worker pool of multi-core workers on the EML cluster\n% execute code\ndelete(pool);   % Make sure to delete the job so the cluster resources of the Slurm job are released\n\n\n\nThis option allows you to be running code within MATLAB running on a stand-alone Linux machine (not part of the EML cluster) and offload parallel execution of a portion of your code to the cluster without explicitly starting a cluster job via Slurm. Note that you simply login to an EML Linux machine and start MATLAB; you do NOT use sbatch or srun to start a cluster job under this approach.\nUnder Option 2, you can either start a pool of workers using “parpool” or you can use the “batch” command to execute code across multiple workers.\nTo start up a pool of workers (with the only limit on the number of workers being the number of cores in a given partition and the usage of cores by other users’ jobs), you’ll need to use the ‘dcs’ cluster profile.\nAs a one-time setup step (you only need to do this the first time you are using the approach), go to “Environment-&gt;Parallel-&gt;Create and Manage Cluster Profiles” in the MATLAB Desktop toolbar; this will open the Cluster Profile Manager. Then click on ‘Import’ and navigate to /usr/local/linux/MATLAB/current/toolbox/parallel/dcs.mlsettings (dcsProfile.settings in R2022a and earlier versions) and click ‘Open’. Then exit out of the Cluster Profile Manager.\nNow, whenever you want to start up a pool of workers, simply do the following (here for 40 workers):\npool = parpool('dcs', 40);  % Start a 40-worker pool on the EML cluster\n% execute code\ndelete(pool);               % Make sure to delete the job so the cluster resources of the Slurm job are released\nThis starts a Slurm job (and prints out the job ID to the screen in case you want to monitor the Slurm job). Once the pool is ready, simply execute your parallel code (such as with a parfor loop). When you are done remember to delete the pool so the cluster job ends and the resources are available to others.\nFor threaded workers, you can simply do this:\ncl = parcluster('dcs');\ncl.NumThreads = 2;      % however many threads per worker you'd like to use\npool = cl.parpool(20);  % Start a 20-worker pool of multi-core workers on the EML cluster\n% execute code\ndelete(pool);           % Make sure to delete the job so the cluster resources of the Slurm job are released\nIf you’d like to modify the flags that are used when the underlying Slurm job is submitted (e.g., to use the ‘low’ partition and set a particular time limit as shown here), you would do it like this:\ncl = parcluster('dcs');\ncl.AdditionalProperties.AdditionalSubmitArgs='-p low -t 30:00'\n% Start a 40-worker pool on EML cluster low partition, 30 min. time limit\npool = cl.parpool(40);\n% execute code\ndelete(pool);   % Make sure to delete the job so the cluster resources of the Slurm job are released\nAlternatively you can use the “batch” command to execute a script or function across multiple workers. Here is one example usage but there are a variety of others discussed in MATLAB’s online documentation for the “batch” command. Suppose you have a file ‘code.m’ that executes a parfor. To run that code on 39 workers (an additional worker will be used to manage the work, for a total of 40 workers), you would do this:\nc = parcluster('dcs');           % Sets things up to make use of MATLAB Parallel Server\nj = c.batch('code', 'Pool', 39); % Uses 40 workers total, starting a Slurm job on the EML cluster\nwait(j)                          % Wait for the job to finish\ndiary(j)                         % Display logging output\nr = fetchOutputs(j);             % Get results into a cell array\nr{1}                             % Display results\nj.delete()                       % Make sure to delete the job so the cluster resources of the Slurm job are released",
    "crumbs": [
      "Home",
      "Cluster",
      "Using the SLURM cluster"
    ]
  },
  {
    "objectID": "cluster.html#automating-submission-of-multiple-jobs",
    "href": "cluster.html#automating-submission-of-multiple-jobs",
    "title": "Using the SLURM cluster",
    "section": "",
    "text": "Job array submissions are a nice way to submit multiple jobs in which you vary a parameter across the different jobs.\nHere’s what your job script would look like, in this case to run a total of 5 jobs with parameter values of 0, 1, 2, 5, 7:\n#!/bin/bash\n#SBATCH -a 0-2,5,7\nmyExecutable\nYour program should then make use of the SLURM_ARRAY_TASK_ID environment variable, which for a given job will contain one of the values from the set given with the -a flag (in this case from {0,1,2,5,7}). You could, for example, read SLURM_ARRAY_TASK_ID into your R, Python, MATLAB, or C code.\nHere’s a concrete example where it’s sufficient to use SLURM_ARRAY_TASK_ID to distinguish different input files if you need to run the same command (the bioinformatics program tophat in this case) on multiple input files (in this case, trans0.fq, trans1.fq, …):\n#!/bin/bash\n#SBATCH -a 0-2,5,7\ntophat BowtieIndex trans${SLURM_ARRAY_TASK_ID}.fq\n\n\n\nHere’s how you would set up your job script if you want to run multiple instances (18 in this case) of the same code as part of a single job.\n#!/bin/bash\n#SBATCH --ntasks 18 \nsrun myExecutable\nTo have each instance behave differently, you can make use of the SLURM_PROCID environment variable, which will be distinct (and have values 0, 1, 2, …) between the different instances.\nTo have each process be threaded, see the syntax under the MPI section above.\n\n\n\nThe above approaches are more elegant, but you can also use UNIX shell tools to submit multiple Slurm jobs. Here are some approaches and example syntax. We’ve tested these a bit but email consult@econ.berkeley.edu if you have problems or find a better way to do this. (Of course you can also manually create lots of individual job submission scripts, each of which calls a different script.)\nFirst, remember that each individual job should be submitted through sbatch.\nHere is some example bash shell code (which could be placed in a shell script file) that loops over two variables (one numeric and the other a string):\nfor ((it = 1; it &lt;= 10; it++)); do\n  for mode in short long; do\n    sbatch job.sh $it $mode\n  done\ndone\nYou now have a couple options in terms of how job.sh is specified. This illustrates things for MATLAB jobs, but it shouldn’t be too hard to modify for other types of jobs.\n\n\n# contents of job.sh\necho \"it = $1; mode = '$2'; myMatlabCode\" &gt; tmp-$1-$2.m\nmatlab -nodesktop -nodisplay -singleCompThread &lt; tmp-$1-$2.m &gt; tmp-$1-$2.out 2&gt; tmp-$1-$2.err\nIn this case myMatlabCode.m would use the variables ‘it’ and ‘mode’ but not define them.\n\n\n\n# contents of job.sh\nexport it=$1; export mode=$2;\nmatlab -nodesktop -nodisplay -singleCompThread &lt; myMatlabCode.m &gt; tmp-$1-$2.out 2&gt; tmp-$1-$2.err\nIn this case you need to insert the following MATLAB code at the start of myMatlabCode.m so that MATLAB correctly reads the values of ‘it’ and ‘mode’ from the UNIX environment variables:\nit = str2num(getenv('it'));\nmode = getenv('mode');\nFor Stata jobs, there’s an easier mechanism for passing arguments into a batch job. Invoke Stata as follows in job.sh:\nstata -b do myStataCode.do $1 $2\nand then in the first line of your Stata code file, myStataCode.do above, assign the input values to variables (in this case I’ve named them id and mode to match the shell variables, but they can be named differently):\nargs id mode\nThen the remainder of your code can make use of these variables.",
    "crumbs": [
      "Home",
      "Cluster",
      "Using the SLURM cluster"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact Us",
    "section": "",
    "text": "Phone: (510) 642-0619\nIn Person: 643 Evans Hall\n\n\n\ntrouble@econ - for problems with EML hardware, networking or printing\nconsult@econ - for questions about our software and for submitting requests for software installation\nmanager@econ - for problems that have to do with your account, for quota increase requests, and other administrative questions"
  },
  {
    "objectID": "contact.html#email",
    "href": "contact.html#email",
    "title": "Contact Us",
    "section": "",
    "text": "trouble@econ - for problems with EML hardware, networking or printing\nconsult@econ - for questions about our software and for submitting requests for software installation\nmanager@econ - for problems that have to do with your account, for quota increase requests, and other administrative questions"
  },
  {
    "objectID": "disk-quota.html",
    "href": "disk-quota.html",
    "title": "Disk Quota",
    "section": "",
    "text": "Disk Quota\nEach user is assigned a disk space quota, or allotment, when their account is created to insure that there will be sufficient disk space for all our users’ needs.\nOnce you are over quota, programs may fail to run and you may also be prevented from logging in.\nEach user is expected to monitor their own disk usage and to attempt to stay within their quota. To view your current usage, type quota on the command line.\nThe best practice is to check your quota occasionally, and if it appears you are nearing your limit, you should see what files you may be able to remove from your account to provide yourself with more disk space.\nYou should never need to remove files that you need in order to meet your disk quota. If you anticipate a long-term need for an unusually large amount of disk space, please notify the EML staff before the need becomes acute, so that we can find a suitable location for your files without encroaching on the files of other users. Additional disk space may be requested by sending mail to manager@econ.berkeley.edu.",
    "crumbs": [
      "Home",
      "Data and Storage",
      "Disk Quota"
    ]
  },
  {
    "objectID": "eligibility.html",
    "href": "eligibility.html",
    "title": "Eligibility Policies",
    "section": "",
    "text": "Eligibility Policies\nWho Can Use the EML:\n\nRegistered graduate students in the Economics Ph.D. program; continuing but unregistered graduate students in the Economics Ph.D. program who are writing dissertations; faculty in the Economics department; visiting scholars who are sponsored by the Economics department; Economics department staff and research support personnel.\nRegistered students who are currently enrolled in a graduate course that is using the EML. Class accounts are handed out by the instructor in class, and any registered student, graduate or undergraduate, who is currently enrolled in the course may have an EML account for that semester.\nOthers by exception, such as alumni up to two months out from the Ph.D. degree; courtesy accounts for software vendors; system administrators at related facilities; non-departmental research project teams. The EML has specific guidelines governing non-departmental research project accounts that can be obtained on request from the EML manager in 643 Evans Hall.\n\nAny graduate, staff, or faculty user may use the workstations in 616 Evans Hall on a twenty-four hour basis, provided you have a security card key to let you into the building during non-working hours.",
    "crumbs": [
      "Home",
      "Accounts",
      "Policies and Rules",
      "Eligibility Policies"
    ]
  },
  {
    "objectID": "ergonomics.html",
    "href": "ergonomics.html",
    "title": "Ergonomic Resources",
    "section": "",
    "text": "The Econometrics Laboratory (EML) in conjunction with the Department of Economics will try to provide ergonomic accommodations whenever possible. It is the responsibility of users to seek assistance in maintaining a heathly work environment. Users must be pro-active and take appropriate measures to prevent Repetitive Stress Injuries (RSI). The following is a synopsis of services and facilities that are available to users.\n\n\nRoom 616: Fully adjustable chairs, Adjustable tables\n\n\n\nxwrits: reminds you to take wrist breaks\n\n\n\nLiterature is available in the computer labs in the document racks. More ergonomic information can be found at University Health Services.",
    "crumbs": [
      "Home",
      "Accounts",
      "Ergonomic Resources"
    ]
  },
  {
    "objectID": "ergonomics.html#accommodations",
    "href": "ergonomics.html#accommodations",
    "title": "Ergonomic Resources",
    "section": "",
    "text": "Room 616: Fully adjustable chairs, Adjustable tables",
    "crumbs": [
      "Home",
      "Accounts",
      "Ergonomic Resources"
    ]
  },
  {
    "objectID": "ergonomics.html#software",
    "href": "ergonomics.html#software",
    "title": "Ergonomic Resources",
    "section": "",
    "text": "xwrits: reminds you to take wrist breaks",
    "crumbs": [
      "Home",
      "Accounts",
      "Ergonomic Resources"
    ]
  },
  {
    "objectID": "ergonomics.html#additional-information",
    "href": "ergonomics.html#additional-information",
    "title": "Ergonomic Resources",
    "section": "",
    "text": "Literature is available in the computer labs in the document racks. More ergonomic information can be found at University Health Services.",
    "crumbs": [
      "Home",
      "Accounts",
      "Ergonomic Resources"
    ]
  },
  {
    "objectID": "globus.html",
    "href": "globus.html",
    "title": "Globus",
    "section": "",
    "text": "Globus\nGlobus is a data management service that allows you to easily transfer data (including fast transfers of extremely large datasets) between machines and share data with others. You logon and specify the transfer to be made, and Globus takes care of it in a robust manner without you having to monitor the transfer or worry about the connection between the machines being lost.\nThe easiest thing you can do is transfer files between machines/systems that are already registered with Globus as Globus endpoints. Some endpoints that may be useful for Berkeley affiliates include Berkeley Research Computing’s Savio campus cluster and NERSC:\n\n\n\n\nEndpoint\n\n\nDisplay Name\n\n\n\n\n\n\nucb#economics\n\n\nUC Berkeley Economics Department\n\n\n\n\nucb#statistics\n\n\nUC Berkeley Statistics Department\n\n\n\n\nucb#brc\n\n\nUC Berkeley Savio campus Linux cluster\n\n\n\n\nnersc#cori\n\n\nNERSC Cori\n\n\n\n\nnersc#hpss\n\n\nNERSC HPSS\n\n\n\n\nVisit the Globus Web App to transfer files. You should be able to authenticate with your Berkeley credentials. Enter the name of the endpoint and authenticate to the resource by following the directions given. Once both endpoints are authenticated, it’s straightforward to drag and drop to transfer files. Globus will email you when the transfer is complete.\nYou can also transfer to/from your own machine. To do so, first get the Globus Connect Personal client for your machine (see the lower right of the webpage to download the client for your operating system). Your machine will then be registered as one of your personal endpoints. When selecting an endpoint, you should be able to click on the box labelled “Endpoint” and select the resource from the list in “My Endpoints”. To transfer to an external drive, see these instructions.",
    "crumbs": [
      "Home",
      "Remote Access",
      "File Transfer",
      "Globus"
    ]
  },
  {
    "objectID": "hardware.html",
    "href": "hardware.html",
    "title": "Hardware",
    "section": "",
    "text": "The EML supports ten linux compute servers. The compute servers processing units vary from 8-80 and the memory on each vary from 6 GB to 754 GB. A complete list is available at our Grafana dashboards which are only available to EML users. The operating system for the compute servers is Ubuntu.\n\n\n\nThe EML also has a high performance computing cluster, containing twelve nodes (eight nodes containing 32 CPU cores, four nodes containing 56 CPU cores each, and four nodes containing ) available for compute jobs. Four nodes have 264 GB dedicated RAM, four nodes have 132 GB dedicated RAM, and four nodes have 768 GB dedicated RAM. It is managed by the SLURM queueing software. Slurm provides a standard batch queueing system through which users submit jobs to the cluster. Jobs are typically submitted to Slurm via a user’s shell script which executes one’s application code. Users may also query the cluster to see job status. All software running on EML Linux machines and compute servers are also available on the cluster. Users can also compile programs on any EML Linux machine and then run that program on the cluster.\n\n\n\nThe EML provides a GPU (an Nvidia A40 with 46 GB GPU memory), with associated software (CUDA, CuDNN, Tensorflow, Pytorch), available through the ‘gpu’ partition on the cluster.\n\n\n\nEML users may access the condo node at Savio, the high-performance computational cluster managed by the Berkeley Research Computing (BRC) program. This allows EML users to run jobs with priority access to 2 nodes. They are also entitled to use the extra resource available on the Savio cluster through a low priority QoS. More information is available at the Savio website.\n\n\n\nThe EML supports a lab with public Apple desktop computers and two network printers.",
    "crumbs": [
      "Home",
      "Cluster",
      "Hardware"
    ]
  },
  {
    "objectID": "hardware.html#servers",
    "href": "hardware.html#servers",
    "title": "Hardware",
    "section": "",
    "text": "The EML supports ten linux compute servers. The compute servers processing units vary from 8-80 and the memory on each vary from 6 GB to 754 GB. A complete list is available at our Grafana dashboards which are only available to EML users. The operating system for the compute servers is Ubuntu.",
    "crumbs": [
      "Home",
      "Cluster",
      "Hardware"
    ]
  },
  {
    "objectID": "hardware.html#computing-cluster",
    "href": "hardware.html#computing-cluster",
    "title": "Hardware",
    "section": "",
    "text": "The EML also has a high performance computing cluster, containing twelve nodes (eight nodes containing 32 CPU cores, four nodes containing 56 CPU cores each, and four nodes containing ) available for compute jobs. Four nodes have 264 GB dedicated RAM, four nodes have 132 GB dedicated RAM, and four nodes have 768 GB dedicated RAM. It is managed by the SLURM queueing software. Slurm provides a standard batch queueing system through which users submit jobs to the cluster. Jobs are typically submitted to Slurm via a user’s shell script which executes one’s application code. Users may also query the cluster to see job status. All software running on EML Linux machines and compute servers are also available on the cluster. Users can also compile programs on any EML Linux machine and then run that program on the cluster.",
    "crumbs": [
      "Home",
      "Cluster",
      "Hardware"
    ]
  },
  {
    "objectID": "hardware.html#gpu",
    "href": "hardware.html#gpu",
    "title": "Hardware",
    "section": "",
    "text": "The EML provides a GPU (an Nvidia A40 with 46 GB GPU memory), with associated software (CUDA, CuDNN, Tensorflow, Pytorch), available through the ‘gpu’ partition on the cluster.",
    "crumbs": [
      "Home",
      "Cluster",
      "Hardware"
    ]
  },
  {
    "objectID": "hardware.html#condo-node-at-savio",
    "href": "hardware.html#condo-node-at-savio",
    "title": "Hardware",
    "section": "",
    "text": "EML users may access the condo node at Savio, the high-performance computational cluster managed by the Berkeley Research Computing (BRC) program. This allows EML users to run jobs with priority access to 2 nodes. They are also entitled to use the extra resource available on the Savio cluster through a low priority QoS. More information is available at the Savio website.",
    "crumbs": [
      "Home",
      "Cluster",
      "Hardware"
    ]
  },
  {
    "objectID": "hardware.html#eml-lab-616-evans",
    "href": "hardware.html#eml-lab-616-evans",
    "title": "Hardware",
    "section": "",
    "text": "The EML supports a lab with public Apple desktop computers and two network printers.",
    "crumbs": [
      "Home",
      "Cluster",
      "Hardware"
    ]
  },
  {
    "objectID": "homepage.html",
    "href": "homepage.html",
    "title": "Publish a personal website",
    "section": "",
    "text": "The EML enables users to publish documents and data on the web. Users may place files in a directory so that outside users can view them with a web browser.\n\n\nOnly individuals who are associated with the Economics Department are eligible to use this resource to distribute information. Participants must observe all departmental and UC campus rules and regulations, and all copyright laws. The EML reserves the right not to post submitted material.\nGraduate students may maintain their own homepage using the following guidelines:\n\nPosted material at the top level home page is limited to information related to the individual’s academic interests. Listed below are examples of the type of information that is appropriate for the top level homepage:\n\nBiographical information (including the student’s photograph).\nDissertation abstract.\nData sets (with the signed approval of faculty advisor).\nLinks to other professionally relevant sites.\n\nPersonal information can be included in a sub-level home page that is clearly identified as containing personal information. This area can include links to sites that are not related to to the individual’s academic work.\nThe posting or advertising of personal items for sale and the posting of any published material (including articles authored by the student) is forbidden.\n\n\n\n\nIn order to publish material on the web, you will create or deposit your files into a user-specific directory, /accounts/web/public/{username}/.\nFollow the instructions below to create your web area:\n\nSend mail to manager@econ.berkeley.edu requesting the creation of an area in /accounts/web/public/.\nManager will reply with the name of your directory. (usually /accounts/web/public/{username})\nVisit Rowilma in 643 Evans to sign a copyright form.\nCreate your homepage, for example “index.html” in your web directory.\nView your site at https://eml.berkeley.edu/~{username}.",
    "crumbs": [
      "Home",
      "Accounts",
      "Publish a personal website"
    ]
  },
  {
    "objectID": "homepage.html#guidelines",
    "href": "homepage.html#guidelines",
    "title": "Publish a personal website",
    "section": "",
    "text": "Only individuals who are associated with the Economics Department are eligible to use this resource to distribute information. Participants must observe all departmental and UC campus rules and regulations, and all copyright laws. The EML reserves the right not to post submitted material.\nGraduate students may maintain their own homepage using the following guidelines:\n\nPosted material at the top level home page is limited to information related to the individual’s academic interests. Listed below are examples of the type of information that is appropriate for the top level homepage:\n\nBiographical information (including the student’s photograph).\nDissertation abstract.\nData sets (with the signed approval of faculty advisor).\nLinks to other professionally relevant sites.\n\nPersonal information can be included in a sub-level home page that is clearly identified as containing personal information. This area can include links to sites that are not related to to the individual’s academic work.\nThe posting or advertising of personal items for sale and the posting of any published material (including articles authored by the student) is forbidden.",
    "crumbs": [
      "Home",
      "Accounts",
      "Publish a personal website"
    ]
  },
  {
    "objectID": "homepage.html#setting-up-the-web-area",
    "href": "homepage.html#setting-up-the-web-area",
    "title": "Publish a personal website",
    "section": "",
    "text": "In order to publish material on the web, you will create or deposit your files into a user-specific directory, /accounts/web/public/{username}/.\nFollow the instructions below to create your web area:\n\nSend mail to manager@econ.berkeley.edu requesting the creation of an area in /accounts/web/public/.\nManager will reply with the name of your directory. (usually /accounts/web/public/{username})\nVisit Rowilma in 643 Evans to sign a copyright form.\nCreate your homepage, for example “index.html” in your web directory.\nView your site at https://eml.berkeley.edu/~{username}.",
    "crumbs": [
      "Home",
      "Accounts",
      "Publish a personal website"
    ]
  },
  {
    "objectID": "julia-packages.html",
    "href": "julia-packages.html",
    "title": "Julia Packages",
    "section": "",
    "text": "We provide Julia, available on all machines by invoking `julia`.\nTo see what Julia packages we have installed, you can run\n$ ls /usr/local/linux/julia-1.8.5/packages\nTo see what Julia packages are directly available for loading (via `using` or `import`) through our system project, you can run\n$ cat /usr/local/linux/julia-1.8.5/share/julia/environments/v1.8/Project.toml\nAt the moment, there are very few packages installed and available system-wide at the moment. However, we’re happy to install additional packages system-wide, particularly if they seem like they would be useful to multiple people. Just email consult@econ.berkeley.edu.\nFor Julia 1.8.5, for any packages not in the system project (see above), you need to add the packages to your Julia project (which might simply be your default project in `~/.julia/environments/v1.8`) using `Pkg.add` (see below). Packages installed on the system won’t be reinstalled (unless a newer version is available than the one we installed); they’ll simply be associated with your project.\n\n\nYou can also install additional packages into your own account. Packages are associated with Julia projects. You can view your current project with `Base.active_project()` and activate a project using `Pkg.activate()`.\nHere is an example of installing the `GaussianMixtures` package for your current project:\njulia&gt; using Pkg\njulia&gt; Pkg.add(\"GaussianMixtures\")\njulia&gt; using GaussianMixtures\nBy running the ‘using’ command immediately, Julia will precompile the package.\nNote that if the current version of `GaussianMixtures` were already installed at the system level, Julia won’t reinstall it, but will simply make the system-installed package available in your current project.\n\n\n\nYou can use Linux environment modules to switch between different Julia versions. This can be done on a one-time basis in a given terminal session or cluster submission script, or can be done in your .bashrc (after the stanza involving ~skel/std.bashrc) to set a default different than the system default.\nTo see what older versions are available and use one of them:\n$ module avail julia\n$ module load julia/1.6.6\nTo switch from Julia 1.6.6 to Julia 1.8:\n$ module switch julia/1.6.6 julia/1.8\nTo see what Julia is being used:\nmodule list",
    "crumbs": [
      "Home",
      "Software",
      "Julia Packages"
    ]
  },
  {
    "objectID": "julia-packages.html#versions",
    "href": "julia-packages.html#versions",
    "title": "Julia Packages",
    "section": "",
    "text": "You can use Linux environment modules to switch between different Julia versions. This can be done on a one-time basis in a given terminal session or cluster submission script, or can be done in your .bashrc (after the stanza involving ~skel/std.bashrc) to set a default different than the system default.\nTo see what older versions are available and use one of them:\n$ module avail julia\n$ module load julia/1.6.6\nTo switch from Julia 1.6.6 to Julia 1.8:\n$ module switch julia/1.6.6 julia/1.8\nTo see what Julia is being used:\nmodule list",
    "crumbs": [
      "Home",
      "Software",
      "Julia Packages"
    ]
  },
  {
    "objectID": "lab-rules.html",
    "href": "lab-rules.html",
    "title": "Computer Lab Rules",
    "section": "",
    "text": "Computer Lab Rules\nObserve the following rules while in the computer labs:\n\nNo food or drinks are allowed.\nNo smoking is permitted.\nIf you need to talk to others - talk quietly.\nObserve room hours. Be prepared to leave before the room is scheduled to close.\nKeep your work area clean - No writing on desks or terminals.\nPlease report any problems to the TA and/or send mail to “trouble”.\nDo not leave the room with a terminal or workstation logged in for more than 10 minutes. Leave a note on the terminal if you leave the room.\nDo not sit in front of a terminal/workstation if you are not using it.\nDo not move any workstation or terminal. You can adjust the angle of the monitor but do not move/relocate the base of the unit.\nDo not turn off the power to any piece of equipment. Refer to item #6.",
    "crumbs": [
      "Home",
      "Accounts",
      "Policies and Rules",
      "Computer Lab Rules"
    ]
  },
  {
    "objectID": "monitoring.html",
    "href": "monitoring.html",
    "title": "Monitoring EML Resources",
    "section": "",
    "text": "The EML has a series of dashboards which provide an overview of the machines and their available resources. You must login with your EML account.\n\n\n\nGeneral overview\nMemory utilization\nCPU load averages\nSLURM activity\nAll general dashboards",
    "crumbs": [
      "Home",
      "Remote Access",
      "Monitoring EML Resources"
    ]
  },
  {
    "objectID": "monitoring.html#grafana-dashboards",
    "href": "monitoring.html#grafana-dashboards",
    "title": "Monitoring EML Resources",
    "section": "",
    "text": "General overview\nMemory utilization\nCPU load averages\nSLURM activity\nAll general dashboards",
    "crumbs": [
      "Home",
      "Remote Access",
      "Monitoring EML Resources"
    ]
  },
  {
    "objectID": "noaccess.html.html",
    "href": "noaccess.html.html",
    "title": "Directory browsing not allowed on this server.",
    "section": "",
    "text": "Directory browsing not allowed on this server."
  },
  {
    "objectID": "putty.html",
    "href": "putty.html",
    "title": "Putty",
    "section": "",
    "text": "Generate an SSH key pair\nOpen Putty\nOn the Host Name, type in an EML hostname \nUnder the Connection - “SSH” (on the left menu), click on “Auth”. On the field ““Private key file for authentication”, click on Browse. Look for the private key file that you had saved (ends with .ppk). Find and select “Open” in the file window.\nOn the left menu, click Session and type a name for the session and hit “Save” button.\nOn the bottom, click “Open”. Login in with the project account username and type the passphrase.\n\n\n\n\n\nGenerate an SSH key pair, and have the project account administrator install the private key into the account.\nOpen WinSCP. Under Hostname, type in an EML hostname\nUnder Username, type in project account username\nClick on Advanced\nClick on Authentication (under SSH)\nUnder the section Authentication parameters, Private key file, click on the icon with three dots to browse for the private key file that you saved.\nClick Ok.\nClick on Login\nYou should be asked for the passphrase you used when you generated the key pair.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Putty"
    ]
  },
  {
    "objectID": "putty.html#ssh",
    "href": "putty.html#ssh",
    "title": "Putty",
    "section": "",
    "text": "Generate an SSH key pair\nOpen Putty\nOn the Host Name, type in an EML hostname \nUnder the Connection - “SSH” (on the left menu), click on “Auth”. On the field ““Private key file for authentication”, click on Browse. Look for the private key file that you had saved (ends with .ppk). Find and select “Open” in the file window.\nOn the left menu, click Session and type a name for the session and hit “Save” button.\nOn the bottom, click “Open”. Login in with the project account username and type the passphrase.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Putty"
    ]
  },
  {
    "objectID": "putty.html#using-winscp",
    "href": "putty.html#using-winscp",
    "title": "Putty",
    "section": "",
    "text": "Generate an SSH key pair, and have the project account administrator install the private key into the account.\nOpen WinSCP. Under Hostname, type in an EML hostname\nUnder Username, type in project account username\nClick on Advanced\nClick on Authentication (under SSH)\nUnder the section Authentication parameters, Private key file, click on the icon with three dots to browse for the private key file that you saved.\nClick Ok.\nClick on Login\nYou should be asked for the passphrase you used when you generated the key pair.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "Putty"
    ]
  },
  {
    "objectID": "r-libraries.html",
    "href": "r-libraries.html",
    "title": "R packages",
    "section": "",
    "text": "By default, R searches a set of paths when you request actions involving libraries. The first path is used by default when invoking functions such as install.packages() leading to messages like this:\nmkdir: cannot create directory  `/server/linux/lib/R/site-library/00LOCK': Permission denied ERROR: failed to lock directory \n\n '/server/linux/lib/R/site-library' for modifying\nFortunately, R provides a number of methods for controlling the library path to accomodate just about any user’s need.\n\n\n\nYou can modify R’s notion of your library path on a one-time basis by specifying the lib= argument to install.packages. Suppose there is a directory called MyRlibs in your home directory. The command:\ninstall.packages(\"caTools\",lib=\"~/MyRlibs\")\nwill install the specified package in your local directory. To access it, the lib.loc= argument of library must be used:\nlibrary(caTools,lib=\"~/MyRlibs\")\nOne problem with this scheme is that if a local library invokes the library() function, it won’t know to also search the local library\n\n\n\nThe .libPaths() function accepts a character vector naming the libraries which are to be used as a search path. Note that it does not automatically retain directories which are already on the search path. Since the .libPaths() function returns the current search path when called with no arguments, a call like\n.libPaths(c(\"~/MyRlibs\",.libPaths()))\nwill put your local directory at the beginning of the search path. This means that install.packages() will automatically put packages there, and the library() function will find libraries in your local directory without additional arguments.\n\n\n\nThe environmental variable R_LIBS is set by the script that invokes R, and can be overridden (in a shell startup file, for example) to customize your library path. This variable should be set to a colon-separated string of directories to search. Since it’s always set inside of an R session, the easiest way to get a starting point for it is to use Sys.getenv():\n&gt; Sys.getenv(\"R_LIBS\")                          \n\nR_LIBS \"/usr/local/linux/lib/R/site-library:/usr/local/lib/R/site-library: /usr/lib/R/site-library:/usr/lib/R/library\"\nYou could then make a copy of this path, modify it, and set the R_LIBS environmental variable to that value in the shell or a startup script.",
    "crumbs": [
      "Home",
      "Software",
      "R packages"
    ]
  },
  {
    "objectID": "r-libraries.html#library-path-management",
    "href": "r-libraries.html#library-path-management",
    "title": "R packages",
    "section": "",
    "text": "By default, R searches a set of paths when you request actions involving libraries. The first path is used by default when invoking functions such as install.packages() leading to messages like this:\nmkdir: cannot create directory  `/server/linux/lib/R/site-library/00LOCK': Permission denied ERROR: failed to lock directory \n\n '/server/linux/lib/R/site-library' for modifying\nFortunately, R provides a number of methods for controlling the library path to accomodate just about any user’s need.",
    "crumbs": [
      "Home",
      "Software",
      "R packages"
    ]
  },
  {
    "objectID": "r-libraries.html#temporarily-changing-the-library-path",
    "href": "r-libraries.html#temporarily-changing-the-library-path",
    "title": "R packages",
    "section": "",
    "text": "You can modify R’s notion of your library path on a one-time basis by specifying the lib= argument to install.packages. Suppose there is a directory called MyRlibs in your home directory. The command:\ninstall.packages(\"caTools\",lib=\"~/MyRlibs\")\nwill install the specified package in your local directory. To access it, the lib.loc= argument of library must be used:\nlibrary(caTools,lib=\"~/MyRlibs\")\nOne problem with this scheme is that if a local library invokes the library() function, it won’t know to also search the local library",
    "crumbs": [
      "Home",
      "Software",
      "R packages"
    ]
  },
  {
    "objectID": "r-libraries.html#changing-the-library-path-for-a-session",
    "href": "r-libraries.html#changing-the-library-path-for-a-session",
    "title": "R packages",
    "section": "",
    "text": "The .libPaths() function accepts a character vector naming the libraries which are to be used as a search path. Note that it does not automatically retain directories which are already on the search path. Since the .libPaths() function returns the current search path when called with no arguments, a call like\n.libPaths(c(\"~/MyRlibs\",.libPaths()))\nwill put your local directory at the beginning of the search path. This means that install.packages() will automatically put packages there, and the library() function will find libraries in your local directory without additional arguments.",
    "crumbs": [
      "Home",
      "Software",
      "R packages"
    ]
  },
  {
    "objectID": "r-libraries.html#permanently-changing-the-library-path",
    "href": "r-libraries.html#permanently-changing-the-library-path",
    "title": "R packages",
    "section": "",
    "text": "The environmental variable R_LIBS is set by the script that invokes R, and can be overridden (in a shell startup file, for example) to customize your library path. This variable should be set to a colon-separated string of directories to search. Since it’s always set inside of an R session, the easiest way to get a starting point for it is to use Sys.getenv():\n&gt; Sys.getenv(\"R_LIBS\")                          \n\nR_LIBS \"/usr/local/linux/lib/R/site-library:/usr/local/lib/R/site-library: /usr/lib/R/site-library:/usr/lib/R/library\"\nYou could then make a copy of this path, modify it, and set the R_LIBS environmental variable to that value in the shell or a startup script.",
    "crumbs": [
      "Home",
      "Software",
      "R packages"
    ]
  },
  {
    "objectID": "rdp.html",
    "href": "rdp.html",
    "title": "Remote Desktop",
    "section": "",
    "text": "Remote Desktop enables you to remotely connect to a graphical Linux desktop running on the EML servers.\nOne option is to access Remote Desktop through your browser via the EML JupyterHub.\n\n\nAlternatvely, you can install an RDP (remote desktop protocol) program such as Microsoft Remote Desktop on your device. The Microsoft app comes with Windows and can be downloaded from the App Store for Mac.\n\n\nYou are now required to first login to the campus VPN when using RDP from off-campus. Note that if you are already connected to the VPN and change your wifi network, you will need to disconnect and reconnect to the VPN.\nCollaborators on EML project accounts that do not have access to the campus VPN and use the Remote Desktop Application to access EML can create an SSH tunnel.\n\n\n\nChoose an EML server, and specify your username in your RDP program. You may want to also change the defaults for sound output and whether you want the application to run in fullscreen.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Remote Desktop"
    ]
  },
  {
    "objectID": "rdp.html#rdp",
    "href": "rdp.html#rdp",
    "title": "Remote Desktop",
    "section": "",
    "text": "Alternatvely, you can install an RDP (remote desktop protocol) program such as Microsoft Remote Desktop on your device. The Microsoft app comes with Windows and can be downloaded from the App Store for Mac.\n\n\nYou are now required to first login to the campus VPN when using RDP from off-campus. Note that if you are already connected to the VPN and change your wifi network, you will need to disconnect and reconnect to the VPN.\nCollaborators on EML project accounts that do not have access to the campus VPN and use the Remote Desktop Application to access EML can create an SSH tunnel.\n\n\n\nChoose an EML server, and specify your username in your RDP program. You may want to also change the defaults for sound output and whether you want the application to run in fullscreen.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Remote Desktop"
    ]
  },
  {
    "objectID": "restrictions.html",
    "href": "restrictions.html",
    "title": "Restrictions and Limitations",
    "section": "",
    "text": "EML student accounts are issued only to students who are currently registered with the University of California at Berkeley, and all accounts are subject to approval. An account is issued to a specific individual who is responsible for all activity within his/her account and who agrees not to allow any other individual to access his/her account. EML policies apply to all accounts, and acceptance of an account implies acknowledgement and acceptance of all EML policies. An EML account is a privilege and as such can be revoked if misused. Any graduate student who receives a degree from the Department of Economics is eligible for an “alumni” account, a one-year extension of his/her student account upon graduation. Alumni accounts require the sponsorship of a faculty member within the Department of Economics.\nAccounts that are issued to students, alumni, guests, and visitors will be closed on January 1 and July 1 of each year. ONLY accounts belonging to currently registered Economics graduate students will remain open beyond that date. Individuals having other accounts must apply for an extension. No extensions are granted for class accounts.\nClass accounts will be removed after 3PM of the first Monday after final exams of the semester for which they were assigned. Be sure to make any arrangements for permanent or backup storage of your class account files before the accounts are closed. There will be a $20 fee (plus the cost of media) for recovering files from accounts that have been closed. Upon request, mail messages can be forwarded to another account for up to 60 days after an account has been closed. (This does not apply to class accounts.)\nAll user accounts have disk use quotas which impose an absolute limit on the amount of disk space the account may consume. For more information, see “What is my disk quota?”. User accounts are also subject to periodic purging of certain files. \nBe warned that abuse of any account on any EML UNIX system (or any other computer system) may lead to termination of that account and suspension of all EML system privileges for the offender. “Abuse of an account” includes, but is not limited to: repeated failure to follow posted rules for use of terminal rooms; playing of games; unauthorized attempts to access accounts, files, or system resources not one’s own; malicious mischief of any sort; and failure to cooperate with requests of the System Staff regarding use of system resources. Files under accounts are not personal property; as such the EML reserves the right to review, modify, or delete any file or terminate any activity that may interfere with the operations or security of the EML.\nPlease refer to our email guidelines for policy information on electronic email privacy.\n\n\n\nWhat are the rules of the Econometrics Laboratory?\nHow do I manage UNIX processes?\nHow much disk space am I using?\nWhat temporary disk storage is available?",
    "crumbs": [
      "Home",
      "Accounts",
      "Policies and Rules",
      "Restrictions and Limitations"
    ]
  },
  {
    "objectID": "restrictions.html#related-information",
    "href": "restrictions.html#related-information",
    "title": "Restrictions and Limitations",
    "section": "",
    "text": "What are the rules of the Econometrics Laboratory?\nHow do I manage UNIX processes?\nHow much disk space am I using?\nWhat temporary disk storage is available?",
    "crumbs": [
      "Home",
      "Accounts",
      "Policies and Rules",
      "Restrictions and Limitations"
    ]
  },
  {
    "objectID": "rules.html",
    "href": "rules.html",
    "title": "Account Rules",
    "section": "",
    "text": "Account Rules\n\nDo not give out your account information to any other individual. Any individual found accessing another individual’s account will have his/her account closed immediately, and this may result in further disciplinary action.\n\nEach individual is responsible for ALL activity associated with his/her account.\nDO NOT log into your account from another individual’s account.\nSend mail to “manager” immediately if you suspect that someone has gained access to your account.\n\nAbuse of any computer account by an individual within the EML system or abuse of any other computer system may lead to termination of the individual’s EML account and permanent suspension of all EML system privileges. Abuse of an account includes, but is not limited to:\n\nUnauthorized attempts to access accounts, files, or system resources.\nMalicious mischief of any sort.\nAny activity originating from a local account (on any computer system) that results in an official complaint being logged against the user.\nUnsolicited electronic communications with an individual who is not known to the user and/or the recipient.\nUse of electronic communications for advertising, selling, personal solicitations, or sending chain letters (The use of departmental aliases is restricted to University business).\nFailure to cooperate with requests of the System Staff regarding use of system resources.\nPlaying of games.\nRepeated failure to follow posted rules.\n\nIndividuals are not allowed to connect or remove computer equipment to or from the network connections in any room or office. An individual may request a connection for a personal computer and will be assigned a DHCP connection to use with the purple cables installed in offices. Attempting to attach any other computer equipment to an office network outlet is prohibited. This includes connecting switches, hubs, laptops or other computers from outside of the department.\nAll network connections within the department are controlled by the EML. All network related requests for service or reports of problems should be directed to the EML.\nThe contents of all accounts (including files that are owned or created by the user regardless of location) are subject to copyright laws, and all users must comply with those laws. All “original works of authorship” that are produced or distributed are covered by copyright law. An individual can not store or distribute (make available), in part or in whole, any item that is protected by copyright law without the written permission of the copyright owner. In order not to fall under the provisions of Senate Bill 1386, users are prohibited from storing/creating information that contains an individuals name in combination with personal information as defined by either a social security number, drivers license number, or financial/credit card number.\nEML accounts are not to be used for storing personal music or videos not directly related to course work or research. EML accounts can be used to transfer personal music or video files but the files must be removed within 48 hours.\nRestrictions on files located under the home directory with names that begin with a ‘.’ prefix (referred to as ‘dot’ files):\n\nOnly the owner is permitted to have “write” access to a ‘dot’ file.\nDot files can not be a ‘link’ to a file outside of the user’s account.\nA “.rhosts” file can not contain the name of any non-EML computer. Undergraduate class accounts are prohibited from using a “.rhosts” file.\n\nLimitations on the use of computer resources require that users do not run more that one large job on a computer at a time and do not run jobs on more than 8 computers simultaneously. When printing do not place more than 10 jobs in a printer queue. For information on resource usage see “help bigjobs”.\nRemove messages from the incoming mail file after they have been read. Do not save messages in the incoming mail file (/var/mail/[user-name]). If the incoming mail file grows to more than 0.1MB the mail file will be truncated and messages older than 30 days may be automatically deleted. Class accounts can not be used to subscribe to news groups, listing services, or are allowed to post messages to the net.\nUsers are restricted to creating and modifying files under their account (home directory). With the exception of the use of the directory “/tmp” the placement or modification of files in any other location without authorization is prohibited. The /tmp directory can be used for temporary (one day only) storage of files. Files older than 24 hours will be automatically deleted, but users should remove their files as soon as their work has been completed (See “help tmp”).\nAccounts must be renewed according to the following schedule:\n\nClass accounts expire at the end of each semester and can not be renewed.\nGraduate accounts for Economics students are valid as long as the individual is currently enrolled. Alumni accounts are issued upon request to individuals who have left the Department in good standing and are valid for one year after separation from the Department. Alumni accounts can not be renewed.\nAll other student accounts expire on Jan 1 and July 1 of each year and must be renewed.\nGuest accounts must be renewed each year by July 1 and require approval of the sponsoring faculty member.\nFaculty & visitor (associate research fellows) accounts expire upon termination of their appointments.\nContractor accounts are valid indefinitely, as long as the account is in good standing.\nAll other accounts expire on July 1 of each year and must be renewed.\n\nRequests for an extension of an account must be received within 15 days of the account expiration date (send electronic mail to “manager@econ”). There is a $20 fee to recover files from an account that has expired. Refer to “help accounts” for more information.\nServices requiring reimbursement for materials.\n\nPrinting: Student accounts are charged $0.05/page for any printing above their quota established according to the following categories:\n\n40 pages for each lower division undergraduate class account.\n100 pages for each upper division undergraduate class account.\n*160 pages for each graduate class account.\n40 pages/semester for each undergraduate student account.\n\n+160 pages/semester for each graduate student account.\nd Contractor, research, and non-statistics UC staff accounts are charged for all printing and should refer to the current rate schedule.\n*Students enrolled in Stat 299 can have their quota increased to 500 pages during the period their thesis is being reviewed.\n+Alumni accounts will be charged at the rate of $0.05/page for all printing.\nMedia: Only the costs for the media are charged when transferring files to a removable media.\n\nPlease report any problems regarding equipment or system software to the EML staff by sending mail to “trouble” or by reporting the problem directly to either room 643 or 498/499. For information/questions on the use of application packages (eg. blss, sas, S), programming languages and libraries send mail to “consult”. Questions/problems regarding accounts should be sent to “manager”. Refer to “help emergency” for a list of people to contact in case of an emergency.",
    "crumbs": [
      "Home",
      "Accounts",
      "Policies and Rules",
      "Account Rules"
    ]
  },
  {
    "objectID": "security.html",
    "href": "security.html",
    "title": "Security Issues and Policies",
    "section": "",
    "text": "Security Issues and Policies\nThe Econometrics Laboratory is a shared resource, and is subject to strict security procedures to protect the integrity of the system for all its users.\n\nDo not give your password to anyone.\nDo not write your password down where it can be seen.\nDo not let anyone look over your shoulder when you log in.\nAlways logout properly when you leave a workstation.\nPay attention to your directory and file permissions.\nChange your password frequently.\nIf you suspect someone’s been using your account, report it immediately to trouble@econ.berkeley.edu.\n\nUsers should also be aware that electronic files stored on disk in an individual’s account, a shared project account, or a system partition are not personal property, regardless of content, intended use at the time of creation, or purpose. Appropriate use of University of California facilities and infrastructure is defined in policies and guidelines posted on University of California web sites.\nAs such the Econometrics Laboratory (EML) reserve the right to review, modify, or delete any file or terminate any activity that may interfere with the operations of the EML’s computing facility. The EML will comply with prevailing University of California systemwide and Berkeley campus policies and guidelines governing the security and appropriate use of electronic and network resources. Further, the EMLwill comply with prevailing University of California systemwide and Berkeley campus policies and guidelines governing use of electronic and network resources and an individual’s right to privacy.",
    "crumbs": [
      "Home",
      "Accounts",
      "Security Issues and Policies"
    ]
  },
  {
    "objectID": "servers.html",
    "href": "servers.html",
    "title": "Login Servers",
    "section": "",
    "text": "Login Servers\nThis is a partial list of EML servers (with the memory available on the machines in parentheses). Some have access restrictions.\nYou can also browse a list of EML computers on the General overview of our dashboards.\n\nfargo.berkeley.edu (376 GB)\ngriliches.berkeley.edu (6 GB)\niia.berkeley.edu (125 GB)\njorgenson.berkeley.edu (188 GB)\nklein.berkeley.edu (754 GB)\nlaffont.berkeley.edu (94 GB)\nlogit.berkeley.edu (15 GB)\nnerlove.berkeley.edu (125 GB) *\nquesnay.berkeley.edu (251 GB)\nradner.berkeley.edu (31 GB)\ntheil.berkeley.edu (125 GB)\n\n* Access to nerlove is restricted to individuals who have obtained instructions regarding the use and limitations of running jobs on the compute servers. Please contact the EML staff to register as a restricted compute server user or to schedule access to additional resources on the EML compute servers.\nThese are shared machines and CPU and memory use of user jobs is not restricted by the system. This means that other jobs running on a machine could prevent your job from getting the memory it needs and lead to an out of memory error.",
    "crumbs": [
      "Home",
      "Cluster",
      "Login Servers"
    ]
  },
  {
    "objectID": "sftp-scp.html",
    "href": "sftp-scp.html",
    "title": "Secure File Transfer",
    "section": "",
    "text": "You can start sftp in much the same way you start ssh, e.g. ‘sftp username@remotehost’. Once you are connected, the environment functions like traditional ftp:\n$ sftp eml_user@iia.berkeley.edu\nsftp&gt; cd /tmp\nsftp&gt; put Book1.gnumeric\nUploading Book1.gnumeric to /tmp/Book1.gnumeric\nsftp&gt; get asdf\nFetching /tmp/asdf to asdf\nsftp&gt; quit\n \n\n\n\nSCP is useful for non-interactive file copying. The following will copy file into the user’s home direcory on the remote side:\n$ scp file eml_user@iia.berkeley.edu:\neml_user@iia.berkeley.edu's password: \nfile                100% |*****************************|   595       00:00\n \nThe following will copy the remote directory dir/ to the local directory dir2/ via the ‘-r’ (recursive) command-line switch:\n$ scp -r eml_user@iia.berkeley.edu:dir dir2/\neml_user@iia.berkeley.edu's password: \n$ ls dir2/\ndir",
    "crumbs": [
      "Home",
      "Remote Access",
      "File Transfer",
      "Secure File Transfer"
    ]
  },
  {
    "objectID": "sftp-scp.html#sftp",
    "href": "sftp-scp.html#sftp",
    "title": "Secure File Transfer",
    "section": "",
    "text": "You can start sftp in much the same way you start ssh, e.g. ‘sftp username@remotehost’. Once you are connected, the environment functions like traditional ftp:\n$ sftp eml_user@iia.berkeley.edu\nsftp&gt; cd /tmp\nsftp&gt; put Book1.gnumeric\nUploading Book1.gnumeric to /tmp/Book1.gnumeric\nsftp&gt; get asdf\nFetching /tmp/asdf to asdf\nsftp&gt; quit",
    "crumbs": [
      "Home",
      "Remote Access",
      "File Transfer",
      "Secure File Transfer"
    ]
  },
  {
    "objectID": "sftp-scp.html#scp",
    "href": "sftp-scp.html#scp",
    "title": "Secure File Transfer",
    "section": "",
    "text": "SCP is useful for non-interactive file copying. The following will copy file into the user’s home direcory on the remote side:\n$ scp file eml_user@iia.berkeley.edu:\neml_user@iia.berkeley.edu's password: \nfile                100% |*****************************|   595       00:00\n \nThe following will copy the remote directory dir/ to the local directory dir2/ via the ‘-r’ (recursive) command-line switch:\n$ scp -r eml_user@iia.berkeley.edu:dir dir2/\neml_user@iia.berkeley.edu's password: \n$ ls dir2/\ndir",
    "crumbs": [
      "Home",
      "Remote Access",
      "File Transfer",
      "Secure File Transfer"
    ]
  },
  {
    "objectID": "software.html",
    "href": "software.html",
    "title": "Software Inventory",
    "section": "",
    "text": "Ubuntu Linux on all servers and workstations\n\n\n\n\nSAS\nStata and Stata MP (xstata/xstata-mp)\nGauss\nR\nPython\nTensorflow\nPytorch\nTSP (Available only for download)\n\n\n\n\n\nMATLAB\nMathematica\nOctave\nmatElike\nIpopt\nMaple\nOpenBLAS\nIBM CPLEX Solver for Matlab\n\n\n\n\n\nNAG (Numerical Algorithms Group Library)\nIMSL Fortran Numerical Library\nStatTransfer\n\n\n\n\n\nGNU: gcc, g++, gfortran\nIntel: icc, ifort\n\n\n\n\n\nC\nC++\nPython\nR\nFortran\nJulia\nPerl\n\n\n\n\n\nvi\nEmacs\npico\nTeX, LaTeX, LaTeX2e\nkate\nLyx\n\n\n\n\n\nMicrosoft Office (only on lab Macs)\nLibre Office\n\n\n\n\n\ndynare++\n7zip\nAspera Connect\nPdftk",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#operating-systems-and-applications-software",
    "href": "software.html#operating-systems-and-applications-software",
    "title": "Software Inventory",
    "section": "",
    "text": "Ubuntu Linux on all servers and workstations",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#statistics-econometrics-and-machine-learning",
    "href": "software.html#statistics-econometrics-and-machine-learning",
    "title": "Software Inventory",
    "section": "",
    "text": "SAS\nStata and Stata MP (xstata/xstata-mp)\nGauss\nR\nPython\nTensorflow\nPytorch\nTSP (Available only for download)",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#mathematics",
    "href": "software.html#mathematics",
    "title": "Software Inventory",
    "section": "",
    "text": "MATLAB\nMathematica\nOctave\nmatElike\nIpopt\nMaple\nOpenBLAS\nIBM CPLEX Solver for Matlab",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#tools-and-utilities",
    "href": "software.html#tools-and-utilities",
    "title": "Software Inventory",
    "section": "",
    "text": "NAG (Numerical Algorithms Group Library)\nIMSL Fortran Numerical Library\nStatTransfer",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#compilers",
    "href": "software.html#compilers",
    "title": "Software Inventory",
    "section": "",
    "text": "GNU: gcc, g++, gfortran\nIntel: icc, ifort",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#programmingscripting",
    "href": "software.html#programmingscripting",
    "title": "Software Inventory",
    "section": "",
    "text": "C\nC++\nPython\nR\nFortran\nJulia\nPerl",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#text-editing-and-document-preparation",
    "href": "software.html#text-editing-and-document-preparation",
    "title": "Software Inventory",
    "section": "",
    "text": "vi\nEmacs\npico\nTeX, LaTeX, LaTeX2e\nkate\nLyx",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#office-applications",
    "href": "software.html#office-applications",
    "title": "Software Inventory",
    "section": "",
    "text": "Microsoft Office (only on lab Macs)\nLibre Office",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "software.html#other-applications",
    "href": "software.html#other-applications",
    "title": "Software Inventory",
    "section": "",
    "text": "dynare++\n7zip\nAspera Connect\nPdftk",
    "crumbs": [
      "Home",
      "Software",
      "Software Inventory"
    ]
  },
  {
    "objectID": "ssh-tunnel.html",
    "href": "ssh-tunnel.html",
    "title": "SSH Tunneling",
    "section": "",
    "text": "An SSH tunnel establishes a connection between your local machine and the remote machine via a TCP port. When you configure your local application to use an SSH tunnel you tell it to connect to your local machine at a specified port, rather than the remote machine. The tunnel then carries your traffic securely to the remote machine.\n\n\nHere is a list of application-specific tunnel settings. Note that in order to bind to ports lower than 1024 on Linux and Mac, one must have administrative privileges.\n\nTunnel Settings\n\n\nApplication\nType\nListen Port\n\n\n\n\nSMB\nTCP\n139\n\n\nSMB\nTCP\n445\n\n\nPrinting\nTCP\n515\n\n\nRemote Desktop\nTCP\n3389\n\n\nMySQL\nTCP\n3306\n\n\nVNC\nTCP\n5901\n\n\nJSTOR\nTCP\n8000\n\n\n\n\n\n\n\nClick the plus sign by the SSH menu choice in the left pane of the main window.\nClick on Tunnels.\nSet Source port to the value of the listen port and Destination to DESTINATION_HOST:DESTINATION_PORT given your specific tunneling options. (see table above)\nOnce the information is in place, click the Add button to create the tunnel.\nClick on the Session menu choice at the top of the left hand pane and enter any valid EML host in the Host Name window. Click on Open, and log in with your EML username and password.\nIf you are using an Remote Desktop application, under computername, type localhost:53389\n\n\n\n\nType (on your local machine) in a terminal window:\nssh -l username -L LISTEN_PORT:eml.berkeley.edu:DESTINATION_PORT EML_HOSTNAME\nwhere LISTEN_PORT is the Listen Port, DESTINATION_PORT is the Destination Port, and EML_HOSTNAME is any EML computer. See our dashboards for a list of EML computers.\nYou may included more than one tunnel on the command-line, for example:\nssh -l username -L 25:DESTINATION_HOST:25 -L 110:DESTINATION_HOST:110 EML_HOSTNAME\n\n\nIf you receive a message that the port is in use or are denied permission, you will need to choose a different port number for the local port. For example you would specify port 5445 rather than 445 as in the example below.\n\n\n\n\n\n\nConnect to the EML file server from off campus:\nssh -L 5445:eml.berkeley.edu:445 username@EML_HOSTNAME\nand then connect your SMB client to smb://localhost:5445/homes (or \\localhost:5445on Windows).\n\n\n\nRead JSTOR from off campus:\nssh -L 8000:www.jstor.org:80 username@EML_HOSTNAME\nand then connect your web browser to http://localhost:8000.\n\n\n\nConnect to an EML server through the VPN:\nssh -L 53389:localhost:3389 username@EML_HOSTNAME\nand then connect your RDP client (e.g. Microsoft Remote Desktop) to localhost:53389.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH Tunneling"
    ]
  },
  {
    "objectID": "ssh-tunnel.html#typical-configurations",
    "href": "ssh-tunnel.html#typical-configurations",
    "title": "SSH Tunneling",
    "section": "",
    "text": "Here is a list of application-specific tunnel settings. Note that in order to bind to ports lower than 1024 on Linux and Mac, one must have administrative privileges.\n\nTunnel Settings\n\n\nApplication\nType\nListen Port\n\n\n\n\nSMB\nTCP\n139\n\n\nSMB\nTCP\n445\n\n\nPrinting\nTCP\n515\n\n\nRemote Desktop\nTCP\n3389\n\n\nMySQL\nTCP\n3306\n\n\nVNC\nTCP\n5901\n\n\nJSTOR\nTCP\n8000",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH Tunneling"
    ]
  },
  {
    "objectID": "ssh-tunnel.html#in-windows---putty",
    "href": "ssh-tunnel.html#in-windows---putty",
    "title": "SSH Tunneling",
    "section": "",
    "text": "Click the plus sign by the SSH menu choice in the left pane of the main window.\nClick on Tunnels.\nSet Source port to the value of the listen port and Destination to DESTINATION_HOST:DESTINATION_PORT given your specific tunneling options. (see table above)\nOnce the information is in place, click the Add button to create the tunnel.\nClick on the Session menu choice at the top of the left hand pane and enter any valid EML host in the Host Name window. Click on Open, and log in with your EML username and password.\nIf you are using an Remote Desktop application, under computername, type localhost:53389",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH Tunneling"
    ]
  },
  {
    "objectID": "ssh-tunnel.html#macos-and-linux",
    "href": "ssh-tunnel.html#macos-and-linux",
    "title": "SSH Tunneling",
    "section": "",
    "text": "Type (on your local machine) in a terminal window:\nssh -l username -L LISTEN_PORT:eml.berkeley.edu:DESTINATION_PORT EML_HOSTNAME\nwhere LISTEN_PORT is the Listen Port, DESTINATION_PORT is the Destination Port, and EML_HOSTNAME is any EML computer. See our dashboards for a list of EML computers.\nYou may included more than one tunnel on the command-line, for example:\nssh -l username -L 25:DESTINATION_HOST:25 -L 110:DESTINATION_HOST:110 EML_HOSTNAME\n\n\nIf you receive a message that the port is in use or are denied permission, you will need to choose a different port number for the local port. For example you would specify port 5445 rather than 445 as in the example below.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH Tunneling"
    ]
  },
  {
    "objectID": "ssh-tunnel.html#examples",
    "href": "ssh-tunnel.html#examples",
    "title": "SSH Tunneling",
    "section": "",
    "text": "Connect to the EML file server from off campus:\nssh -L 5445:eml.berkeley.edu:445 username@EML_HOSTNAME\nand then connect your SMB client to smb://localhost:5445/homes (or \\localhost:5445on Windows).\n\n\n\nRead JSTOR from off campus:\nssh -L 8000:www.jstor.org:80 username@EML_HOSTNAME\nand then connect your web browser to http://localhost:8000.\n\n\n\nConnect to an EML server through the VPN:\nssh -L 53389:localhost:3389 username@EML_HOSTNAME\nand then connect your RDP client (e.g. Microsoft Remote Desktop) to localhost:53389.",
    "crumbs": [
      "Home",
      "Remote Access",
      "Secure Shell",
      "SSH Tunneling"
    ]
  },
  {
    "objectID": "system-status.html",
    "href": "system-status.html",
    "title": "Service Status",
    "section": "",
    "text": "There are no scheduled maintenance activities or active incidents to report."
  },
  {
    "objectID": "system-status.html#nothing-to-report",
    "href": "system-status.html#nothing-to-report",
    "title": "Service Status",
    "section": "",
    "text": "There are no scheduled maintenance activities or active incidents to report."
  },
  {
    "objectID": "temp-space.html",
    "href": "temp-space.html",
    "title": "Temporary Disk Space",
    "section": "",
    "text": "There are several places where users can temporarily store data.\n\n\nTemporary storage locations are not backed up and may be removed without notice.\n\n\n\nFiles put in the /tmp directory are only accessible on the machine on which they were created and are automatically wiped everytime the computer is rebooted. Files may also be deleted with little or no warning if resources become scarce. However, if you need a large amount of disk space for a short amount of time, /tmp provides a solution which does not need any staff intervention. Remember that there is no guarantee that files stored in /tmp are safe. Do not use /tmp for data that that is difficult or expensive to re-create.\nNo special permissions are required to use /tmp. To reference your files using /tmp, use ‘/tmp’ as the prefix to the name of the file, for example ‘/tmp/myfile’. If you are storing more than a handful of files, reduce the clutter by using a subdirectory of /tmp named with your account name, for example ‘/tmp/username/myfile’.\nThe limit to the amount of storage a user can take up is the physical limitation of the partition. However, if /tmp is full, editors, compilers, and many other programs will not work or behave erratically. To find out how much space is available in /tmp on your system, type ‘df -k /tmp’. Do not use /tmp if less than 30% of the space is available. Remove files when they are no longer needed.\n\n\n\nThe /var/tmp directory functions similarly to /tmp, however, files are not automatically removed after the machine is rebooted. This directory does get erased, however, whenever the workstation needs to be reinstalled or reconfigured. Otherwise, the same policies that apply to /tmp apply to /var/tmp.\nThe /Users/Shared directory functions identically to /var/tmp, except it is only found on our Macintosh computers.\n\n\n\nThe /var/tmp/scratch directory exists on some workstations that have secondary disks. This directory functions similarly to /var/tmp, however, it does not get erased when the computer is reinstalled or reconfigured.\n\n\n\nDirectories under /scratch/public can be used for projects requiring large files that are modified frequently. The scratch directories exist on the file server and not on the local workstations, however if space becomes limited we may automatically compress/gzip files or (if time permitting) ask users to either remove or archive files that are no longer needed in order to make room for other users needs. Files that are not actively being used and are compressible should be stored in a compressed format."
  },
  {
    "objectID": "temp-space.html#tmp",
    "href": "temp-space.html#tmp",
    "title": "Temporary Disk Space",
    "section": "",
    "text": "Files put in the /tmp directory are only accessible on the machine on which they were created and are automatically wiped everytime the computer is rebooted. Files may also be deleted with little or no warning if resources become scarce. However, if you need a large amount of disk space for a short amount of time, /tmp provides a solution which does not need any staff intervention. Remember that there is no guarantee that files stored in /tmp are safe. Do not use /tmp for data that that is difficult or expensive to re-create.\nNo special permissions are required to use /tmp. To reference your files using /tmp, use ‘/tmp’ as the prefix to the name of the file, for example ‘/tmp/myfile’. If you are storing more than a handful of files, reduce the clutter by using a subdirectory of /tmp named with your account name, for example ‘/tmp/username/myfile’.\nThe limit to the amount of storage a user can take up is the physical limitation of the partition. However, if /tmp is full, editors, compilers, and many other programs will not work or behave erratically. To find out how much space is available in /tmp on your system, type ‘df -k /tmp’. Do not use /tmp if less than 30% of the space is available. Remove files when they are no longer needed."
  },
  {
    "objectID": "temp-space.html#vartmp-usersshared",
    "href": "temp-space.html#vartmp-usersshared",
    "title": "Temporary Disk Space",
    "section": "",
    "text": "The /var/tmp directory functions similarly to /tmp, however, files are not automatically removed after the machine is rebooted. This directory does get erased, however, whenever the workstation needs to be reinstalled or reconfigured. Otherwise, the same policies that apply to /tmp apply to /var/tmp.\nThe /Users/Shared directory functions identically to /var/tmp, except it is only found on our Macintosh computers."
  },
  {
    "objectID": "temp-space.html#vartmpscratch",
    "href": "temp-space.html#vartmpscratch",
    "title": "Temporary Disk Space",
    "section": "",
    "text": "The /var/tmp/scratch directory exists on some workstations that have secondary disks. This directory functions similarly to /var/tmp, however, it does not get erased when the computer is reinstalled or reconfigured."
  },
  {
    "objectID": "temp-space.html#scratchpublic",
    "href": "temp-space.html#scratchpublic",
    "title": "Temporary Disk Space",
    "section": "",
    "text": "Directories under /scratch/public can be used for projects requiring large files that are modified frequently. The scratch directories exist on the file server and not on the local workstations, however if space becomes limited we may automatically compress/gzip files or (if time permitting) ask users to either remove or archive files that are no longer needed in order to make room for other users needs. Files that are not actively being used and are compressible should be stored in a compressed format."
  },
  {
    "objectID": "terminate-r.html",
    "href": "terminate-r.html",
    "title": "Terminate R sessions",
    "section": "",
    "text": "When you run an R job, you should properly quit the job when you’re done, by typing “q()” at the R prompt, and responding to the query about “Save workspace image?” appropriately. DO NOT log off without terminating your R job/session, and you should not kill a window with a running R process unless you follow one of the suggestions below.\n\n\n\nIf you want your R job to keep running after you log out, the best way to run R is through the BATCH command, i.e. run a command like this one at the UNIX prompt:\nR CMD BATCH cmds.r output.txt &\nwhere “cmds.r” is a file containing the R commands that you wish to run, and output.txt is the file where R will write its output. Type help(BATCH) from inside of R for more information. You can use this technique even if you don’t think you’ll be logging off before your job is done to make sure that R will terminate properly.\n\n\n\nIf you don’t want to worry about shutting down your interactive R session, you MUST use either the -save or the -no-save option. The reason that this is important is that if you log off or close a window while an interactive job is running, R will fall into an infinite loop at the end of your program, trying to ask you whether or not to save the data space. Using one of the options mentioned above will prevent this problem, as R will know the disposition of your data space before the program is completed. In other words, instead of just typing R at the UNIX prompt, type\nR --save\nor\nR --no-save",
    "crumbs": [
      "Home",
      "Software",
      "Terminate R sessions"
    ]
  },
  {
    "objectID": "terminate-r.html#quit",
    "href": "terminate-r.html#quit",
    "title": "Terminate R sessions",
    "section": "",
    "text": "When you run an R job, you should properly quit the job when you’re done, by typing “q()” at the R prompt, and responding to the query about “Save workspace image?” appropriately. DO NOT log off without terminating your R job/session, and you should not kill a window with a running R process unless you follow one of the suggestions below.",
    "crumbs": [
      "Home",
      "Software",
      "Terminate R sessions"
    ]
  },
  {
    "objectID": "terminate-r.html#batch",
    "href": "terminate-r.html#batch",
    "title": "Terminate R sessions",
    "section": "",
    "text": "If you want your R job to keep running after you log out, the best way to run R is through the BATCH command, i.e. run a command like this one at the UNIX prompt:\nR CMD BATCH cmds.r output.txt &\nwhere “cmds.r” is a file containing the R commands that you wish to run, and output.txt is the file where R will write its output. Type help(BATCH) from inside of R for more information. You can use this technique even if you don’t think you’ll be logging off before your job is done to make sure that R will terminate properly.",
    "crumbs": [
      "Home",
      "Software",
      "Terminate R sessions"
    ]
  },
  {
    "objectID": "terminate-r.html#explicit-invocation",
    "href": "terminate-r.html#explicit-invocation",
    "title": "Terminate R sessions",
    "section": "",
    "text": "If you don’t want to worry about shutting down your interactive R session, you MUST use either the -save or the -no-save option. The reason that this is important is that if you log off or close a window while an interactive job is running, R will fall into an infinite loop at the end of your program, trying to ask you whether or not to save the data space. Using one of the options mentioned above will prevent this problem, as R will know the disposition of your data space before the program is completed. In other words, instead of just typing R at the UNIX prompt, type\nR --save\nor\nR --no-save",
    "crumbs": [
      "Home",
      "Software",
      "Terminate R sessions"
    ]
  },
  {
    "objectID": "unix-processes.html",
    "href": "unix-processes.html",
    "title": "Managing UNIX processes",
    "section": "",
    "text": "The output of ps will indicate the name of the program, its process I.D., and the amount of CPU time it has consumed so far.\n\nTo display information about a specific user’s processes:\n\nps -U USERNAME\nwhere USERNAME is your username\n\nTo display information about a specific running program:\n\nps -ef | grep PROGRAM\nwhere PROGRAM is the program’s name\nSee man ps for additional information.\n\n\n\nTo kill a running program, type:\nkill PID\nwhere PID is the process I.D. obtained by running ps.\nIf the first form does not kill your process, try\nkill -9 PID\nTo kill all your background processes, execute:\nkill 0\n\n\n\nMost programs initially inherit the current terminal or pseudo-terminal for doing input and output. This means that these programs have a “controlling terminal”. The “controlling terminal”, and therefore all output, is lost if you logout before your background job completes. To avoid this loss, you should either code your program to read all input and write all output to specific files, or your should redirect input and output for the program by using the shell operators: &lt;, &gt;, &gt;&gt;, and &gt;&.\nIt is recommended that you redirect standard output and standard error to a log file for all programs run in the background. For example:\nmyprog &gt;& logfile &\nwill run myprog in the background, redirecting all output to the file ‘logfile’ in the current directory. See man bash for details on shell redirection operators.\n\n\n\nA “big job” is any CPU-bound process which requires over one minute of CPU time.\n\n\nIn order to run big jobs without slowing down the entire system and inconveniencing all users, everyone must follow certain procedures.\n\nClass accounts are restricted to running their jobs on the public workstations (Use the command sitehosts public for a list of public workstations). Class accounts are not allowed to run a job on a faculty workstation without the prior consent of the faculty member.\nRun the program in background. Do not run the program as “a.out”. Please rename the “a.out” file before executing the program and do not remove the program “binary” before the program has completed executing.\nRun only one background job at a time per machine. If you need to run multiple jobs on one machine, run them in sequence, not in parallel, by putting all the commands in a shell script. Select another computer if a large job is already running on the computer that you have selected. Use the command idle to select a host and top to examine the most CPU intensive jobs are running on that host.\nPlease do not submit jobs to more than 8 computers at any one time. If you have special requirements, you can request an increase in the number of computers to use concurrently by notifying the EML staff. This will enable the EML staff to evaluate load requirements and to monitor the system resources, which will help to avoid conflicts with other users.\nBig jobs should run at low priority, or high “nice value”, of 18 or 19. By default, all programs run at nice value 0. But on the EML systems, the following minumum nice values are required for big jobs:\nTable 1. Appropriate nice values\n\n\n\n\nCPU time\n\n\nMinimum nice value\n\n\n\n\n\n\n1 - 5 minutes\n\n\n18\n\n\n\n\nover 5 minutes\n\n\n19\n\n\n\n\n\nFor example, suppose one wanted to run Matlab in the background with nice value of 19:\n% nice +19 matlab &\nFor more information on these commands, see “man nice” (but note that where the manual says “nice -10” the C shell requires “nice +10”. Each user is responsible for ensuring that his/her big jobs are running at appropriate priorities. The superuser is free to renice appropriately any process which is slowing the system down.\nIf you need to nice a process while it is running, look up the PID as described above and run:\n% renice +19 PID\n\n\n\nComputer memory is necessary for the computer to operate on your data. As the size of the data you’re working with gets bigger and bigger, the computer tends to need more memory. Thus, when you’re working with lots of data and your program prints an error message, especially one which reports a number of bytes or kilobytes of memory requested, the problem is most likely computer memory. The first step is to lift the default restriction on the use of memory which is imposed by the shell, by typing the command:\nlimit datasize unlimited\nat the UNIX command prompt, before you run the program which is failing to obtain the required memory. If the problem persists, in general your only alternative is to run the job on a computer which has more memory. Please send mail to consult to get information about the memory resources of the different EML machines.\n\n\n\nSome people run 2-hour CPU-time jobs only to discover afterwords that the program didn’t even do what they wanted. Avoid this. Debug your program using small test cases until you’re sure you’ve got it right. Only then should you run the big monster.\nIf it’s a very long computation and you can wait for the results, use the “batch” and “at” commands to run it when the system is unloaded.\n\n\n\nTwo common questions when running big jobs are “How do I find out the running time?” and “How do I capture the program output which would normally go to the screen?”. Here is one simple way to do both (as:\n% nice +18 /usr/bin/time program-name &gt;& ouput-filename\nWhere program-name is the name of your program and ouput-filename is the name of the file in which you want to capture output. The running time will be the last line of the output file, formatted like this:\n60.0 real        10.0 user         0.5 sys\nIn this example, the cpu time used was 10.5 seconds (10.0 user + 0.5 sys) and the elapsed (wall-clock) time was 60.0 seconds. By division, your program used 10.5/60 or just over 1/6th of the available cpu time while it ran.\n\n\n\nUsers should run only one background job at a time per machine. If you must run several jobs in background, run them sequentially, not simultaneously. If your programs are ‘prog1’, ‘prog2’ and ‘prog3’, run them in background via the shell command:\n(prog1 ; prog2 ; prog3) &gt;& log &\nAnother way is to use a semicolon:\nrun1 &gt;& run1.log ; run2 &gt;& run2.log\nwhere run1 and run2 are the programs you wish to run and run1.log and run2.log are the logfiles.\nYet annother way is to set up a shell script file, for example ‘run_all’, containing:\n#!/bin/sh run1 &gt;& run1.log run2 &gt;& run2.log\nBy specifying the &gt; sign, you save the output from run1 into file run1.log. By also including the & sign, it also saves any error message output into run1.log.\nThen from the unix prompt:\n% chmod +x run_all\nto allow the script to be executable, and then type:\n./run_all\nto run the script. You could also type:\n./run_all &\nto have it run in the background.\n\n\n\n\nThe at and batch commands allow the system to queue up big jobs and run them at a later time. at allows you to specify when the commands should be executed, while jobs queued with batch will execute as soon as the system load level permits. These commands provide a mechanism for big jobs to run without slowing down interactive response and interfering with other people trying to use the computer.\n\n\nTo use at or batch, create a script file which contains the unix commands you want to run. Suppose your script file is called ‘filename’. To run it in batch, type the command:\nbatch filename\nTo run the script at a specific time, use:\nat time date filename\nwhere time is in the form 0815, 0815am, 8:15am, now, and 5 pm; and date is in the form Jan 24, Friday, tomorrow, and today.\nIf you leave out the date field, the date will default to today.\nThe computer will respond:\njob N at &lt;full date&gt;\nwhere ‘N’ is the job number it creates. When the job finishes, it will mail you the output of the script, unless output was redirected. (see below)\n\n\n\nBy default, /bin/sh is used as the shell interpreter for the commands in your script. If your script-file is a /bin/csh script, use the ‘-c’ flag, as in ‘at -c 1 pm script’.\nIf the commands in your script file need any input, create separate input files which contain the necessary input and use the ‘&lt;’ shell feature in the script file. To redirect the output of a particular command in your script, use the ‘&gt;’ shell feature. For example, your script file might contain the line:\n\nproga &lt; inputa &gt; outputa\n\nThis would cause the program ‘proga’ to take its input from the file ‘inputa’ and send output to ‘outputa’.\n\n\n\nTo find out the status of your jobs, type the command:\nat -l\nThis will report both ‘batch’ and ‘at’ jobs. If ‘N’ is the job number reported by ‘at -l’ then the command:\nat -r N\nwill remove that job from the queue (whether or not it is already running) and interrupt it (if it is already running).",
    "crumbs": [
      "Home",
      "Software",
      "Managing UNIX processes"
    ]
  },
  {
    "objectID": "unix-processes.html#the-ps-command",
    "href": "unix-processes.html#the-ps-command",
    "title": "Managing UNIX processes",
    "section": "",
    "text": "The output of ps will indicate the name of the program, its process I.D., and the amount of CPU time it has consumed so far.\n\nTo display information about a specific user’s processes:\n\nps -U USERNAME\nwhere USERNAME is your username\n\nTo display information about a specific running program:\n\nps -ef | grep PROGRAM\nwhere PROGRAM is the program’s name\nSee man ps for additional information.",
    "crumbs": [
      "Home",
      "Software",
      "Managing UNIX processes"
    ]
  },
  {
    "objectID": "unix-processes.html#killing-processes",
    "href": "unix-processes.html#killing-processes",
    "title": "Managing UNIX processes",
    "section": "",
    "text": "To kill a running program, type:\nkill PID\nwhere PID is the process I.D. obtained by running ps.\nIf the first form does not kill your process, try\nkill -9 PID\nTo kill all your background processes, execute:\nkill 0",
    "crumbs": [
      "Home",
      "Software",
      "Managing UNIX processes"
    ]
  },
  {
    "objectID": "unix-processes.html#input-and-output",
    "href": "unix-processes.html#input-and-output",
    "title": "Managing UNIX processes",
    "section": "",
    "text": "Most programs initially inherit the current terminal or pseudo-terminal for doing input and output. This means that these programs have a “controlling terminal”. The “controlling terminal”, and therefore all output, is lost if you logout before your background job completes. To avoid this loss, you should either code your program to read all input and write all output to specific files, or your should redirect input and output for the program by using the shell operators: &lt;, &gt;, &gt;&gt;, and &gt;&.\nIt is recommended that you redirect standard output and standard error to a log file for all programs run in the background. For example:\nmyprog &gt;& logfile &\nwill run myprog in the background, redirecting all output to the file ‘logfile’ in the current directory. See man bash for details on shell redirection operators.",
    "crumbs": [
      "Home",
      "Software",
      "Managing UNIX processes"
    ]
  },
  {
    "objectID": "unix-processes.html#running-intensive-processes",
    "href": "unix-processes.html#running-intensive-processes",
    "title": "Managing UNIX processes",
    "section": "",
    "text": "A “big job” is any CPU-bound process which requires over one minute of CPU time.\n\n\nIn order to run big jobs without slowing down the entire system and inconveniencing all users, everyone must follow certain procedures.\n\nClass accounts are restricted to running their jobs on the public workstations (Use the command sitehosts public for a list of public workstations). Class accounts are not allowed to run a job on a faculty workstation without the prior consent of the faculty member.\nRun the program in background. Do not run the program as “a.out”. Please rename the “a.out” file before executing the program and do not remove the program “binary” before the program has completed executing.\nRun only one background job at a time per machine. If you need to run multiple jobs on one machine, run them in sequence, not in parallel, by putting all the commands in a shell script. Select another computer if a large job is already running on the computer that you have selected. Use the command idle to select a host and top to examine the most CPU intensive jobs are running on that host.\nPlease do not submit jobs to more than 8 computers at any one time. If you have special requirements, you can request an increase in the number of computers to use concurrently by notifying the EML staff. This will enable the EML staff to evaluate load requirements and to monitor the system resources, which will help to avoid conflicts with other users.\nBig jobs should run at low priority, or high “nice value”, of 18 or 19. By default, all programs run at nice value 0. But on the EML systems, the following minumum nice values are required for big jobs:\nTable 1. Appropriate nice values\n\n\n\n\nCPU time\n\n\nMinimum nice value\n\n\n\n\n\n\n1 - 5 minutes\n\n\n18\n\n\n\n\nover 5 minutes\n\n\n19\n\n\n\n\n\nFor example, suppose one wanted to run Matlab in the background with nice value of 19:\n% nice +19 matlab &\nFor more information on these commands, see “man nice” (but note that where the manual says “nice -10” the C shell requires “nice +10”. Each user is responsible for ensuring that his/her big jobs are running at appropriate priorities. The superuser is free to renice appropriately any process which is slowing the system down.\nIf you need to nice a process while it is running, look up the PID as described above and run:\n% renice +19 PID\n\n\n\nComputer memory is necessary for the computer to operate on your data. As the size of the data you’re working with gets bigger and bigger, the computer tends to need more memory. Thus, when you’re working with lots of data and your program prints an error message, especially one which reports a number of bytes or kilobytes of memory requested, the problem is most likely computer memory. The first step is to lift the default restriction on the use of memory which is imposed by the shell, by typing the command:\nlimit datasize unlimited\nat the UNIX command prompt, before you run the program which is failing to obtain the required memory. If the problem persists, in general your only alternative is to run the job on a computer which has more memory. Please send mail to consult to get information about the memory resources of the different EML machines.\n\n\n\nSome people run 2-hour CPU-time jobs only to discover afterwords that the program didn’t even do what they wanted. Avoid this. Debug your program using small test cases until you’re sure you’ve got it right. Only then should you run the big monster.\nIf it’s a very long computation and you can wait for the results, use the “batch” and “at” commands to run it when the system is unloaded.\n\n\n\nTwo common questions when running big jobs are “How do I find out the running time?” and “How do I capture the program output which would normally go to the screen?”. Here is one simple way to do both (as:\n% nice +18 /usr/bin/time program-name &gt;& ouput-filename\nWhere program-name is the name of your program and ouput-filename is the name of the file in which you want to capture output. The running time will be the last line of the output file, formatted like this:\n60.0 real        10.0 user         0.5 sys\nIn this example, the cpu time used was 10.5 seconds (10.0 user + 0.5 sys) and the elapsed (wall-clock) time was 60.0 seconds. By division, your program used 10.5/60 or just over 1/6th of the available cpu time while it ran.\n\n\n\nUsers should run only one background job at a time per machine. If you must run several jobs in background, run them sequentially, not simultaneously. If your programs are ‘prog1’, ‘prog2’ and ‘prog3’, run them in background via the shell command:\n(prog1 ; prog2 ; prog3) &gt;& log &\nAnother way is to use a semicolon:\nrun1 &gt;& run1.log ; run2 &gt;& run2.log\nwhere run1 and run2 are the programs you wish to run and run1.log and run2.log are the logfiles.\nYet annother way is to set up a shell script file, for example ‘run_all’, containing:\n#!/bin/sh run1 &gt;& run1.log run2 &gt;& run2.log\nBy specifying the &gt; sign, you save the output from run1 into file run1.log. By also including the & sign, it also saves any error message output into run1.log.\nThen from the unix prompt:\n% chmod +x run_all\nto allow the script to be executable, and then type:\n./run_all\nto run the script. You could also type:\n./run_all &\nto have it run in the background.",
    "crumbs": [
      "Home",
      "Software",
      "Managing UNIX processes"
    ]
  },
  {
    "objectID": "unix-processes.html#scheduling-jobs",
    "href": "unix-processes.html#scheduling-jobs",
    "title": "Managing UNIX processes",
    "section": "",
    "text": "The at and batch commands allow the system to queue up big jobs and run them at a later time. at allows you to specify when the commands should be executed, while jobs queued with batch will execute as soon as the system load level permits. These commands provide a mechanism for big jobs to run without slowing down interactive response and interfering with other people trying to use the computer.\n\n\nTo use at or batch, create a script file which contains the unix commands you want to run. Suppose your script file is called ‘filename’. To run it in batch, type the command:\nbatch filename\nTo run the script at a specific time, use:\nat time date filename\nwhere time is in the form 0815, 0815am, 8:15am, now, and 5 pm; and date is in the form Jan 24, Friday, tomorrow, and today.\nIf you leave out the date field, the date will default to today.\nThe computer will respond:\njob N at &lt;full date&gt;\nwhere ‘N’ is the job number it creates. When the job finishes, it will mail you the output of the script, unless output was redirected. (see below)\n\n\n\nBy default, /bin/sh is used as the shell interpreter for the commands in your script. If your script-file is a /bin/csh script, use the ‘-c’ flag, as in ‘at -c 1 pm script’.\nIf the commands in your script file need any input, create separate input files which contain the necessary input and use the ‘&lt;’ shell feature in the script file. To redirect the output of a particular command in your script, use the ‘&gt;’ shell feature. For example, your script file might contain the line:\n\nproga &lt; inputa &gt; outputa\n\nThis would cause the program ‘proga’ to take its input from the file ‘inputa’ and send output to ‘outputa’.\n\n\n\nTo find out the status of your jobs, type the command:\nat -l\nThis will report both ‘batch’ and ‘at’ jobs. If ‘N’ is the job number reported by ‘at -l’ then the command:\nat -r N\nwill remove that job from the queue (whether or not it is already running) and interrupt it (if it is already running).",
    "crumbs": [
      "Home",
      "Software",
      "Managing UNIX processes"
    ]
  },
  {
    "objectID": "x-windows.html",
    "href": "x-windows.html",
    "title": "X Windows",
    "section": "",
    "text": "This article describes the steps necessary to install X server software on your home computer. This will enable you to display windows and graphics created by applications running on remote UNIX systems.\nNote that in many cases you may be better of using the EML JupyterHub for browser-based access to RStudio and VS Code, or Remote Desktop to run any graphical program in a remote desktop window.\n\n\nMost of our users who require X server software tend to choose Hummingbird’s eXceed because of its availability to the Berkeley campus, its broad feature set, and its Microsoft Windows compatability.\n\n\nHummingbird eXceed can be downloaded from http://software.berkeley.edu. You are required to authenticate with your CalNet ID.\n\n\n\nInstallation is fairly simple; just double-click on the installation program. The installer runs some display diagnostics towards the end so expect the installation process to take longer than most software installations.\n\n\n\nThe best way to run eXceed is in conjunction with SSH software. This ensures that your connection is secure and that anyone snooping on your internet connection will not be able to read any passwords or other secure information that you type. When you run eXceed and SSH software, you will launch programs from the SSH window and eXceed will be able to display them. See these instructions for information on downloading and installing SSH software.\n\n\nTo enable eXceed to work with SSH clients, it will have to be configured to wait for X connections, as opposed to initiating X sessions itself.\nRun the Xconfig utility that comes with eXceed. In the Xconfig control panel, open the Communication item and configure your connection to be Passive.\n\n\n\nYour Windows SSH client must be configured to forward X Window System communication from the machine you are connecting to to your PC’s display.\n\nputty\nLaunch putty.exe, click on the plus sign to the left of “SSH” in the left hand pane, then click “X11” and check the box labelled “Enable X11 Forwarding”.\nSSH Communications Security\nChoose Settings… from the Edit menu and then choose Tunneling from the Profile Settings tree on the left. Check Tunnel X11 connections in the pane on the right.\nThe above works fine if you start eXceed first and then start your SSH client. It is possible, however, to create a shortcut on your desktop that will automatically start both eXceed and your SSH client automatically. To enable this:\n\nOpen the Xsession utility that came with eXceed.\nIn the Xsession Session Startup Application popup window, click on New Program. Then choose Windows App and then the OK button.\nIn the Wstart popup window, fill in:\nDescription:  ssh\nCommand line: the path to ssh.exe (Browse for it)\nWorking directory: the path up to \\ssh, i.e., c:\\data fellows\\f-secure\\ssh\nRun:  Normal\nThen choose Save from the File menu and name the file ssh.ws. Then quit the Wstart window.\nNow in the Xsession window, you will see ssh.ws ssh under Available Programs. ssh.ws is the new filename, and ssh is the description.\nClick on ssh.ws ssh to enable the Add button. Click on Add. This adds the ssh.ws file to Included Programs.\nNext choose Save from the File menu and name the file ssh.ses. Again, the default path is the user directory in the exceed tree.\nThe last step is to find where eXceed saved ssh.ses and create a shortcup to it on your desktop. This is the icon you should double-click to start your secure X session.\n\n\n\n\n\n\n\nXming is the X Windows Software from X.Org ported to Microsoft Windows. It shares source code with Cygwin’s X server (see below), but you do not need the full cygwin environment to run it. You can use this X server in much the same way you use eXceed, though it does not come with many of the features of eXceed. If, for some reason, eXceed becomes unavailable to you, try this software. It can be downloaded from http://www.straightrunning.com/XmingNotes/.\n\n\n\nThe Cygwin UNIX environment also includes the XFree86 X Window System. It can be downloaded from http://www.cygwin.com/xfree/.\n\n\n\n\n\nDownload XQuartz from https://www.xquartz.org.\n\n\n\nFor forwarding remote X sessions over ssh you can use either Terminal.app (also found in /Applications/Utilities) or xterm. If you are using the macOS Terminal, you will need to set your DISPLAY variable. Enter this statement into the file ~/.bashrc on your own computer (not your EML account):\nif [ -z \"$DISPLAY\" ]; then export DISPLAY=:0.0; fi\nand then start a new Terminal window. If you are using xterm from with XQuartz (via the Application menu &gt; xterm), the variable should be set for you.\nOn the Mac you should also use the -X and -Y options:\nssh -X -Y username@hostname",
    "crumbs": [
      "Home",
      "Remote Access",
      "X Windows"
    ]
  },
  {
    "objectID": "x-windows.html#windows-exceed",
    "href": "x-windows.html#windows-exceed",
    "title": "X Windows",
    "section": "",
    "text": "Most of our users who require X server software tend to choose Hummingbird’s eXceed because of its availability to the Berkeley campus, its broad feature set, and its Microsoft Windows compatability.\n\n\nHummingbird eXceed can be downloaded from http://software.berkeley.edu. You are required to authenticate with your CalNet ID.\n\n\n\nInstallation is fairly simple; just double-click on the installation program. The installer runs some display diagnostics towards the end so expect the installation process to take longer than most software installations.\n\n\n\nThe best way to run eXceed is in conjunction with SSH software. This ensures that your connection is secure and that anyone snooping on your internet connection will not be able to read any passwords or other secure information that you type. When you run eXceed and SSH software, you will launch programs from the SSH window and eXceed will be able to display them. See these instructions for information on downloading and installing SSH software.\n\n\nTo enable eXceed to work with SSH clients, it will have to be configured to wait for X connections, as opposed to initiating X sessions itself.\nRun the Xconfig utility that comes with eXceed. In the Xconfig control panel, open the Communication item and configure your connection to be Passive.\n\n\n\nYour Windows SSH client must be configured to forward X Window System communication from the machine you are connecting to to your PC’s display.\n\nputty\nLaunch putty.exe, click on the plus sign to the left of “SSH” in the left hand pane, then click “X11” and check the box labelled “Enable X11 Forwarding”.\nSSH Communications Security\nChoose Settings… from the Edit menu and then choose Tunneling from the Profile Settings tree on the left. Check Tunnel X11 connections in the pane on the right.\nThe above works fine if you start eXceed first and then start your SSH client. It is possible, however, to create a shortcut on your desktop that will automatically start both eXceed and your SSH client automatically. To enable this:\n\nOpen the Xsession utility that came with eXceed.\nIn the Xsession Session Startup Application popup window, click on New Program. Then choose Windows App and then the OK button.\nIn the Wstart popup window, fill in:\nDescription:  ssh\nCommand line: the path to ssh.exe (Browse for it)\nWorking directory: the path up to \\ssh, i.e., c:\\data fellows\\f-secure\\ssh\nRun:  Normal\nThen choose Save from the File menu and name the file ssh.ws. Then quit the Wstart window.\nNow in the Xsession window, you will see ssh.ws ssh under Available Programs. ssh.ws is the new filename, and ssh is the description.\nClick on ssh.ws ssh to enable the Add button. Click on Add. This adds the ssh.ws file to Included Programs.\nNext choose Save from the File menu and name the file ssh.ses. Again, the default path is the user directory in the exceed tree.\nThe last step is to find where eXceed saved ssh.ses and create a shortcup to it on your desktop. This is the icon you should double-click to start your secure X session.",
    "crumbs": [
      "Home",
      "Remote Access",
      "X Windows"
    ]
  },
  {
    "objectID": "x-windows.html#windows-xming",
    "href": "x-windows.html#windows-xming",
    "title": "X Windows",
    "section": "",
    "text": "Xming is the X Windows Software from X.Org ported to Microsoft Windows. It shares source code with Cygwin’s X server (see below), but you do not need the full cygwin environment to run it. You can use this X server in much the same way you use eXceed, though it does not come with many of the features of eXceed. If, for some reason, eXceed becomes unavailable to you, try this software. It can be downloaded from http://www.straightrunning.com/XmingNotes/.",
    "crumbs": [
      "Home",
      "Remote Access",
      "X Windows"
    ]
  },
  {
    "objectID": "x-windows.html#windows-cygwin",
    "href": "x-windows.html#windows-cygwin",
    "title": "X Windows",
    "section": "",
    "text": "The Cygwin UNIX environment also includes the XFree86 X Window System. It can be downloaded from http://www.cygwin.com/xfree/.",
    "crumbs": [
      "Home",
      "Remote Access",
      "X Windows"
    ]
  },
  {
    "objectID": "x-windows.html#apple-xquartz",
    "href": "x-windows.html#apple-xquartz",
    "title": "X Windows",
    "section": "",
    "text": "Download XQuartz from https://www.xquartz.org.\n\n\n\nFor forwarding remote X sessions over ssh you can use either Terminal.app (also found in /Applications/Utilities) or xterm. If you are using the macOS Terminal, you will need to set your DISPLAY variable. Enter this statement into the file ~/.bashrc on your own computer (not your EML account):\nif [ -z \"$DISPLAY\" ]; then export DISPLAY=:0.0; fi\nand then start a new Terminal window. If you are using xterm from with XQuartz (via the Application menu &gt; xterm), the variable should be set for you.\nOn the Mac you should also use the -X and -Y options:\nssh -X -Y username@hostname",
    "crumbs": [
      "Home",
      "Remote Access",
      "X Windows"
    ]
  }
]